{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAY20npHGl8fwNz2y0kZV/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b3e29d4d9de4263a6f5d939fe364759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3935efda545f418e80c01bac4e5bf814",
              "IPY_MODEL_d3809b6c66fd437d91f8614d67928123",
              "IPY_MODEL_c9efc28814664aceb836823ed4aa8839"
            ],
            "layout": "IPY_MODEL_fe87e186b1804a9d9ff3282d307b4253"
          }
        },
        "3935efda545f418e80c01bac4e5bf814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d54ea6456474c86a9b6f10a59d0b7e5",
            "placeholder": "​",
            "style": "IPY_MODEL_53f17586010f40e9a035a56407d0e199",
            "value": "model_index.json: 100%"
          }
        },
        "d3809b6c66fd437d91f8614d67928123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3059e3c1134b401fa5f41c008ea8eba8",
            "max": 427,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e63e9cbb9b11484ba7e423016e2b73db",
            "value": 427
          }
        },
        "c9efc28814664aceb836823ed4aa8839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7109d79984e045caa5ffc57b2b16485d",
            "placeholder": "​",
            "style": "IPY_MODEL_c2525ada1d4347199b4f033c0ae76749",
            "value": " 427/427 [00:00&lt;00:00, 13.7kB/s]"
          }
        },
        "fe87e186b1804a9d9ff3282d307b4253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d54ea6456474c86a9b6f10a59d0b7e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f17586010f40e9a035a56407d0e199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3059e3c1134b401fa5f41c008ea8eba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e63e9cbb9b11484ba7e423016e2b73db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7109d79984e045caa5ffc57b2b16485d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2525ada1d4347199b4f033c0ae76749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "304169a128264d0d8a359b0b91c44704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34727a27244249fc984ab9c3987ad003",
              "IPY_MODEL_e654b1a7b4514671a8f881bec207392c",
              "IPY_MODEL_c5814000423444938bf488d2c5ec6d33"
            ],
            "layout": "IPY_MODEL_d3bac2e448cc44a7a7d95af8636774a6"
          }
        },
        "34727a27244249fc984ab9c3987ad003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_788ec4bc17d04fe5ba5c0fc71667a1f1",
            "placeholder": "​",
            "style": "IPY_MODEL_5eafae5ff88d4d13b38b60fcd20f0614",
            "value": "Fetching 18 files: 100%"
          }
        },
        "e654b1a7b4514671a8f881bec207392c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b50eb72064394c12903eea98d7f22dd8",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b74beb2365474415979c18b89deba013",
            "value": 18
          }
        },
        "c5814000423444938bf488d2c5ec6d33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a86a684be2854268aca639b878f1c7b3",
            "placeholder": "​",
            "style": "IPY_MODEL_c404e9b450284e4e8d55e26ebbd0fe4f",
            "value": " 18/18 [01:44&lt;00:00,  9.69s/it]"
          }
        },
        "d3bac2e448cc44a7a7d95af8636774a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "788ec4bc17d04fe5ba5c0fc71667a1f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eafae5ff88d4d13b38b60fcd20f0614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b50eb72064394c12903eea98d7f22dd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b74beb2365474415979c18b89deba013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a86a684be2854268aca639b878f1c7b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c404e9b450284e4e8d55e26ebbd0fe4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b0ea337b30341cfba409cc9f59e5fba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cd7c712a8b8c48d29f7da6df32654ed0",
              "IPY_MODEL_2923ed0e19a94b809a50800bbc548f2e",
              "IPY_MODEL_30627ffc8aa54eecabe0b8155fe145ea"
            ],
            "layout": "IPY_MODEL_2f88dcd8c32c470e84bf71b9edc141a0"
          }
        },
        "cd7c712a8b8c48d29f7da6df32654ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e92eca535b3644ddb5f173f574aba3ef",
            "placeholder": "​",
            "style": "IPY_MODEL_03b38e56951f4c71a03c69fcc6562a07",
            "value": "config.json: "
          }
        },
        "2923ed0e19a94b809a50800bbc548f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c932eef64f84a1caa90213bc2f5d2ac",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_780b67a1b9ee4427bb5df408b81913e9",
            "value": 1
          }
        },
        "30627ffc8aa54eecabe0b8155fe145ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b45ba7d2adc43579905ea0ea45a901a",
            "placeholder": "​",
            "style": "IPY_MODEL_bb12e808d2de40de99402ffe691c83bb",
            "value": " 1.32k/? [00:00&lt;00:00, 27.5kB/s]"
          }
        },
        "2f88dcd8c32c470e84bf71b9edc141a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e92eca535b3644ddb5f173f574aba3ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03b38e56951f4c71a03c69fcc6562a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c932eef64f84a1caa90213bc2f5d2ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "780b67a1b9ee4427bb5df408b81913e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b45ba7d2adc43579905ea0ea45a901a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb12e808d2de40de99402ffe691c83bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86e2650ba1cd45a8bf7f7ed5541b0def": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ab85bccfe374019a97137c61e65e027",
              "IPY_MODEL_01ffbb863fcb4db1b120959ca3a8f05f",
              "IPY_MODEL_431e0654b83c479eb55ea48666c17daf"
            ],
            "layout": "IPY_MODEL_528d0dac6ee9434cb5a5da361aef8b95"
          }
        },
        "2ab85bccfe374019a97137c61e65e027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2334881b039246f7b04d3a8f2e0bdcfd",
            "placeholder": "​",
            "style": "IPY_MODEL_ab9d82c25a434d57bde0f7aea98ea80a",
            "value": "pytorch_model-00003-of-00007.bin: 100%"
          }
        },
        "01ffbb863fcb4db1b120959ca3a8f05f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2f2f0c331514585b7cdda51185c2dba",
            "max": 1927415036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4c62221bdef4f2baf9a8b712e517891",
            "value": 1927415036
          }
        },
        "431e0654b83c479eb55ea48666c17daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0496affc69f4c71a96f83a37537f24f",
            "placeholder": "​",
            "style": "IPY_MODEL_e52e791316724e4991464777ad1da1be",
            "value": " 1.93G/1.93G [01:43&lt;00:00, 18.3MB/s]"
          }
        },
        "528d0dac6ee9434cb5a5da361aef8b95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2334881b039246f7b04d3a8f2e0bdcfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab9d82c25a434d57bde0f7aea98ea80a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2f2f0c331514585b7cdda51185c2dba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4c62221bdef4f2baf9a8b712e517891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0496affc69f4c71a96f83a37537f24f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e52e791316724e4991464777ad1da1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97f4f72e338f4e9e9b1a572133a7bca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef3ccaf45c204cbcaad69043fe6a8d3e",
              "IPY_MODEL_61e572d26e70484c92e0dab0ce3cbf61",
              "IPY_MODEL_44f5b6ab060b4683ad5fa75259255abc"
            ],
            "layout": "IPY_MODEL_016c286597ca447db67d3d36b0f01ba4"
          }
        },
        "ef3ccaf45c204cbcaad69043fe6a8d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478a7e64a977486bb893f6c1e0b127e8",
            "placeholder": "​",
            "style": "IPY_MODEL_1873887d6c8f4d8a9bcbfbc65d7e1ac0",
            "value": "pytorch_model-00001-of-00007.bin: 100%"
          }
        },
        "61e572d26e70484c92e0dab0ce3cbf61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a90496f3115457593c4423d1aaab89a",
            "max": 1827781090,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f81ce9998fb2408ab019d7200446d263",
            "value": 1827781090
          }
        },
        "44f5b6ab060b4683ad5fa75259255abc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7eaea8c1219a4efa849feb58c8a69cdc",
            "placeholder": "​",
            "style": "IPY_MODEL_1e3881dd29b24089a92fc06044e31452",
            "value": " 1.83G/1.83G [01:42&lt;00:00, 6.49MB/s]"
          }
        },
        "016c286597ca447db67d3d36b0f01ba4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "478a7e64a977486bb893f6c1e0b127e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1873887d6c8f4d8a9bcbfbc65d7e1ac0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a90496f3115457593c4423d1aaab89a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81ce9998fb2408ab019d7200446d263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7eaea8c1219a4efa849feb58c8a69cdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3881dd29b24089a92fc06044e31452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "937dae3add724cfcaf5b4d7209656d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64bd07cf64b449adb5c2ffa8e2aaa126",
              "IPY_MODEL_8dd681f4e2284fceb395ba33a9b7e69b",
              "IPY_MODEL_f08d210c28cd44c084e2e886e0fe98ea"
            ],
            "layout": "IPY_MODEL_1cb97607bece4ba5895476bb2e35854a"
          }
        },
        "64bd07cf64b449adb5c2ffa8e2aaa126": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce09480c94984fff88f32c6b18914fc9",
            "placeholder": "​",
            "style": "IPY_MODEL_af667af9d3a34d6eaf52ce00dd7c9ab7",
            "value": "pytorch_model-00002-of-00007.bin: 100%"
          }
        },
        "8dd681f4e2284fceb395ba33a9b7e69b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc13c17b88c5492288cfc3c61ecac3a1",
            "max": 1968299480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3739d00bb07d40d19ca1eec6fe3de6e2",
            "value": 1968299480
          }
        },
        "f08d210c28cd44c084e2e886e0fe98ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c6384ff7b4e4347a373381cc6f32588",
            "placeholder": "​",
            "style": "IPY_MODEL_fd8704f779314f6ca38fa66101ff73eb",
            "value": " 1.97G/1.97G [01:43&lt;00:00, 70.5MB/s]"
          }
        },
        "1cb97607bece4ba5895476bb2e35854a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce09480c94984fff88f32c6b18914fc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af667af9d3a34d6eaf52ce00dd7c9ab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc13c17b88c5492288cfc3c61ecac3a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3739d00bb07d40d19ca1eec6fe3de6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c6384ff7b4e4347a373381cc6f32588": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd8704f779314f6ca38fa66101ff73eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c6f07b77e3641d7afda2df5277bfc20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a14fb5e5769c44158a6d82313336d2bd",
              "IPY_MODEL_94cc78ab1846451daf9390ec587dce3f",
              "IPY_MODEL_e9385687a5f14b0d925986cfb0b57773"
            ],
            "layout": "IPY_MODEL_04031d0f8f2c4b24abd9c1bee701ef4a"
          }
        },
        "a14fb5e5769c44158a6d82313336d2bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afe11f644a93490e88e4188b359c8513",
            "placeholder": "​",
            "style": "IPY_MODEL_629b44e257cc4f709f99f6cb4eac8d20",
            "value": "pytorch_model-00004-of-00007.bin: 100%"
          }
        },
        "94cc78ab1846451daf9390ec587dce3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b291173baf984c35b66a97360fb7ce7e",
            "max": 1815225998,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b6965a6cc9d4d7eb959e5b7d469c478",
            "value": 1815225998
          }
        },
        "e9385687a5f14b0d925986cfb0b57773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e1c656dcf1d442a8cb2d7c1270c0660",
            "placeholder": "​",
            "style": "IPY_MODEL_3426c60716e74df899faccb9cf237d49",
            "value": " 1.82G/1.82G [01:41&lt;00:00, 25.0MB/s]"
          }
        },
        "04031d0f8f2c4b24abd9c1bee701ef4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe11f644a93490e88e4188b359c8513": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "629b44e257cc4f709f99f6cb4eac8d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b291173baf984c35b66a97360fb7ce7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b6965a6cc9d4d7eb959e5b7d469c478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e1c656dcf1d442a8cb2d7c1270c0660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3426c60716e74df899faccb9cf237d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f05ba7367c474aee8e97979e58d4475c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c1feb4ab328439f894a63a886769c62",
              "IPY_MODEL_774a14462ecd41f6bf771ac905a27b1d",
              "IPY_MODEL_2eaa34a80b4049ccaa6bb9071321532b"
            ],
            "layout": "IPY_MODEL_3557f96611f2441288d5b32b2562651a"
          }
        },
        "3c1feb4ab328439f894a63a886769c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5f44cdd4044459aa2bc5ca701e99bf3",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6cde5072ef4c43a4223fd22731d3bb",
            "value": "pytorch_model-00006-of-00007.bin: 100%"
          }
        },
        "774a14462ecd41f6bf771ac905a27b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1a6c90e4d034439b03473d7ead42eb1",
            "max": 1927415036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9172b8709d884ed58743717239249da7",
            "value": 1927415036
          }
        },
        "2eaa34a80b4049ccaa6bb9071321532b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_950dd11a7902431d90c79586465b3584",
            "placeholder": "​",
            "style": "IPY_MODEL_e6966f8e315247538b8b69da6f6b9d24",
            "value": " 1.93G/1.93G [01:43&lt;00:00, 18.8MB/s]"
          }
        },
        "3557f96611f2441288d5b32b2562651a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5f44cdd4044459aa2bc5ca701e99bf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6cde5072ef4c43a4223fd22731d3bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1a6c90e4d034439b03473d7ead42eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9172b8709d884ed58743717239249da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "950dd11a7902431d90c79586465b3584": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6966f8e315247538b8b69da6f6b9d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be253b8e2e8b4646ba746b396eb2456c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6017dbbdf57f43faa41cb9f675f0616a",
              "IPY_MODEL_343cdad01b1b4b699236d581d544af59",
              "IPY_MODEL_3c380cfc96cd47c8b4d41fc7c0e64093"
            ],
            "layout": "IPY_MODEL_2b976c3aa20745fba6660d9650f06756"
          }
        },
        "6017dbbdf57f43faa41cb9f675f0616a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d487e253b64049e5832c253e42a78fe8",
            "placeholder": "​",
            "style": "IPY_MODEL_d28f11574f004c569b4534c2fbaeaca3",
            "value": "pytorch_model-00005-of-00007.bin: 100%"
          }
        },
        "343cdad01b1b4b699236d581d544af59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_012387807ea149d587fcba1ea85d4a33",
            "max": 1968299544,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aebbdd90776246c099d9fb101028ca6b",
            "value": 1968299544
          }
        },
        "3c380cfc96cd47c8b4d41fc7c0e64093": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1036d7a75b7940429c197d5122a2b219",
            "placeholder": "​",
            "style": "IPY_MODEL_53cbfe22dc0e476d98eca65ffee45079",
            "value": " 1.97G/1.97G [01:44&lt;00:00, 81.0MB/s]"
          }
        },
        "2b976c3aa20745fba6660d9650f06756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d487e253b64049e5832c253e42a78fe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d28f11574f004c569b4534c2fbaeaca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "012387807ea149d587fcba1ea85d4a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aebbdd90776246c099d9fb101028ca6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1036d7a75b7940429c197d5122a2b219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53cbfe22dc0e476d98eca65ffee45079": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b0284fc56bc405d81dc838934b4d0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c764457ce4c4580816ddeaf2621f726",
              "IPY_MODEL_4960b2c958d146b8a3818bfe1e848ce6",
              "IPY_MODEL_eed514a38f7e4fd2b804433a049b7297"
            ],
            "layout": "IPY_MODEL_a994617a19a14695ada86c544dbbc5c8"
          }
        },
        "2c764457ce4c4580816ddeaf2621f726": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21eceab0087749478bd9c5057669df65",
            "placeholder": "​",
            "style": "IPY_MODEL_7f58a18959c54e1c826ce0d89ed4e3b2",
            "value": "scheduler_config.json: 100%"
          }
        },
        "4960b2c958d146b8a3818bfe1e848ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a6e9a9737b4478fbc4cea993de52540",
            "max": 606,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c83851dca2341b5a4de2879c00238a0",
            "value": 606
          }
        },
        "eed514a38f7e4fd2b804433a049b7297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5331e73d98754640adc4ce1d41b2095d",
            "placeholder": "​",
            "style": "IPY_MODEL_a77554ff9a844afa95f375302b8b3d82",
            "value": " 606/606 [00:00&lt;00:00, 4.26kB/s]"
          }
        },
        "a994617a19a14695ada86c544dbbc5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21eceab0087749478bd9c5057669df65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f58a18959c54e1c826ce0d89ed4e3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a6e9a9737b4478fbc4cea993de52540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c83851dca2341b5a4de2879c00238a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5331e73d98754640adc4ce1d41b2095d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a77554ff9a844afa95f375302b8b3d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69dbae988b1f4fb8aeaa7394557aaa26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b289ef8bafe43df8e5fba7bb4a4da21",
              "IPY_MODEL_eaeaa7573a9e45309a5512063f0bc575",
              "IPY_MODEL_8dadef06d22341f4a1fa3e1ec860b307"
            ],
            "layout": "IPY_MODEL_7cb3eb025db442cb8b35d30b5bcef189"
          }
        },
        "3b289ef8bafe43df8e5fba7bb4a4da21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26a717e8265c404bbc0f3f02a03286fc",
            "placeholder": "​",
            "style": "IPY_MODEL_89aca9a92ac646b89610a32ebb13c585",
            "value": "pytorch_model-00007-of-00007.bin: 100%"
          }
        },
        "eaeaa7573a9e45309a5512063f0bc575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a2c60fc78df4f1f88fda5d50d4ec6f0",
            "max": 1052808542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_afc3c6348ea7473ba8c71ae2ad4c6fe4",
            "value": 1052808542
          }
        },
        "8dadef06d22341f4a1fa3e1ec860b307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff93b7f91b0143b28d2f90e1a5772d3f",
            "placeholder": "​",
            "style": "IPY_MODEL_2020fa4fc861468994c9d2dba4190ee1",
            "value": " 1.05G/1.05G [01:03&lt;00:00, 25.0MB/s]"
          }
        },
        "7cb3eb025db442cb8b35d30b5bcef189": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26a717e8265c404bbc0f3f02a03286fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89aca9a92ac646b89610a32ebb13c585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a2c60fc78df4f1f88fda5d50d4ec6f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afc3c6348ea7473ba8c71ae2ad4c6fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff93b7f91b0143b28d2f90e1a5772d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2020fa4fc861468994c9d2dba4190ee1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf17c96ecc624a9fb758fcbd8fcc9aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0a2610eb8d24eebb3ab0d12facf6f81",
              "IPY_MODEL_17b248987f8a43e5a5c36d47c38127a5",
              "IPY_MODEL_3e0e699a45eb47798eafc8756d8ef037"
            ],
            "layout": "IPY_MODEL_1249159b95f249148817f661729bd63f"
          }
        },
        "c0a2610eb8d24eebb3ab0d12facf6f81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_065458c1d38e4c0f8b594bd318fe5ec6",
            "placeholder": "​",
            "style": "IPY_MODEL_13563e9326374a0190f5ad89eb37eeb3",
            "value": "pytorch_model.bin.index.json: "
          }
        },
        "17b248987f8a43e5a5c36d47c38127a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4089a6ea47ce4cca91f7b94ea980cfda",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d1e8473236e407bb3cc28052e07432e",
            "value": 1
          }
        },
        "3e0e699a45eb47798eafc8756d8ef037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_783afbb01bdc466da948c3d171390879",
            "placeholder": "​",
            "style": "IPY_MODEL_8102702aee3e4f70b5008c9f007258ec",
            "value": " 20.4k/? [00:00&lt;00:00, 828kB/s]"
          }
        },
        "1249159b95f249148817f661729bd63f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "065458c1d38e4c0f8b594bd318fe5ec6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13563e9326374a0190f5ad89eb37eeb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4089a6ea47ce4cca91f7b94ea980cfda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2d1e8473236e407bb3cc28052e07432e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "783afbb01bdc466da948c3d171390879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8102702aee3e4f70b5008c9f007258ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1744cab7e03340dfa45d3301af0bb87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41bed656ba404d4d9b7f2ef331a43f4c",
              "IPY_MODEL_7e566916ae444d53b28145d0a8e58fcc",
              "IPY_MODEL_6308196b022f429ebcfff8194fecc068"
            ],
            "layout": "IPY_MODEL_707d93c029744f4c97fbf958e3374bf7"
          }
        },
        "41bed656ba404d4d9b7f2ef331a43f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e86090975cde4c2cbdec298aea946096",
            "placeholder": "​",
            "style": "IPY_MODEL_01651f9690e8453899c6dd7047e228fb",
            "value": "tokenization_chatglm.py: "
          }
        },
        "7e566916ae444d53b28145d0a8e58fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baf94d1e991e47b2991794cbac03082c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_255e7e12d13c4fcc963e3a41b4afbdfc",
            "value": 1
          }
        },
        "6308196b022f429ebcfff8194fecc068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82ff7b63a3934743aca2bd1c7159e32e",
            "placeholder": "​",
            "style": "IPY_MODEL_5a622136ae9242b39793d33c5c10e1e6",
            "value": " 12.2k/? [00:00&lt;00:00, 510kB/s]"
          }
        },
        "707d93c029744f4c97fbf958e3374bf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e86090975cde4c2cbdec298aea946096": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01651f9690e8453899c6dd7047e228fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baf94d1e991e47b2991794cbac03082c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "255e7e12d13c4fcc963e3a41b4afbdfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82ff7b63a3934743aca2bd1c7159e32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a622136ae9242b39793d33c5c10e1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "847bdaff6708404a9b5f25dd43d764ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87de67aa17b248a8a4499c19dc71410a",
              "IPY_MODEL_f3502b36f9ca4c77a904162f345406fb",
              "IPY_MODEL_109860b4189a4f81be5e11df7c8686f7"
            ],
            "layout": "IPY_MODEL_b1db95acc587477086f38ac60b0ad579"
          }
        },
        "87de67aa17b248a8a4499c19dc71410a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_799610901c454e4285378e34cf5d72ff",
            "placeholder": "​",
            "style": "IPY_MODEL_759647d13af5434984bd5e2bb6c9a352",
            "value": "tokenizer.model: 100%"
          }
        },
        "f3502b36f9ca4c77a904162f345406fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b35b358ca245ef90a4650136fd1e15",
            "max": 1018370,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57a106f05dfb430a9b91e8166e3210d3",
            "value": 1018370
          }
        },
        "109860b4189a4f81be5e11df7c8686f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5a07c457f39460bbf5c448831854db2",
            "placeholder": "​",
            "style": "IPY_MODEL_e4b79dcd5d7a43f892e52665e279db14",
            "value": " 1.02M/1.02M [00:00&lt;00:00, 9.34MB/s]"
          }
        },
        "b1db95acc587477086f38ac60b0ad579": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "799610901c454e4285378e34cf5d72ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "759647d13af5434984bd5e2bb6c9a352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59b35b358ca245ef90a4650136fd1e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a106f05dfb430a9b91e8166e3210d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5a07c457f39460bbf5c448831854db2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4b79dcd5d7a43f892e52665e279db14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdbc6750dd7c43a3888b244b0ceab98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7083e4233835405aa5209d1c7419b465",
              "IPY_MODEL_97e2218b8cf04b3b86846009b8dacd34",
              "IPY_MODEL_7f949eecb89742c7ab0cf473a6636e8d"
            ],
            "layout": "IPY_MODEL_3ded1303bf6441b5abc159adeda939d5"
          }
        },
        "7083e4233835405aa5209d1c7419b465": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f764cb7aa91648719c246a23434dca40",
            "placeholder": "​",
            "style": "IPY_MODEL_135d6b0e83ef4a2aa186c830d5293281",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "97e2218b8cf04b3b86846009b8dacd34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4d6c79c72941d4b68ee9ebf0aee881",
            "max": 249,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9656b8e49fe14d98b23b2e9322269d3a",
            "value": 249
          }
        },
        "7f949eecb89742c7ab0cf473a6636e8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c680b2def08f4e22b80dd596be107273",
            "placeholder": "​",
            "style": "IPY_MODEL_f303b1437c4a4c799a832b8a399b7444",
            "value": " 249/249 [00:00&lt;00:00, 1.14kB/s]"
          }
        },
        "3ded1303bf6441b5abc159adeda939d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f764cb7aa91648719c246a23434dca40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "135d6b0e83ef4a2aa186c830d5293281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf4d6c79c72941d4b68ee9ebf0aee881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9656b8e49fe14d98b23b2e9322269d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c680b2def08f4e22b80dd596be107273": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f303b1437c4a4c799a832b8a399b7444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "038fa33a67b64fee91779b177533437b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1338b57420c84318b3148785263528db",
              "IPY_MODEL_b3bd745abf6b4504b3c45cc187e1f65a",
              "IPY_MODEL_a5cffef83be840a6bcd8cfd27d760395"
            ],
            "layout": "IPY_MODEL_b19d2d0333c94bc4a7853a88821f6512"
          }
        },
        "1338b57420c84318b3148785263528db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc65fecf2c3d4f1ea860ed2583eaaf61",
            "placeholder": "​",
            "style": "IPY_MODEL_0db9623155e74dd5a01a55d2de04f77f",
            "value": "config.json: "
          }
        },
        "b3bd745abf6b4504b3c45cc187e1f65a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a3d01ab7e7b4c52ab4b3f419b4fedb2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca2aebc441a64c66ab5a860771b654c7",
            "value": 1
          }
        },
        "a5cffef83be840a6bcd8cfd27d760395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51d3f03cff3e44f1be6caf3e8a0eed19",
            "placeholder": "​",
            "style": "IPY_MODEL_d91ea52ceaca416893942be362007ecf",
            "value": " 1.78k/? [00:00&lt;00:00, 9.11kB/s]"
          }
        },
        "b19d2d0333c94bc4a7853a88821f6512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc65fecf2c3d4f1ea860ed2583eaaf61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0db9623155e74dd5a01a55d2de04f77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a3d01ab7e7b4c52ab4b3f419b4fedb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ca2aebc441a64c66ab5a860771b654c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51d3f03cff3e44f1be6caf3e8a0eed19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d91ea52ceaca416893942be362007ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78404ab9aa0249adb5586c9fb30241cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e2f63ae423f4160becfcdc0019ed743",
              "IPY_MODEL_546a2982b6c540be812473d565668a64",
              "IPY_MODEL_84c8e18b19b54df1b7d59818516470aa"
            ],
            "layout": "IPY_MODEL_e7ad0c68586a45ac9f4376ac23249a64"
          }
        },
        "4e2f63ae423f4160becfcdc0019ed743": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed5496f5da44b94ab4452a8f7e8217e",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6fb7b14564444aae64e8c449b341d1",
            "value": "config.json: 100%"
          }
        },
        "546a2982b6c540be812473d565668a64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56874decde5343c6ab05ae0069678947",
            "max": 611,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b52349715d9946d58b8f1a2a6da55de3",
            "value": 611
          }
        },
        "84c8e18b19b54df1b7d59818516470aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_208e696686224390becebb5166dc476d",
            "placeholder": "​",
            "style": "IPY_MODEL_92b07ed010824ffcaf0394e26390f9a3",
            "value": " 611/611 [00:00&lt;00:00, 4.15kB/s]"
          }
        },
        "e7ad0c68586a45ac9f4376ac23249a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bed5496f5da44b94ab4452a8f7e8217e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae6fb7b14564444aae64e8c449b341d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56874decde5343c6ab05ae0069678947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b52349715d9946d58b8f1a2a6da55de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "208e696686224390becebb5166dc476d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92b07ed010824ffcaf0394e26390f9a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27b21c4440d04ceebf2ecfec5236ee91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_14e3f1681e194001b11813a498533c44",
              "IPY_MODEL_d99e372c09bb4051a27d0d59556e0ac3",
              "IPY_MODEL_fb3633daa5344cf1bdc5ba7db48735c7"
            ],
            "layout": "IPY_MODEL_17fc92f5677448168ffe172af95e2e49"
          }
        },
        "14e3f1681e194001b11813a498533c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c3ad52cccd2416ebe2e6939f1084081",
            "placeholder": "​",
            "style": "IPY_MODEL_65bc40f9b7b14909a3d0d0cf81152b84",
            "value": "diffusion_pytorch_model.fp16.bin: 100%"
          }
        },
        "d99e372c09bb4051a27d0d59556e0ac3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3ade838b46d46acab5f4b8ec51a272e",
            "max": 167405651,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f963d7fec4c54963b25a6661219e67ef",
            "value": 167405651
          }
        },
        "fb3633daa5344cf1bdc5ba7db48735c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e429b37ec284d06b1591433155a9415",
            "placeholder": "​",
            "style": "IPY_MODEL_62a6177336374062b18c606ada6d2e87",
            "value": " 167M/167M [00:05&lt;00:00, 34.7MB/s]"
          }
        },
        "17fc92f5677448168ffe172af95e2e49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c3ad52cccd2416ebe2e6939f1084081": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65bc40f9b7b14909a3d0d0cf81152b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3ade838b46d46acab5f4b8ec51a272e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f963d7fec4c54963b25a6661219e67ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e429b37ec284d06b1591433155a9415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62a6177336374062b18c606ada6d2e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82cc702de2f5492f97235608a3311ead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1344c9e564944d5e96651aee61f633e0",
              "IPY_MODEL_f307e1c5643c4db88457f8c80ecfd0e1",
              "IPY_MODEL_0b63f39f8ef246c5aa00a9b94d6b4ad9"
            ],
            "layout": "IPY_MODEL_e613e7bed71944f995c483815bb42c89"
          }
        },
        "1344c9e564944d5e96651aee61f633e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a983125976498bb2fcdc30cb0e2257",
            "placeholder": "​",
            "style": "IPY_MODEL_353fc554bb7b4a829504286d46b1fe24",
            "value": "Loading pipeline components...:  40%"
          }
        },
        "f307e1c5643c4db88457f8c80ecfd0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5efbd3f84a734bc4bb084d4f2d7f58d9",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b14a8e7087124b119d19030c928a2cf9",
            "value": 2
          }
        },
        "0b63f39f8ef246c5aa00a9b94d6b4ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d79478596ad4cd9bbedd3b55030b160",
            "placeholder": "​",
            "style": "IPY_MODEL_a1c6c07e3e4c4027acda0af28b812faf",
            "value": " 2/5 [00:00&lt;00:01,  2.98it/s]"
          }
        },
        "e613e7bed71944f995c483815bb42c89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a983125976498bb2fcdc30cb0e2257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353fc554bb7b4a829504286d46b1fe24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5efbd3f84a734bc4bb084d4f2d7f58d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b14a8e7087124b119d19030c928a2cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d79478596ad4cd9bbedd3b55030b160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1c6c07e3e4c4027acda0af28b812faf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78b573b281214f2c99ca5f48a876da3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d66f2e315124856a3fa0905c069bc18",
              "IPY_MODEL_1a466b3d70ac43ab9c99d1b85943775b",
              "IPY_MODEL_ded68904b4014826b31ef2e2e0b714ae"
            ],
            "layout": "IPY_MODEL_15f994205742490eacf96a5bdba51393"
          }
        },
        "0d66f2e315124856a3fa0905c069bc18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c52f4212d7c74f41972fef066ee14df3",
            "placeholder": "​",
            "style": "IPY_MODEL_8b8e88d646d84ff0b7997ae1f70f25c8",
            "value": "Loading pipeline components...:  20%"
          }
        },
        "1a466b3d70ac43ab9c99d1b85943775b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df50fa45cd3e46c18020eb7dc6cce0ee",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_faed0cecd1544f5e8ad3ce2b27c4314f",
            "value": 1
          }
        },
        "ded68904b4014826b31ef2e2e0b714ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_291e39a2d6744667bcdae11425b0ddf7",
            "placeholder": "​",
            "style": "IPY_MODEL_b50dc1649de74c4aa9f493cd2d44f724",
            "value": " 1/5 [00:00&lt;00:00,  5.78it/s]"
          }
        },
        "15f994205742490eacf96a5bdba51393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c52f4212d7c74f41972fef066ee14df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b8e88d646d84ff0b7997ae1f70f25c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df50fa45cd3e46c18020eb7dc6cce0ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faed0cecd1544f5e8ad3ce2b27c4314f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "291e39a2d6744667bcdae11425b0ddf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b50dc1649de74c4aa9f493cd2d44f724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SinghDhruv1/email-backup-wizard-chatbot/blob/main/Untitled.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2b3e29d4d9de4263a6f5d939fe364759",
            "3935efda545f418e80c01bac4e5bf814",
            "d3809b6c66fd437d91f8614d67928123",
            "c9efc28814664aceb836823ed4aa8839",
            "fe87e186b1804a9d9ff3282d307b4253",
            "3d54ea6456474c86a9b6f10a59d0b7e5",
            "53f17586010f40e9a035a56407d0e199",
            "3059e3c1134b401fa5f41c008ea8eba8",
            "e63e9cbb9b11484ba7e423016e2b73db",
            "7109d79984e045caa5ffc57b2b16485d",
            "c2525ada1d4347199b4f033c0ae76749",
            "304169a128264d0d8a359b0b91c44704",
            "34727a27244249fc984ab9c3987ad003",
            "e654b1a7b4514671a8f881bec207392c",
            "c5814000423444938bf488d2c5ec6d33",
            "d3bac2e448cc44a7a7d95af8636774a6",
            "788ec4bc17d04fe5ba5c0fc71667a1f1",
            "5eafae5ff88d4d13b38b60fcd20f0614",
            "b50eb72064394c12903eea98d7f22dd8",
            "b74beb2365474415979c18b89deba013",
            "a86a684be2854268aca639b878f1c7b3",
            "c404e9b450284e4e8d55e26ebbd0fe4f",
            "9b0ea337b30341cfba409cc9f59e5fba",
            "cd7c712a8b8c48d29f7da6df32654ed0",
            "2923ed0e19a94b809a50800bbc548f2e",
            "30627ffc8aa54eecabe0b8155fe145ea",
            "2f88dcd8c32c470e84bf71b9edc141a0",
            "e92eca535b3644ddb5f173f574aba3ef",
            "03b38e56951f4c71a03c69fcc6562a07",
            "2c932eef64f84a1caa90213bc2f5d2ac",
            "780b67a1b9ee4427bb5df408b81913e9",
            "2b45ba7d2adc43579905ea0ea45a901a",
            "bb12e808d2de40de99402ffe691c83bb",
            "86e2650ba1cd45a8bf7f7ed5541b0def",
            "2ab85bccfe374019a97137c61e65e027",
            "01ffbb863fcb4db1b120959ca3a8f05f",
            "431e0654b83c479eb55ea48666c17daf",
            "528d0dac6ee9434cb5a5da361aef8b95",
            "2334881b039246f7b04d3a8f2e0bdcfd",
            "ab9d82c25a434d57bde0f7aea98ea80a",
            "b2f2f0c331514585b7cdda51185c2dba",
            "c4c62221bdef4f2baf9a8b712e517891",
            "a0496affc69f4c71a96f83a37537f24f",
            "e52e791316724e4991464777ad1da1be",
            "97f4f72e338f4e9e9b1a572133a7bca7",
            "ef3ccaf45c204cbcaad69043fe6a8d3e",
            "61e572d26e70484c92e0dab0ce3cbf61",
            "44f5b6ab060b4683ad5fa75259255abc",
            "016c286597ca447db67d3d36b0f01ba4",
            "478a7e64a977486bb893f6c1e0b127e8",
            "1873887d6c8f4d8a9bcbfbc65d7e1ac0",
            "6a90496f3115457593c4423d1aaab89a",
            "f81ce9998fb2408ab019d7200446d263",
            "7eaea8c1219a4efa849feb58c8a69cdc",
            "1e3881dd29b24089a92fc06044e31452",
            "937dae3add724cfcaf5b4d7209656d3d",
            "64bd07cf64b449adb5c2ffa8e2aaa126",
            "8dd681f4e2284fceb395ba33a9b7e69b",
            "f08d210c28cd44c084e2e886e0fe98ea",
            "1cb97607bece4ba5895476bb2e35854a",
            "ce09480c94984fff88f32c6b18914fc9",
            "af667af9d3a34d6eaf52ce00dd7c9ab7",
            "bc13c17b88c5492288cfc3c61ecac3a1",
            "3739d00bb07d40d19ca1eec6fe3de6e2",
            "2c6384ff7b4e4347a373381cc6f32588",
            "fd8704f779314f6ca38fa66101ff73eb",
            "0c6f07b77e3641d7afda2df5277bfc20",
            "a14fb5e5769c44158a6d82313336d2bd",
            "94cc78ab1846451daf9390ec587dce3f",
            "e9385687a5f14b0d925986cfb0b57773",
            "04031d0f8f2c4b24abd9c1bee701ef4a",
            "afe11f644a93490e88e4188b359c8513",
            "629b44e257cc4f709f99f6cb4eac8d20",
            "b291173baf984c35b66a97360fb7ce7e",
            "9b6965a6cc9d4d7eb959e5b7d469c478",
            "4e1c656dcf1d442a8cb2d7c1270c0660",
            "3426c60716e74df899faccb9cf237d49",
            "f05ba7367c474aee8e97979e58d4475c",
            "3c1feb4ab328439f894a63a886769c62",
            "774a14462ecd41f6bf771ac905a27b1d",
            "2eaa34a80b4049ccaa6bb9071321532b",
            "3557f96611f2441288d5b32b2562651a",
            "e5f44cdd4044459aa2bc5ca701e99bf3",
            "bc6cde5072ef4c43a4223fd22731d3bb",
            "f1a6c90e4d034439b03473d7ead42eb1",
            "9172b8709d884ed58743717239249da7",
            "950dd11a7902431d90c79586465b3584",
            "e6966f8e315247538b8b69da6f6b9d24",
            "be253b8e2e8b4646ba746b396eb2456c",
            "6017dbbdf57f43faa41cb9f675f0616a",
            "343cdad01b1b4b699236d581d544af59",
            "3c380cfc96cd47c8b4d41fc7c0e64093",
            "2b976c3aa20745fba6660d9650f06756",
            "d487e253b64049e5832c253e42a78fe8",
            "d28f11574f004c569b4534c2fbaeaca3",
            "012387807ea149d587fcba1ea85d4a33",
            "aebbdd90776246c099d9fb101028ca6b",
            "1036d7a75b7940429c197d5122a2b219",
            "53cbfe22dc0e476d98eca65ffee45079",
            "6b0284fc56bc405d81dc838934b4d0b6",
            "2c764457ce4c4580816ddeaf2621f726",
            "4960b2c958d146b8a3818bfe1e848ce6",
            "eed514a38f7e4fd2b804433a049b7297",
            "a994617a19a14695ada86c544dbbc5c8",
            "21eceab0087749478bd9c5057669df65",
            "7f58a18959c54e1c826ce0d89ed4e3b2",
            "8a6e9a9737b4478fbc4cea993de52540",
            "4c83851dca2341b5a4de2879c00238a0",
            "5331e73d98754640adc4ce1d41b2095d",
            "a77554ff9a844afa95f375302b8b3d82",
            "69dbae988b1f4fb8aeaa7394557aaa26",
            "3b289ef8bafe43df8e5fba7bb4a4da21",
            "eaeaa7573a9e45309a5512063f0bc575",
            "8dadef06d22341f4a1fa3e1ec860b307",
            "7cb3eb025db442cb8b35d30b5bcef189",
            "26a717e8265c404bbc0f3f02a03286fc",
            "89aca9a92ac646b89610a32ebb13c585",
            "4a2c60fc78df4f1f88fda5d50d4ec6f0",
            "afc3c6348ea7473ba8c71ae2ad4c6fe4",
            "ff93b7f91b0143b28d2f90e1a5772d3f",
            "2020fa4fc861468994c9d2dba4190ee1",
            "cf17c96ecc624a9fb758fcbd8fcc9aac",
            "c0a2610eb8d24eebb3ab0d12facf6f81",
            "17b248987f8a43e5a5c36d47c38127a5",
            "3e0e699a45eb47798eafc8756d8ef037",
            "1249159b95f249148817f661729bd63f",
            "065458c1d38e4c0f8b594bd318fe5ec6",
            "13563e9326374a0190f5ad89eb37eeb3",
            "4089a6ea47ce4cca91f7b94ea980cfda",
            "2d1e8473236e407bb3cc28052e07432e",
            "783afbb01bdc466da948c3d171390879",
            "8102702aee3e4f70b5008c9f007258ec",
            "1744cab7e03340dfa45d3301af0bb87f",
            "41bed656ba404d4d9b7f2ef331a43f4c",
            "7e566916ae444d53b28145d0a8e58fcc",
            "6308196b022f429ebcfff8194fecc068",
            "707d93c029744f4c97fbf958e3374bf7",
            "e86090975cde4c2cbdec298aea946096",
            "01651f9690e8453899c6dd7047e228fb",
            "baf94d1e991e47b2991794cbac03082c",
            "255e7e12d13c4fcc963e3a41b4afbdfc",
            "82ff7b63a3934743aca2bd1c7159e32e",
            "5a622136ae9242b39793d33c5c10e1e6",
            "847bdaff6708404a9b5f25dd43d764ca",
            "87de67aa17b248a8a4499c19dc71410a",
            "f3502b36f9ca4c77a904162f345406fb",
            "109860b4189a4f81be5e11df7c8686f7",
            "b1db95acc587477086f38ac60b0ad579",
            "799610901c454e4285378e34cf5d72ff",
            "759647d13af5434984bd5e2bb6c9a352",
            "59b35b358ca245ef90a4650136fd1e15",
            "57a106f05dfb430a9b91e8166e3210d3",
            "d5a07c457f39460bbf5c448831854db2",
            "e4b79dcd5d7a43f892e52665e279db14",
            "fdbc6750dd7c43a3888b244b0ceab98d",
            "7083e4233835405aa5209d1c7419b465",
            "97e2218b8cf04b3b86846009b8dacd34",
            "7f949eecb89742c7ab0cf473a6636e8d",
            "3ded1303bf6441b5abc159adeda939d5",
            "f764cb7aa91648719c246a23434dca40",
            "135d6b0e83ef4a2aa186c830d5293281",
            "cf4d6c79c72941d4b68ee9ebf0aee881",
            "9656b8e49fe14d98b23b2e9322269d3a",
            "c680b2def08f4e22b80dd596be107273",
            "f303b1437c4a4c799a832b8a399b7444",
            "038fa33a67b64fee91779b177533437b",
            "1338b57420c84318b3148785263528db",
            "b3bd745abf6b4504b3c45cc187e1f65a",
            "a5cffef83be840a6bcd8cfd27d760395",
            "b19d2d0333c94bc4a7853a88821f6512",
            "cc65fecf2c3d4f1ea860ed2583eaaf61",
            "0db9623155e74dd5a01a55d2de04f77f",
            "1a3d01ab7e7b4c52ab4b3f419b4fedb2",
            "ca2aebc441a64c66ab5a860771b654c7",
            "51d3f03cff3e44f1be6caf3e8a0eed19",
            "d91ea52ceaca416893942be362007ecf",
            "78404ab9aa0249adb5586c9fb30241cf",
            "4e2f63ae423f4160becfcdc0019ed743",
            "546a2982b6c540be812473d565668a64",
            "84c8e18b19b54df1b7d59818516470aa",
            "e7ad0c68586a45ac9f4376ac23249a64",
            "bed5496f5da44b94ab4452a8f7e8217e",
            "ae6fb7b14564444aae64e8c449b341d1",
            "56874decde5343c6ab05ae0069678947",
            "b52349715d9946d58b8f1a2a6da55de3",
            "208e696686224390becebb5166dc476d",
            "92b07ed010824ffcaf0394e26390f9a3",
            "27b21c4440d04ceebf2ecfec5236ee91",
            "14e3f1681e194001b11813a498533c44",
            "d99e372c09bb4051a27d0d59556e0ac3",
            "fb3633daa5344cf1bdc5ba7db48735c7",
            "17fc92f5677448168ffe172af95e2e49",
            "2c3ad52cccd2416ebe2e6939f1084081",
            "65bc40f9b7b14909a3d0d0cf81152b84",
            "e3ade838b46d46acab5f4b8ec51a272e",
            "f963d7fec4c54963b25a6661219e67ef",
            "6e429b37ec284d06b1591433155a9415",
            "62a6177336374062b18c606ada6d2e87",
            "82cc702de2f5492f97235608a3311ead",
            "1344c9e564944d5e96651aee61f633e0",
            "f307e1c5643c4db88457f8c80ecfd0e1",
            "0b63f39f8ef246c5aa00a9b94d6b4ad9",
            "e613e7bed71944f995c483815bb42c89",
            "98a983125976498bb2fcdc30cb0e2257",
            "353fc554bb7b4a829504286d46b1fe24",
            "5efbd3f84a734bc4bb084d4f2d7f58d9",
            "b14a8e7087124b119d19030c928a2cf9",
            "2d79478596ad4cd9bbedd3b55030b160",
            "a1c6c07e3e4c4027acda0af28b812faf"
          ]
        },
        "id": "6MqxYmKIIq6g",
        "outputId": "0266ad0f-aba7-4174-9ec6-00f4d023448b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Collecting decord\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (2.0.2)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (11.3.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (0.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (5.9.5)\n",
            "Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: decord\n",
            "Successfully installed decord-0.6.0\n",
            "Cloning into 'Kolors'...\n",
            "remote: Enumerating objects: 624, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 624 (delta 110), reused 91 (delta 91), pack-reused 478 (from 2)\u001b[K\n",
            "Receiving objects: 100% (624/624), 149.19 MiB | 40.79 MiB/s, done.\n",
            "Resolving deltas: 100% (273/273), done.\n",
            "/content/Kolors\n",
            "--2025-08-19 07:08:19--  https://huggingface.co/Kwai-Kolors/kolors/resolve/main/kolors-video-model.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /Kwai-Kolors/Kolors/resolve/main/kolors-video-model.safetensors [following]\n",
            "--2025-08-19 07:08:19--  https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/kolors-video-model.safetensors\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-08-19 07:08:19 ERROR 404: Not Found.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model_index.json:   0%|          | 0.00/427 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b3e29d4d9de4263a6f5d939fe364759"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A mixture of fp16 and non-fp16 filenames will be loaded.\n",
            "Loaded fp16 filenames:\n",
            "[vae/diffusion_pytorch_model.fp16.bin]\n",
            "Loaded non-fp16 filenames:\n",
            "[text_encoder/pytorch_model-00007-of-00007.bin, text_encoder/pytorch_model-00004-of-00007.bin, text_encoder/pytorch_model-00002-of-00007.bin, text_encoder/pytorch_model-00006-of-00007.bin, text_encoder/pytorch_model-00003-of-00007.bin, text_encoder/pytorch_model-00001-of-00007.bin, text_encoder/pytorch_model-00005-of-00007.bin, text_encoder/pytorch_model.bin.index.json\n",
            "If this behavior is not expected, please check your folder structure.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 18 files:   0%|          | 0/18 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "304169a128264d0d8a359b0b91c44704"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b0ea337b30341cfba409cc9f59e5fba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00003-of-00007.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86e2650ba1cd45a8bf7f7ed5541b0def"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00001-of-00007.bin:   0%|          | 0.00/1.83G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97f4f72e338f4e9e9b1a572133a7bca7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00002-of-00007.bin:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "937dae3add724cfcaf5b4d7209656d3d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00004-of-00007.bin:   0%|          | 0.00/1.82G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c6f07b77e3641d7afda2df5277bfc20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00006-of-00007.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f05ba7367c474aee8e97979e58d4475c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00005-of-00007.bin:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be253b8e2e8b4646ba746b396eb2456c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "scheduler_config.json:   0%|          | 0.00/606 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b0284fc56bc405d81dc838934b4d0b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model-00007-of-00007.bin:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69dbae988b1f4fb8aeaa7394557aaa26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin.index.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf17c96ecc624a9fb758fcbd8fcc9aac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenization_chatglm.py: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1744cab7e03340dfa45d3301af0bb87f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/1.02M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "847bdaff6708404a9b5f25dd43d764ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/249 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdbc6750dd7c43a3888b244b0ceab98d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "038fa33a67b64fee91779b177533437b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/611 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78404ab9aa0249adb5586c9fb30241cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "diffusion_pytorch_model.fp16.bin:   0%|          | 0.00/167M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27b21c4440d04ceebf2ecfec5236ee91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82cc702de2f5492f97235608a3311ead"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/vae: Error no file named diffusion_pytorch_model.fp16.safetensors found in directory /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/unet.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Error no file named diffusion_pytorch_model.bin found in directory /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/unet.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3797123068.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# 4. Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m pipe = DiffusionPipeline.from_pretrained(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;34m\"Kwai-Kolors/kolors\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                     \u001b[0;32melse\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                 )\n\u001b[0;32m-> 1022\u001b[0;31m                 loaded_sub_model = load_sub_model(\n\u001b[0m\u001b[1;32m   1023\u001b[0m                     \u001b[0mlibrary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrary_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                     \u001b[0mclass_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/pipeline_loading_utils.py\u001b[0m in \u001b[0;36mload_sub_model\u001b[0;34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder, use_safetensors, dduf_entries, provider_options, quantization_config)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mloaded_sub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloading_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         \u001b[0mloaded_sub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloading_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0;31m# else load from the root directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolved_model_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sharded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m                 resolved_model_file = _get_model_file(\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m                     \u001b[0mweights_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_add_variant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py\u001b[0m in \u001b[0;36m_get_model_file\u001b[0;34m(pretrained_model_name_or_path, weights_name, subfolder, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, dduf_entries)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;34mf\"Error no file named {weights_name} found in directory {pretrained_model_name_or_path}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             )\n",
            "\u001b[0;31mOSError\u001b[0m: Error no file named diffusion_pytorch_model.bin found in directory /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/unet."
          ]
        }
      ],
      "source": [
        "# ============================================\n",
        "# 🚀 Text-to-Video AI (30 seconds) with Kwai Kolors\n",
        "# Runs in Google Colab - No Watermark\n",
        "# ============================================\n",
        "\n",
        "# 1. Install dependencies\n",
        "!pip install torch torchvision torchaudio transformers accelerate safetensors\n",
        "!pip install imageio[ffmpeg] einops decord\n",
        "!git clone https://github.com/Kwai-Kolors/Kolors.git\n",
        "%cd Kolors\n",
        "\n",
        "# 2. Download pretrained model weights (first run may take time)\n",
        "!mkdir -p models\n",
        "!wget -O models/kolors-video-model.safetensors https://huggingface.co/Kwai-Kolors/kolors/resolve/main/kolors-video-model.safetensors\n",
        "\n",
        "# 3. Import libraries\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from diffusers import DiffusionPipeline\n",
        "\n",
        "# 4. Load model\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"Kwai-Kolors/kolors\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\"\n",
        ").to(\"cuda\")\n",
        "\n",
        "# 5. Define your text prompt\n",
        "prompt = \"A cinematic mobile fashion app demo video, showing smooth pastel UI animations, floating clothing icons, elegant transitions, upbeat modern style, vertical 9:16 format, 30 seconds\"\n",
        "negative_prompt = \"blurry, distorted, text errors, watermark, glitch\"\n",
        "\n",
        "# 6. Generate 30s video (30 fps x 30s = 900 frames)\n",
        "video_frames = pipe(\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_frames=900,   # ~30 seconds\n",
        "    guidance_scale=7.5,\n",
        "    height=512,\n",
        "    width=288  # vertical format 9:16\n",
        ").frames\n",
        "\n",
        "# 7. Save frames\n",
        "output_dir = Path(\"frames\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "import imageio\n",
        "\n",
        "for i, frame in enumerate(video_frames):\n",
        "    imageio.imwrite(output_dir / f\"frame_{i:04d}.png\", frame)\n",
        "\n",
        "# 8. Convert frames into MP4 video (30s, 30fps)\n",
        "!ffmpeg -y -framerate 30 -i frames/frame_%04d.png -c:v libx264 -pix_fmt yuv420p output.mp4\n",
        "\n",
        "print(\"✅ Done! 30-second AI-generated video saved as output.mp4 (no watermark)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================\n",
        "# 🚀 45s WahDrobe Cinematic Trailer with Voiceover & LipSync\n",
        "# ================================================\n",
        "\n",
        "# 1. Install dependencies\n",
        "import torch\n",
        "!pip install torch torchvision torchaudio transformers safetensors accelerate\n",
        "!pip install imageio[ffmpeg] einops decord\n",
        "!git clone https://github.com/Kwai-Kolors/Kolors.git\n",
        "!git clone https://github.com/Rudrabha/Wav2Lip.git\n",
        "!pip install TTS ffmpeg-python\n",
        "%cd Kolors\n",
        "\n",
        "# Download Kolors weights\n",
        "!mkdir -p models\n",
        "!wget -O models/kolors-video-model.safetensors https://huggingface.co/Kwai-Kolors/kolors/resolve/main/kolors-video-model.safetensors\n",
        "\n",
        "# 2. Define scene prompts (cinematic, 2K, 60fps)\n",
        "scenes = [\n",
        "    {\n",
        "        \"prompt\": \"Cinematic close-up of a frustrated young woman in stylish bedroom, messy closet full of clothes. Dramatic pastel lighting, fashion aesthetic. Character should be speaking with lip movement.\",\n",
        "        \"voiceover\": \"Tired of outfit decisions? What if AI could solve your daily style dilemma?\",\n",
        "        \"duration\": 180\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Epic smooth 3D phone animation. The WahDrobe logo glows in pink gradient. Floating icons 👗👠👜, cinematic lighting.\",\n",
        "        \"voiceover\": \"Meet WahDrobe — your AI fashion stylist!\",\n",
        "        \"duration\": 180\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Feature montage: Weather widget showing 34°C Delhi with sun animation. Outfit suggestion card: 'Classic White T-shirt + Blue Jeans + Sneakers'. Stylish rating overlay 'TOTAL SLAY! (71%)'. Wardrobe gallery glowing.\",\n",
        "        \"voiceover\": \"Smart recommendations based on weather, your wardrobe, and personal style!\",\n",
        "        \"duration\": 360\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Confident young woman walking in city in recommended outfit. Split-screen app glowing with: 'WHY YOU’LL LOVE THIS: THIS COMBO LOOKS AMAZING! 💕'.\",\n",
        "        \"voiceover\": \"Feel confident in every outfit choice!\",\n",
        "        \"duration\": 360\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Epic outro: Elegant gradient background, glowing 'Coming Soon' badge, App Store & Google Play icons floating, cinematic light sweep.\",\n",
        "        \"voiceover\": \"WahDrobe — Coming Soon. Get early access now!\",\n",
        "        \"duration\": 270\n",
        "    }\n",
        "]\n",
        "\n",
        "# 3. Generate scenes (video frames only, lip movement if character present)\n",
        "from diffusers import DiffusionPipeline\n",
        "import imageio, os\n",
        "from pathlib import Path\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"Kwai-Kolors/kolors\",\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "Path(\"frames\").mkdir(exist_ok=True)\n",
        "scene_videos = []\n",
        "\n",
        "for idx, scene in enumerate(scenes):\n",
        "    out_file = f\"scene_{idx+1}.mp4\"\n",
        "    result = pipe(\n",
        "        prompt=scene[\"prompt\"],\n",
        "        negative_prompt=\"blurry, watermark, distorted\",\n",
        "        num_frames=scene[\"duration\"],\n",
        "        guidance_scale=8,\n",
        "        height=2048, width=1080\n",
        "    )\n",
        "\n",
        "    scene_dir = Path(f\"frames/scene_{idx+1}\")\n",
        "    scene_dir.mkdir(exist_ok=True)\n",
        "    for i, frame in enumerate(result.frames):\n",
        "        imageio.imwrite(scene_dir / f\"frame_{i:04d}.png\", frame)\n",
        "\n",
        "    os.system(f\"ffmpeg -y -framerate 60 -i {scene_dir}/frame_%04d.png -c:v libx264 -pix_fmt yuv420p -crf 15 {out_file}\")\n",
        "    scene_videos.append(out_file)\n",
        "\n",
        "# 4. Generate voiceovers (Coqui TTS)\n",
        "from TTS.api import TTS\n",
        "tts = TTS(\"tts_models/en/ljspeech/tacotron2-DDC\")  # female English voice\n",
        "\n",
        "for idx, scene in enumerate(scenes):\n",
        "    audio_file = f\"voice_{idx+1}.wav\"\n",
        "    tts.tts_to_file(text=scene[\"voiceover\"], file_path=audio_file)\n",
        "\n",
        "# 5. Lip-sync videos (Wav2Lip)\n",
        "%cd ../Wav2Lip\n",
        "!gdown --id 1lw3T0uf7hvzGvO7OpoyZ4P6G8Fqi6r3l -O Wav2Lip.pth  # pretrained weights\n",
        "\n",
        "for idx in range(len(scenes)):\n",
        "    os.system(f\"python inference.py --checkpoint_path Wav2Lip.pth --face ../Kolors/scene_{idx+1}.mp4 --audio ../Kolors/voice_{idx+1}.wav --outfile synced_{idx+1}.mp4\")\n",
        "\n",
        "# 6. Concatenate all scenes into final trailer\n",
        "with open(\"inputs.txt\", \"w\") as f:\n",
        "    for idx in range(len(scenes)):\n",
        "        f.write(f\"file 'synced_{idx+1}.mp4'\\n\")\n",
        "\n",
        "!ffmpeg -y -f concat -safe 0 -i inputs.txt -c copy wahdrobe_trailer_final.mp4\n",
        "\n",
        "print(\"✅ Final Trailer Ready: wahdrobe_trailer_final.mp4 (60fps, 2K, Voiceover, Lip-Sync)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "78b573b281214f2c99ca5f48a876da3b",
            "0d66f2e315124856a3fa0905c069bc18",
            "1a466b3d70ac43ab9c99d1b85943775b",
            "ded68904b4014826b31ef2e2e0b714ae",
            "15f994205742490eacf96a5bdba51393",
            "c52f4212d7c74f41972fef066ee14df3",
            "8b8e88d646d84ff0b7997ae1f70f25c8",
            "df50fa45cd3e46c18020eb7dc6cce0ee",
            "faed0cecd1544f5e8ad3ce2b27c4314f",
            "291e39a2d6744667bcdae11425b0ddf7",
            "b50dc1649de74c4aa9f493cd2d44f724"
          ]
        },
        "id": "UikpRDKAKpLe",
        "outputId": "fd1e3a4a-e752-4a49-dc07-41be193556f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.6.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (11.3.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (0.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (5.9.5)\n",
            "Cloning into 'Kolors'...\n",
            "remote: Enumerating objects: 624, done.\u001b[K\n",
            "remote: Counting objects: 100% (146/146), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 624 (delta 110), reused 91 (delta 91), pack-reused 478 (from 2)\u001b[K\n",
            "Receiving objects: 100% (624/624), 149.19 MiB | 39.11 MiB/s, done.\n",
            "Resolving deltas: 100% (273/273), done.\n",
            "Cloning into 'Wav2Lip'...\n",
            "remote: Enumerating objects: 409, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 409 (delta 1), reused 0 (delta 0), pack-reused 406 (from 4)\u001b[K\n",
            "Receiving objects: 100% (409/409), 549.81 KiB | 9.01 MiB/s, done.\n",
            "Resolving deltas: 100% (226/226), done.\n",
            "Requirement already satisfied: TTS in /usr/local/lib/python3.11/dist-packages (0.22.0)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.0.12)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.16.1)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from TTS) (2.6.0+cu124)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.13.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.11.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.6.1)\n",
            "Requirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (7.5.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.67.1)\n",
            "Requirement already satisfied: anyascii>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.3.3)\n",
            "Requirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.12.15)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (25.0)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.1.1)\n",
            "Requirement already satisfied: pysbd>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.3.4)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.5.9.post2)\n",
            "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (3.10.0)\n",
            "Requirement already satisfied: trainer>=0.0.32 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.36)\n",
            "Requirement already satisfied: coqpit>=0.0.16 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.17)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.11/dist-packages (from TTS) (0.42.1)\n",
            "Requirement already satisfied: pypinyin in /usr/local/lib/python3.11/dist-packages (from TTS) (0.55.0)\n",
            "Requirement already satisfied: hangul-romanize in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.0)\n",
            "Requirement already satisfied: gruut==2.2.3 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.2.3)\n",
            "Requirement already satisfied: jamo in /usr/local/lib/python3.11/dist-packages (from TTS) (0.4.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from TTS) (3.9.1)\n",
            "Requirement already satisfied: g2pkk>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.2)\n",
            "Requirement already satisfied: bangla in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.5)\n",
            "Requirement already satisfied: bnnumerizer in /usr/local/lib/python3.11/dist-packages (from TTS) (0.0.2)\n",
            "Requirement already satisfied: bnunicodenormalizer in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.7)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.8.1)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (4.55.2)\n",
            "Requirement already satisfied: encodec>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.1.1)\n",
            "Requirement already satisfied: unidecode>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.4.0)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.11/dist-packages (from TTS) (0.5.14)\n",
            "Requirement already satisfied: spacy>=3 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (3.8.7)\n",
            "Requirement already satisfied: numpy>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from TTS) (1.26.4)\n",
            "Requirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.11/dist-packages (from TTS) (0.60.0)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.17.0)\n",
            "Requirement already satisfied: dateparser~=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.1.8)\n",
            "Requirement already satisfied: gruut-ipa<1.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.13.0)\n",
            "Requirement already satisfied: gruut-lang-en~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.0.1)\n",
            "Requirement already satisfied: jsonlines~=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.2.0)\n",
            "Requirement already satisfied: networkx<3.0.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (2.8.8)\n",
            "Requirement already satisfied: python-crfsuite~=0.9.7 in /usr/local/lib/python3.11/dist-packages (from gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (0.9.11)\n",
            "Requirement already satisfied: gruut-lang-de~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-es~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.1)\n",
            "Requirement already satisfied: gruut-lang-fr~=2.0.0 in /usr/local/lib/python3.11/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.0.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.8.1->TTS) (1.20.1)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask>=2.0.1->TTS) (3.1.3)\n",
            "Requirement already satisfied: more_itertools>=8.5.0 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (10.7.0)\n",
            "Requirement already satisfied: typeguard>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from inflect>=5.6.0->TTS) (4.4.4)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (4.14.1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10.0->TTS) (1.1.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.7.0->TTS) (2.9.0.post0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from num2words->TTS) (0.6.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57.0->TTS) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.0,>=1.4->TTS) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.0->TTS) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.0->TTS) (1.17.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (0.16.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (2.11.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=3->spacy[ja]>=3->TTS) (3.5.0)\n",
            "Requirement already satisfied: sudachipy!=0.6.1,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (0.6.10)\n",
            "Requirement already satisfied: sudachidict_core>=20211220 in /usr/local/lib/python3.11/dist-packages (from spacy[ja]>=3->TTS) (20250515)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.18.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1->TTS) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1->TTS) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from trainer>=0.0.32->TTS) (2.19.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.34.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.33.0->TTS) (0.6.2)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.1->TTS) (0.5.13)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.22)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from dateparser~=1.1.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (5.3.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers>=4.33.0->TTS) (1.1.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from jsonlines~=1.2.0->gruut==2.2.3->gruut[de,es,fr]==2.2.3->TTS) (1.17.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10.0->TTS) (4.3.8)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=3->spacy[ja]>=3->TTS) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=3->spacy[ja]>=3->TTS) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=3->spacy[ja]>=3->TTS) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (0.21.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (7.3.0.post1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.74.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.8.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (5.29.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=3->spacy[ja]>=3->TTS) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=3->spacy[ja]>=3->TTS) (1.17.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=3->spacy[ja]>=3->TTS) (0.1.2)\n",
            "/content/Kolors/Kolors/Kolors/Kolors/Kolors\n",
            "--2025-08-19 07:19:36--  https://huggingface.co/Kwai-Kolors/kolors/resolve/main/kolors-video-model.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.16, 18.239.50.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /Kwai-Kolors/Kolors/resolve/main/kolors-video-model.safetensors [following]\n",
            "--2025-08-19 07:19:36--  https://huggingface.co/Kwai-Kolors/Kolors/resolve/main/kolors-video-model.safetensors\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-08-19 07:19:36 ERROR 404: Not Found.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A mixture of fp16 and non-fp16 filenames will be loaded.\n",
            "Loaded fp16 filenames:\n",
            "[vae/diffusion_pytorch_model.fp16.bin]\n",
            "Loaded non-fp16 filenames:\n",
            "[text_encoder/pytorch_model-00002-of-00007.bin, text_encoder/pytorch_model-00005-of-00007.bin, text_encoder/pytorch_model-00003-of-00007.bin, text_encoder/pytorch_model-00007-of-00007.bin, text_encoder/pytorch_model-00006-of-00007.bin, text_encoder/pytorch_model-00004-of-00007.bin, text_encoder/pytorch_model-00001-of-00007.bin, text_encoder/pytorch_model.bin.index.json\n",
            "If this behavior is not expected, please check your folder structure.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78b573b281214f2c99ca5f48a876da3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/vae: Error no file named diffusion_pytorch_model.fp16.safetensors found in directory /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/vae.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n",
            "An error occurred while trying to fetch /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/unet: Error no file named diffusion_pytorch_model.safetensors found in directory /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/unet.\n",
            "Defaulting to unsafe serialization. Pass `allow_pickle=False` to raise an error instead.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Error no file named diffusion_pytorch_model.bin found in directory /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/unet.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1493378303.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m pipe = DiffusionPipeline.from_pretrained(\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;34m\"Kwai-Kolors/kolors\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                     \u001b[0;32melse\u001b[0m \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m                 )\n\u001b[0;32m-> 1022\u001b[0;31m                 loaded_sub_model = load_sub_model(\n\u001b[0m\u001b[1;32m   1023\u001b[0m                     \u001b[0mlibrary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrary_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m                     \u001b[0mclass_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/pipeline_loading_utils.py\u001b[0m in \u001b[0;36mload_sub_model\u001b[0;34m(library_name, class_name, importable_classes, pipelines, is_pipeline_module, pipeline_class, torch_dtype, provider, sess_options, device_map, max_memory, offload_folder, offload_state_dict, model_variants, name, from_flax, variant, low_cpu_mem_usage, cached_folder, use_safetensors, dduf_entries, provider_options, quantization_config)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0mloaded_sub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloading_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 830\u001b[0;31m         \u001b[0mloaded_sub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloading_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    831\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0;31m# else load from the root directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresolved_model_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sharded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m                 resolved_model_file = _get_model_file(\n\u001b[0m\u001b[1;32m   1178\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m                     \u001b[0mweights_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_add_variant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariant\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/utils/hub_utils.py\u001b[0m in \u001b[0;36m_get_model_file\u001b[0;34m(pretrained_model_name_or_path, weights_name, subfolder, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, dduf_entries)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;34mf\"Error no file named {weights_name} found in directory {pretrained_model_name_or_path}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             )\n",
            "\u001b[0;31mOSError\u001b[0m: Error no file named diffusion_pytorch_model.bin found in directory /root/.cache/huggingface/hub/models--Kwai-Kolors--kolors/snapshots/59e638b67119d3b8e74c3f4905c6572deb4dbfbc/unet."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# 1. Setup - Install dependencies\n",
        "# ===============================\n",
        "!pip install -q diffusers transformers accelerate safetensors xformers imageio ffmpeg-python\n",
        "\n",
        "import torch\n",
        "from diffusers import DiffusionPipeline\n",
        "import imageio, os\n",
        "from pathlib import Path\n",
        "\n",
        "# ===============================\n",
        "# 2. Load Wan2.2-TI2V-5B model\n",
        "# ===============================\n",
        "model_id = \"Wan-AI/Wan2.2-TI2V-5B\"\n",
        "\n",
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float16,\n",
        "    variant=\"fp16\", # Re-adding variant as it was in the original code and might be needed\n",
        "    use_safetensors=True # Explicitly use safetensors\n",
        ").to(\"cuda\")\n",
        "\n",
        "# ===============================\n",
        "# 3. Define your scenes\n",
        "# ===============================\n",
        "scenes = [\n",
        "    {\n",
        "        \"prompt\": \"Close-up of a frustrated young person staring at a messy closet full of clothes, cinematic lighting, fashion photography aesthetic\",\n",
        "        \"duration\": 60  # ~2.5 seconds at 24fps\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Smooth animation of a modern phone mockup with the WahDrobe logo glowing in pink gradient, premium fashion app aesthetic, soft pastel background\",\n",
        "        \"duration\": 60\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Montage: Weather widget showing 34°C Delhi, app recommending outfit: White T-Shirt + Blue Jeans + Sneakers, rating overlay 'TOTAL SLAY! (71%)' with heart emojis\",\n",
        "        \"duration\": 72  # ~3 sec\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Split screen: Left side shows person confidently walking out in outfit, Right side shows phone with text: WHY YOU’LL LOVE THIS: THIS COMBO LOOKS AMAZING! 💕\",\n",
        "        \"duration\": 72\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Elegant cinematic outro with floating fashion icons (👗👔👠👜), soft pastel background, 'Coming Soon' badge with App Store & Google Play icons\",\n",
        "        \"duration\": 72\n",
        "    }\n",
        "]\n",
        "\n",
        "Path(\"frames\").mkdir(exist_ok=True)\n",
        "scene_videos = []\n",
        "\n",
        "# ===============================\n",
        "# 4. Generate video for each scene\n",
        "# ===============================\n",
        "for idx, scene in enumerate(scenes):\n",
        "    print(f\"🎬 Generating Scene {idx+1} ...\")\n",
        "    out_file = f\"scene_{idx+1}.mp4\"\n",
        "    result = pipe(\n",
        "        prompt=scene[\"prompt\"],\n",
        "        num_frames=scene[\"duration\"],   # frames\n",
        "        guidance_scale=7,\n",
        "        height=720, width=1280          # 720p video\n",
        "    )\n",
        "\n",
        "    # Access frames from the first element of the list using integer indexing\n",
        "    video_frames = result[0]\n",
        "\n",
        "    # Save frames to directory\n",
        "    scene_dir = Path(f\"frames/scene_{idx+1}\")\n",
        "    scene_dir.mkdir(exist_ok=True)\n",
        "    for i, frame in enumerate(video_frames):\n",
        "        imageio.imwrite(scene_dir / f\"frame_{i:04d}.png\", frame)\n",
        "\n",
        "    # Convert frames to video\n",
        "    os.system(f\"ffmpeg -y -framerate 24 -i {scene_dir}/frame_%04d.png -c:v libx264 -pix_fmt yuv420p -crf 15 {out_file}\")\n",
        "    scene_videos.append(out_file)\n",
        "\n",
        "# ===============================\n",
        "# 5. Merge all scenes into final trailer\n",
        "# ===============================\n",
        "with open(\"inputs.txt\", \"w\") as f:\n",
        "    for v in scene_videos:\n",
        "        f.write(f\"file '{v}'\\n\")\n",
        "\n",
        "os.system(\"ffmpeg -y -f concat -safe 0 -i inputs.txt -c copy final_trailer.mp4\")\n",
        "\n",
        "print(\"✅ Video generation complete! Check final_trailer.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "jLbV3WvuNBF0",
        "outputId": "1dec2be1-1f98-43f2-f0ae-8ac5ed41fe65"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "EntryNotFoundError",
          "evalue": "404 Client Error. (Request ID: Root=1-68a4283f-495a436123a06ba15046d44c;b5b3ab0d-f97b-4323-977b-7dd1709a47b3)\n\nEntry Not Found for url: https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B/resolve/main/model_index.json.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B/resolve/main/model_index.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3333342140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Wan-AI/Wan2.2-TI2V-5B\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m pipe = DiffusionPipeline.from_pretrained(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    831\u001b[0m                     \u001b[0;34m\" is neither a valid local path nor a valid repo id. Please check the parameter.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 )\n\u001b[0;32m--> 833\u001b[0;31m             cached_folder = cls.download(\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                 \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/pipelines/pipeline_utils.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(cls, pretrained_model_name, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m             config_file = hf_hub_download(\n\u001b[0m\u001b[1;32m   1486\u001b[0m                 \u001b[0mpretrained_model_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m                 \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1008\u001b[0m         )\n\u001b[1;32m   1009\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1011\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1071\u001b[0m     \u001b[0;31m# Try to get metadata (etag, commit_hash, url, size) from the server.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0;31m# If we can't, a HEAD request error is returned.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1073\u001b[0;31m     (url_to_download, etag, commit_hash, expected_size, xet_file_data, head_call_error) = _get_metadata_or_catch_error(\n\u001b[0m\u001b[1;32m   1074\u001b[0m         \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1545\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1546\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1547\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers, endpoint)\u001b[0m\n\u001b[1;32m   1461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1463\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1464\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;31m# Recursively follow relative redirects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_backoff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_exceptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_on_status_codes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m429\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EntryNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{response.status_code} Client Error.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"Entry Not Found for url: {response.url}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEntryNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GatedRepo\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-68a4283f-495a436123a06ba15046d44c;b5b3ab0d-f97b-4323-977b-7dd1709a47b3)\n\nEntry Not Found for url: https://huggingface.co/Wan-AI/Wan2.2-TI2V-5B/resolve/main/model_index.json."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# WahDrobe Video Trailer Generator using Wan2.2-TI2V-5B\n",
        "# ===============================\n",
        "\n",
        "# ===============================\n",
        "# 1. Setup - Install dependencies and clone repository\n",
        "# ===============================\n",
        "\n",
        "# Clone the Wan2.2 repository\n",
        "!git clone https://github.com/Wan-Video/Wan2.2.git\n",
        "%cd Wan2.2\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "!pip install imageio ffmpeg-python\n",
        "\n",
        "# ===============================\n",
        "# 2. Download the Wan2.2-TI2V-5B model\n",
        "# ===============================\n",
        "\n",
        "# Download using huggingface-cli (recommended)\n",
        "!pip install \"huggingface_hub[cli]\"\n",
        "!huggingface-cli download Wan-AI/Wan2.2-TI2V-5B --local-dir ./Wan2.2-TI2V-5B\n",
        "\n",
        "# Alternative: Download using modelscope-cli\n",
        "# !pip install modelscope\n",
        "# !modelscope download Wan-AI/Wan2.2-TI2V-5B --local_dir ./Wan2.2-TI2V-5B\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# ===============================\n",
        "# 3. Define your scenes for WahDrobe trailer\n",
        "# ===============================\n",
        "scenes = [\n",
        "    {\n",
        "        \"prompt\": \"Close-up of a frustrated young person staring at a messy closet full of clothes, cinematic lighting, fashion photography aesthetic, high quality\",\n",
        "        \"output\": \"scene_1_closet_problem.mp4\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Smooth animation of a modern smartphone mockup with WahDrobe app logo glowing in pink gradient, premium fashion app aesthetic, soft pastel background, high quality\",\n",
        "        \"output\": \"scene_2_app_intro.mp4\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Weather widget showing 34 degrees Celsius Delhi, fashion app recommending outfit white t-shirt blue jeans sneakers, rating overlay showing excellent match, high quality\",\n",
        "        \"output\": \"scene_3_weather_outfit.mp4\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Split screen showing confident person walking in stylish recommended outfit, smartphone displaying positive fashion feedback with heart emojis, high quality cinematic\",\n",
        "        \"output\": \"scene_4_confident_walk.mp4\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Elegant cinematic outro with floating fashion icons dress shirt shoes handbag, soft pastel background, Coming Soon text with app store download badges, high quality\",\n",
        "        \"output\": \"scene_5_outro.mp4\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Create output directory\n",
        "Path(\"wahdrobe_scenes\").mkdir(exist_ok=True)\n",
        "scene_videos = []\n",
        "\n",
        "# ===============================\n",
        "# 4. Generate videos using Wan2.2-TI2V-5B\n",
        "# ===============================\n",
        "\n",
        "print(\"🎬 Starting WahDrobe trailer generation...\")\n",
        "\n",
        "for idx, scene in enumerate(scenes):\n",
        "    print(f\"\\n🎥 Generating Scene {idx+1}: {scene['prompt'][:60]}...\")\n",
        "\n",
        "    output_path = f\"wahdrobe_scenes/{scene['output']}\"\n",
        "\n",
        "    # Construct the generation command for Wan2.2\n",
        "    cmd = [\n",
        "        \"python\", \"generate.py\",\n",
        "        \"--task\", \"ti2v-5B\",\n",
        "        \"--size\", \"1280*704\",  # 720P resolution as specified in docs\n",
        "        \"--ckpt_dir\", \"./Wan2.2-TI2V-5B\",\n",
        "        \"--offload_model\", \"True\",  # For consumer GPU compatibility\n",
        "        \"--convert_model_dtype\",    # Optimize memory usage\n",
        "        \"--t5_cpu\",                # Move T5 to CPU to save GPU memory\n",
        "        \"--prompt\", scene[\"prompt\"],\n",
        "        \"--output_dir\", \"wahdrobe_scenes\",\n",
        "        \"--output_name\", f\"scene_{idx+1}\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        # Run the generation command\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)  # 10 min timeout\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"✅ Scene {idx+1} generated successfully!\")\n",
        "            scene_videos.append(output_path)\n",
        "        else:\n",
        "            print(f\"❌ Error generating Scene {idx+1}:\")\n",
        "            print(f\"Error: {result.stderr}\")\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"⏰ Scene {idx+1} generation timed out (10 minutes)\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Unexpected error in Scene {idx+1}: {str(e)}\")\n",
        "\n",
        "# ===============================\n",
        "# 5. Merge scenes into final trailer\n",
        "# ===============================\n",
        "\n",
        "if scene_videos:\n",
        "    print(f\"\\n🎞️ Merging {len(scene_videos)} scenes into final trailer...\")\n",
        "\n",
        "    # Create input file list for ffmpeg\n",
        "    with open(\"wahdrobe_scenes/inputs.txt\", \"w\") as f:\n",
        "        for video in scene_videos:\n",
        "            if os.path.exists(video):\n",
        "                f.write(f\"file '{os.path.basename(video)}'\\n\")\n",
        "\n",
        "    # Merge videos using ffmpeg\n",
        "    merge_cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-f\", \"concat\",\n",
        "        \"-safe\", \"0\",\n",
        "        \"-i\", \"wahdrobe_scenes/inputs.txt\",\n",
        "        \"-c\", \"copy\",\n",
        "        \"final_wahdrobe_trailer.mp4\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        subprocess.run(merge_cmd, check=True, cwd=\"wahdrobe_scenes\")\n",
        "        print(\"✅ Final WahDrobe trailer created: final_wahdrobe_trailer.mp4\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"❌ Error merging videos: {e}\")\n",
        "\n",
        "else:\n",
        "    print(\"❌ No scenes were successfully generated\")\n",
        "\n",
        "print(f\"\\n🎉 Generation complete! Check the wahdrobe_scenes folder for individual scenes\")\n",
        "print(\"📁 Final trailer: final_wahdrobe_trailer.mp4\")\n",
        "\n",
        "# ===============================\n",
        "# 6. Alternative: Single scene generation example\n",
        "# ===============================\n",
        "\n",
        "print(\"\\n💡 To generate a single scene manually, use:\")\n",
        "print(\"python generate.py --task ti2v-5B --size 1280*704 --ckpt_dir ./Wan2.2-TI2V-5B --offload_model True --convert_model_dtype --t5_cpu --prompt 'Your prompt here'\")\n",
        "\n",
        "# ===============================\n",
        "# 7. System Requirements Note\n",
        "# ===============================\n",
        "\n",
        "print(f\"\"\"\n",
        "📋 System Requirements for Wan2.2-TI2V-5B:\n",
        "• GPU: RTX 4090 (24GB VRAM) or better\n",
        "• With optimizations (--offload_model, --convert_model_dtype, --t5_cpu)\n",
        "• Generates 720P videos at 24fps\n",
        "• ~9 minutes for 5-second video on single consumer GPU\n",
        "\n",
        "🚀 For faster generation:\n",
        "• Use 80GB VRAM GPU and remove optimization flags\n",
        "• Use multi-GPU setup with: torchrun --nproc_per_node=8 generate.py ...\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "9rmoDLx0P89D",
        "outputId": "044ce511-dea7-4ab9-8bf6-aaaabb94cd55"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wan2.2'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 109 (delta 38), reused 31 (delta 31), pack-reused 54 (from 1)\u001b[K\n",
            "Receiving objects: 100% (109/109), 1.48 MiB | 7.27 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.8.0)\n",
            "Requirement already satisfied: torchvision>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.12.0.88)\n",
            "Requirement already satisfied: diffusers>=0.31.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.34.0)\n",
            "Requirement already satisfied: transformers>=4.49.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.55.2)\n",
            "Requirement already satisfied: tokenizers>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.21.4)\n",
            "Requirement already satisfied: accelerate>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.13)\n",
            "Collecting ftfy (from -r requirements.txt (line 11))\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting dashscope (from -r requirements.txt (line 12))\n",
            "  Downloading dashscope-1.24.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.6.0)\n",
            "Collecting flash_attn (from -r requirements.txt (line 14))\n",
            "  Downloading flash_attn-2.8.3.tar.gz (8.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (1.26.4)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.37.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch>=2.4.0->-r requirements.txt (line 1)) (75.2.0)\n",
            "Collecting torch>=2.4.0 (from -r requirements.txt (line 1))\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.19.0->-r requirements.txt (line 2)) (11.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.10.2.21->torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.3.90->torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.3.83->torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch>=2.4.0->-r requirements.txt (line 1))\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of opencv-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-python>=4.9.0.80 (from -r requirements.txt (line 3))\n",
            "  Downloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (8.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (0.34.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.1.1->-r requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->-r requirements.txt (line 11)) (0.2.13)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from dashscope->-r requirements.txt (line 12)) (3.12.15)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from dashscope->-r requirements.txt (line 12)) (1.8.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from dashscope->-r requirements.txt (line 12)) (43.0.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash_attn->-r requirements.txt (line 14)) (0.8.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers>=0.31.0->-r requirements.txt (line 4)) (1.1.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (1.20.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->dashscope->-r requirements.txt (line 12)) (1.17.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers>=0.31.0->-r requirements.txt (line 4)) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.31.0->-r requirements.txt (line 4)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.31.0->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.31.0->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.31.0->-r requirements.txt (line 4)) (2025.8.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->dashscope->-r requirements.txt (line 12)) (2.22)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m278.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dashscope-1.24.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: flash_attn\n",
            "  Building wheel for flash_attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash_attn: filename=flash_attn-2.8.3-cp311-cp311-linux_x86_64.whl size=256043372 sha256=3d41b2fc55753faa7f45d6568ea73a96b96afb48b82994ab9b49bcbcb6c87588\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/31/1f/4b22dd7295b3cb064b8fa9038f6d58fb15c9571555b2d7c39c\n",
            "Successfully built flash_attn\n",
            "Installing collected packages: triton, nvidia-cusparselt-cu12, sympy, opencv-python, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, dashscope, torch, flash_attn\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.7.1\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.7.1:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.7.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.12.0.88\n",
            "    Uninstalling opencv-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-4.12.0.88\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0\n",
            "    Uninstalling torch-2.8.0:\n",
            "      Successfully uninstalled torch-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.32.post2 requires torch==2.8.0, but you have torch 2.6.0 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dashscope-1.24.1 flash_attn-2.8.3 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 opencv-python-4.11.0.86 sympy-1.13.1 torch-2.6.0 triton-3.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2",
                  "nvidia",
                  "sympy",
                  "torch",
                  "torchgen",
                  "triton"
                ]
              },
              "id": "8b3d359f080540b9b286e98d52affa33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  87% 2.44G/2.82G [00:57<00:07, 53.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  24% 2.34G/9.83G [00:56<01:59, 62.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.46G/11.4G [00:56<02:19, 63.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.47G/10.0G [00:57<01:59, 62.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  24% 2.35G/9.83G [00:57<02:01, 61.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  87% 2.45G/2.82G [00:57<00:07, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.47G/11.4G [00:56<02:25, 60.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.49G/10.0G [00:57<02:00, 62.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  24% 2.36G/9.83G [00:57<01:56, 64.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  87% 2.46G/2.82G [00:57<00:06, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.49G/11.4G [00:56<02:23, 61.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  24% 2.37G/9.83G [00:57<01:49, 68.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.50G/10.0G [00:57<02:12, 56.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  88% 2.47G/2.82G [00:57<00:06, 53.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.50G/11.4G [00:57<02:33, 57.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  24% 2.38G/9.83G [00:57<02:00, 61.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.51G/10.0G [00:57<02:07, 58.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  88% 2.49G/2.82G [00:57<00:06, 52.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.51G/11.4G [00:57<02:34, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  24% 2.39G/9.83G [00:57<02:02, 60.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.53G/10.0G [00:57<01:41, 73.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  89% 2.50G/2.82G [00:58<00:05, 58.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.52G/11.4G [00:57<02:15, 65.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  24% 2.40G/9.83G [00:57<02:00, 61.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.54G/10.0G [00:57<01:40, 74.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  89% 2.51G/2.82G [00:58<00:04, 63.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.53G/11.4G [00:57<02:10, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.41G/9.83G [00:58<01:54, 64.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  25% 2.55G/10.0G [00:58<01:40, 74.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  89% 2.52G/2.82G [00:58<00:04, 66.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.54G/11.4G [00:57<01:59, 73.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.42G/9.83G [00:58<01:51, 66.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  90% 2.53G/2.82G [00:58<00:04, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.56G/10.0G [00:58<01:40, 73.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  22% 2.55G/11.4G [00:57<02:01, 72.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.43G/9.83G [00:58<01:40, 73.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.56G/11.4G [00:58<03:09, 46.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.57G/10.0G [00:58<02:40, 46.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.44G/9.83G [00:59<04:11, 29.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  90% 2.55G/2.82G [01:00<00:12, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.58G/10.0G [01:03<18:27, 6.70MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.45G/9.83G [01:03<18:44, 6.56MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.47G/9.83G [01:03<10:26, 11.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.60G/10.0G [01:03<10:42, 11.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  91% 2.56G/2.82G [01:04<00:33, 7.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.57G/11.4G [01:03<24:01, 6.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.49G/9.83G [01:03<08:14, 14.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.61G/10.0G [01:04<08:24, 14.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.58G/11.4G [01:03<17:25, 8.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  91% 2.57G/2.82G [01:04<00:24, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  25% 2.50G/9.83G [01:04<06:30, 18.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.62G/10.0G [01:04<06:51, 17.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.59G/11.4G [01:03<13:00, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.51G/9.83G [01:04<05:13, 23.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  92% 2.58G/2.82G [01:04<00:18, 12.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.63G/10.0G [01:04<05:32, 22.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.60G/11.4G [01:03<09:40, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.52G/9.83G [01:04<04:21, 28.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  26% 2.64G/10.0G [01:04<04:24, 27.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  92% 2.59G/2.82G [01:04<00:14, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.61G/11.4G [01:03<07:25, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.53G/9.83G [01:04<03:38, 33.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.65G/10.0G [01:04<03:42, 33.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.62G/11.4G [01:04<05:39, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  92% 2.60G/2.82G [01:04<00:10, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.54G/9.83G [01:04<02:56, 41.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.66G/10.0G [01:04<03:04, 39.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.63G/11.4G [01:04<04:29, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  93% 2.61G/2.82G [01:05<00:07, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.55G/9.83G [01:04<02:33, 47.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.67G/10.0G [01:04<02:30, 48.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.64G/11.4G [01:04<03:40, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  93% 2.62G/2.82G [01:05<00:06, 32.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.65G/11.4G [01:04<03:10, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.57G/9.83G [01:05<01:58, 61.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  93% 2.63G/2.82G [01:05<00:04, 38.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.68G/10.0G [01:05<02:53, 42.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  23% 2.66G/11.4G [01:04<03:05, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  94% 2.64G/2.82G [01:05<00:04, 41.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.58G/9.83G [01:05<02:07, 56.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.69G/10.0G [01:05<02:27, 49.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  94% 2.65G/2.82G [01:05<00:03, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.71G/10.0G [01:05<02:12, 55.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.59G/9.83G [01:05<02:06, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.68G/11.4G [01:04<02:21, 61.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  94% 2.66G/2.82G [01:05<00:02, 54.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.72G/10.0G [01:05<02:03, 59.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  26% 2.60G/9.83G [01:05<01:59, 60.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.69G/11.4G [01:05<02:21, 61.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  95% 2.67G/2.82G [01:05<00:02, 61.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.73G/10.0G [01:05<01:53, 64.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.71G/11.4G [01:05<02:09, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.61G/9.83G [01:05<01:50, 65.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  95% 2.68G/2.82G [01:05<00:02, 67.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.74G/10.0G [01:05<01:54, 63.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  96% 2.69G/2.82G [01:06<00:01, 72.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.62G/9.83G [01:05<01:55, 62.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.72G/11.4G [01:05<02:18, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  27% 2.75G/10.0G [01:06<01:42, 70.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.63G/9.83G [01:06<01:42, 70.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.73G/11.4G [01:05<02:03, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  96% 2.71G/2.82G [01:06<00:01, 66.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.76G/10.0G [01:06<01:42, 70.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.64G/9.83G [01:06<01:53, 63.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.74G/11.4G [01:05<02:11, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  96% 2.72G/2.82G [01:06<00:01, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.77G/10.0G [01:06<01:51, 65.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.65G/9.83G [01:06<01:41, 70.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.75G/11.4G [01:05<02:12, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.78G/10.0G [01:06<01:40, 71.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.66G/9.83G [01:06<01:36, 74.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  97% 2.73G/2.82G [01:06<00:01, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.67G/9.83G [01:06<01:37, 73.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  97% 2.74G/2.82G [01:06<00:01, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.77G/11.4G [01:06<02:05, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.80G/10.0G [01:06<01:35, 75.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.68G/9.83G [01:06<01:36, 74.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  97% 2.75G/2.82G [01:06<00:01, 64.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  24% 2.78G/11.4G [01:06<02:04, 68.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.81G/10.0G [01:06<01:42, 69.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  98% 2.76G/2.82G [01:07<00:00, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  27% 2.69G/9.83G [01:06<01:46, 66.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.79G/11.4G [01:06<01:59, 71.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.82G/10.0G [01:07<01:37, 73.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  98% 2.77G/2.82G [01:07<00:00, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.71G/9.83G [01:07<01:53, 62.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.80G/11.4G [01:06<02:12, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.83G/10.0G [01:07<01:55, 61.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  99% 2.78G/2.82G [01:07<00:00, 62.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.72G/9.83G [01:07<01:58, 60.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.81G/11.4G [01:06<02:17, 62.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  99% 2.79G/2.82G [01:07<00:00, 69.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  28% 2.84G/10.0G [01:07<01:48, 65.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.82G/11.4G [01:07<02:16, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.73G/9.83G [01:07<02:05, 56.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:  99% 2.80G/2.82G [01:07<00:00, 63.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.85G/10.0G [01:07<01:59, 59.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.83G/11.4G [01:07<02:04, 68.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.74G/9.83G [01:07<01:54, 61.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.86G/10.0G [01:09<08:37, 13.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth: 100% 2.82G/2.82G [01:10<00:00, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth: 100% 2.82G/2.82G [01:10<00:00, 40.2MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/Wan2.2_VAE.pth\n",
            "Fetching 23 files:  22% 5/23 [01:10<04:28, 14.94s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.86G/11.4G [01:09<05:48, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.89G/10.0G [01:10<04:08, 28.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.87G/11.4G [01:09<04:45, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.75G/9.83G [01:10<09:21, 12.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.92G/10.0G [01:10<03:00, 39.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.76G/9.83G [01:10<06:54, 17.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.88G/11.4G [01:09<04:22, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.77G/9.83G [01:10<05:25, 21.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.94G/10.0G [01:10<02:37, 45.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  25% 2.89G/11.4G [01:09<03:54, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.78G/9.83G [01:10<04:24, 26.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  29% 2.95G/10.0G [01:10<02:25, 48.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.79G/9.83G [01:10<03:31, 33.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.90G/11.4G [01:10<03:27, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 2.96G/10.0G [01:10<02:16, 51.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.92G/11.4G [01:10<02:52, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  28% 2.80G/9.83G [01:10<02:53, 40.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 2.97G/10.0G [01:10<02:02, 57.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.81G/9.83G [01:10<02:30, 46.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.93G/11.4G [01:10<02:40, 52.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 2.98G/10.0G [01:11<01:55, 60.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.82G/9.83G [01:11<02:09, 53.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.94G/11.4G [01:10<02:22, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 2.99G/10.0G [01:11<01:47, 65.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.83G/9.83G [01:11<02:02, 57.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.95G/11.4G [01:10<02:16, 61.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.00G/10.0G [01:11<01:49, 63.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.96G/11.4G [01:10<02:05, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.84G/9.83G [01:11<01:59, 58.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.97G/11.4G [01:10<01:52, 74.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.01G/10.0G [01:11<01:45, 66.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.98G/11.4G [01:11<01:52, 74.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.02G/10.0G [01:11<01:42, 68.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.86G/9.83G [01:11<01:44, 66.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 2.99G/11.4G [01:11<01:48, 77.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.87G/9.83G [01:11<01:41, 68.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.03G/10.0G [01:11<02:02, 56.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 3.00G/11.4G [01:11<01:57, 71.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.88G/9.83G [01:11<01:45, 65.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  30% 3.04G/10.0G [01:12<01:58, 58.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  26% 3.01G/11.4G [01:11<01:55, 72.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  29% 2.89G/9.83G [01:12<01:41, 68.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.02G/11.4G [01:11<01:54, 72.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.05G/10.0G [01:12<01:54, 60.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.90G/9.83G [01:13<04:09, 27.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.03G/11.4G [01:12<04:59, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.06G/10.0G [01:13<04:21, 26.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.92G/9.83G [01:13<03:18, 34.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.07G/10.0G [01:13<03:28, 33.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.04G/11.4G [01:12<04:06, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.93G/9.83G [01:13<02:42, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.05G/11.4G [01:12<03:18, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.08G/10.0G [01:13<02:55, 39.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.06G/11.4G [01:12<02:45, 50.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.09G/10.0G [01:13<02:30, 46.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.95G/9.83G [01:13<02:05, 54.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.08G/11.4G [01:13<01:57, 70.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.11G/10.0G [01:13<01:45, 65.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.96G/9.83G [01:13<01:58, 57.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  31% 3.14G/10.0G [01:13<01:20, 85.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.09G/11.4G [01:13<02:18, 59.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.97G/9.83G [01:13<02:01, 56.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.10G/11.4G [01:13<02:09, 63.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.98G/9.83G [01:14<01:51, 61.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.16G/10.0G [01:14<01:23, 81.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  27% 3.11G/11.4G [01:13<02:05, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  30% 2.99G/9.83G [01:14<02:00, 56.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.17G/10.0G [01:14<01:30, 75.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.12G/11.4G [01:13<01:56, 70.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.00G/9.83G [01:14<01:46, 64.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.14G/11.4G [01:13<01:50, 74.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.18G/10.0G [01:14<01:30, 75.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.01G/9.83G [01:14<01:40, 68.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.19G/10.0G [01:14<01:32, 73.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.15G/11.4G [01:14<01:54, 71.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.02G/9.83G [01:14<01:41, 67.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.16G/11.4G [01:14<01:43, 78.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.21G/10.0G [01:14<01:23, 81.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.18G/11.4G [01:14<01:25, 95.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.04G/9.83G [01:14<01:23, 81.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.22G/10.0G [01:14<01:20, 84.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.05G/9.83G [01:14<01:21, 83.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.19G/11.4G [01:14<01:30, 90.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  32% 3.24G/10.0G [01:15<01:03, 106MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.20G/11.4G [01:16<06:36, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.07G/9.83G [01:18<08:08, 13.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.21G/11.4G [01:19<16:58, 8.01MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.26G/10.0G [01:20<10:27, 10.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  28% 3.23G/11.4G [01:19<09:50, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.28G/10.0G [01:20<07:04, 15.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.08G/9.83G [01:20<11:08, 10.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.25G/11.4G [01:19<06:23, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.30G/10.0G [01:20<05:02, 22.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  31% 3.09G/9.83G [01:20<08:41, 12.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.10G/9.83G [01:20<06:46, 16.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.27G/11.4G [01:19<04:36, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.32G/10.0G [01:20<03:49, 29.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.11G/9.83G [01:20<05:22, 20.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.29G/11.4G [01:20<03:33, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.12G/9.83G [01:20<04:10, 26.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  33% 3.34G/10.0G [01:20<03:02, 36.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.31G/11.4G [01:20<02:49, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.15G/9.83G [01:21<02:50, 39.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.37G/10.0G [01:21<02:24, 45.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  29% 3.33G/11.4G [01:20<02:13, 60.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.16G/9.83G [01:21<02:28, 44.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.17G/9.83G [01:21<02:13, 50.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.39G/10.0G [01:21<02:01, 54.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.36G/11.4G [01:20<01:54, 69.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.40G/10.0G [01:21<01:53, 58.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  32% 3.18G/9.83G [01:21<02:10, 51.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.41G/10.0G [01:21<01:45, 62.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.38G/11.4G [01:21<01:49, 72.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.20G/9.83G [01:21<01:40, 65.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.39G/11.4G [01:21<01:44, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  34% 3.43G/10.0G [01:21<01:33, 70.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.22G/9.83G [01:21<01:24, 78.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.41G/11.4G [01:21<01:32, 85.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.45G/10.0G [01:21<01:21, 80.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.42G/11.4G [01:21<01:30, 88.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.24G/9.83G [01:22<01:17, 84.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.47G/10.0G [01:22<01:11, 90.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.43G/11.4G [01:21<01:42, 77.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.25G/9.83G [01:22<01:28, 74.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.45G/11.4G [01:21<01:28, 89.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.49G/10.0G [01:22<01:14, 87.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.26G/9.83G [01:22<01:31, 71.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  30% 3.46G/11.4G [01:21<01:33, 84.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  33% 3.27G/9.83G [01:22<01:28, 73.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.51G/10.0G [01:22<01:12, 89.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.48G/11.4G [01:22<01:23, 94.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  35% 3.53G/10.0G [01:22<01:04, 101MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.29G/9.83G [01:22<01:20, 81.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.50G/11.4G [01:22<01:17, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.30G/9.83G [01:22<01:23, 78.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.31G/9.83G [01:23<01:26, 75.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.51G/11.4G [01:22<01:43, 75.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  36% 3.55G/10.0G [01:23<01:24, 76.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.32G/9.83G [01:23<01:27, 74.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.53G/11.4G [01:22<01:23, 93.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  36% 3.57G/10.0G [01:23<01:22, 77.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.33G/9.83G [01:23<01:31, 71.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  36% 3.58G/10.0G [01:23<01:26, 74.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.55G/11.4G [01:22<01:25, 91.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  36% 3.59G/10.0G [01:23<01:22, 77.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.36G/9.83G [01:23<01:19, 81.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  36% 3.61G/10.0G [01:23<01:03, 100MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.37G/9.83G [01:23<01:17, 83.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.57G/11.4G [01:23<01:48, 71.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.38G/9.83G [01:23<01:19, 80.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  36% 3.63G/10.0G [01:23<00:59, 108MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  31% 3.58G/11.4G [01:23<01:42, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.59G/11.4G [01:23<01:36, 80.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  34% 3.39G/9.83G [01:23<01:20, 80.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  37% 3.65G/10.0G [01:24<00:59, 106MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.40G/9.83G [01:24<01:23, 76.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.61G/11.4G [01:23<01:31, 84.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  37% 3.67G/10.0G [01:24<00:59, 106MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.41G/9.83G [01:24<01:29, 72.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.63G/11.4G [01:23<01:16, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  37% 3.69G/10.0G [01:24<00:55, 113MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  37% 3.71G/10.0G [01:24<00:51, 121MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.42G/9.83G [01:24<01:55, 55.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.65G/11.4G [01:24<01:28, 87.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.43G/9.83G [01:24<01:46, 59.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  37% 3.73G/10.0G [01:24<00:59, 105MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.66G/11.4G [01:24<01:39, 77.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.44G/9.83G [01:24<01:38, 64.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.67G/11.4G [01:24<01:49, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.45G/9.83G [01:25<01:44, 60.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.75G/10.0G [01:25<01:09, 89.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.68G/11.4G [01:24<01:46, 72.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.46G/9.83G [01:25<01:37, 65.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.76G/10.0G [01:25<01:12, 85.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  32% 3.69G/11.4G [01:24<01:47, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.47G/9.83G [01:25<01:38, 64.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.77G/10.0G [01:25<01:13, 84.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.70G/11.4G [01:24<01:39, 77.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  35% 3.48G/9.83G [01:25<01:31, 69.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.79G/10.0G [01:25<01:17, 80.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.71G/11.4G [01:25<01:37, 78.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.49G/9.83G [01:25<01:33, 67.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.72G/11.4G [01:25<01:43, 73.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.80G/10.0G [01:25<01:25, 72.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.50G/9.83G [01:25<01:33, 67.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.81G/10.0G [01:25<01:18, 79.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.73G/11.4G [01:25<01:40, 76.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.51G/9.83G [01:25<01:29, 70.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.74G/11.4G [01:25<01:45, 71.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.82G/10.0G [01:26<01:24, 72.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.52G/9.83G [01:26<01:28, 71.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.75G/11.4G [01:25<01:40, 75.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.83G/10.0G [01:26<01:23, 74.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.53G/9.83G [01:26<01:33, 67.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.84G/10.0G [01:26<01:21, 75.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.76G/11.4G [01:25<01:46, 71.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.54G/9.83G [01:26<01:31, 68.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  38% 3.85G/10.0G [01:26<01:22, 74.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.77G/11.4G [01:25<01:45, 71.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.86G/10.0G [01:26<01:23, 73.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.79G/11.4G [01:26<01:49, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.55G/9.83G [01:26<01:40, 62.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  33% 3.80G/11.4G [01:26<01:47, 70.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.87G/10.0G [01:26<01:32, 66.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.57G/9.83G [01:26<01:42, 61.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.88G/10.0G [01:26<01:22, 74.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.81G/11.4G [01:26<01:49, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.89G/10.0G [01:27<01:16, 80.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  36% 3.59G/9.83G [01:27<01:21, 76.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.90G/10.0G [01:27<01:25, 71.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.83G/11.4G [01:26<01:45, 71.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.60G/9.83G [01:27<01:32, 67.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.91G/10.0G [01:27<01:31, 66.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.61G/9.83G [01:27<01:31, 68.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.92G/10.0G [01:27<01:28, 68.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.85G/11.4G [01:26<01:49, 68.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.62G/9.83G [01:27<01:41, 61.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.93G/10.0G [01:27<01:28, 68.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.86G/11.4G [01:27<01:47, 69.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.63G/9.83G [01:27<01:37, 63.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  39% 3.94G/10.0G [01:27<01:27, 69.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.87G/11.4G [01:27<01:45, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.64G/9.83G [01:27<01:31, 67.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.65G/9.83G [01:27<01:23, 74.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 3.95G/10.0G [01:28<01:37, 61.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.88G/11.4G [01:27<01:55, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.66G/9.83G [01:28<01:22, 75.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 3.96G/10.0G [01:28<01:30, 66.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.89G/11.4G [01:27<01:50, 67.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.67G/9.83G [01:28<01:20, 76.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 3.97G/10.0G [01:28<01:27, 68.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.90G/11.4G [01:27<01:47, 69.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  37% 3.68G/9.83G [01:28<01:16, 80.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 3.98G/10.0G [01:28<01:20, 74.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  34% 3.91G/11.4G [01:27<01:41, 73.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.69G/9.83G [01:28<01:14, 82.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 4.00G/10.0G [01:28<01:29, 66.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.92G/11.4G [01:28<01:47, 69.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.70G/9.83G [01:28<01:16, 80.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 4.01G/10.0G [01:28<01:28, 68.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.71G/9.83G [01:28<01:22, 74.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.94G/11.4G [01:28<01:39, 74.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.72G/9.83G [01:28<01:19, 76.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 4.02G/10.0G [01:28<01:37, 61.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.95G/11.4G [01:28<01:38, 75.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.73G/9.83G [01:29<01:22, 73.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 4.03G/10.0G [01:29<01:28, 67.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.96G/11.4G [01:28<01:40, 73.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.74G/9.83G [01:29<01:23, 72.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 4.04G/10.0G [01:29<01:27, 67.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.97G/11.4G [01:28<01:40, 73.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.75G/9.83G [01:29<01:20, 75.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  40% 4.05G/10.0G [01:29<01:24, 70.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 3.98G/11.4G [01:28<01:39, 74.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.76G/9.83G [01:29<01:24, 71.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 4.00G/11.4G [01:28<01:37, 75.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.07G/10.0G [01:29<01:20, 73.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 4.01G/11.4G [01:29<01:29, 82.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  38% 3.77G/9.83G [01:29<01:28, 68.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.08G/10.0G [01:29<01:19, 74.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 4.02G/11.4G [01:29<01:33, 78.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.79G/9.83G [01:29<01:35, 63.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.09G/10.0G [01:29<01:23, 70.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  35% 4.03G/11.4G [01:29<01:37, 75.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.80G/9.83G [01:30<01:36, 62.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.04G/11.4G [01:29<01:45, 69.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.11G/10.0G [01:30<01:11, 82.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.81G/9.83G [01:30<01:36, 62.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.05G/11.4G [01:29<01:45, 69.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.12G/10.0G [01:30<01:14, 78.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.82G/9.83G [01:30<01:35, 63.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.06G/11.4G [01:29<01:34, 77.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.13G/10.0G [01:30<01:15, 77.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.83G/9.83G [01:30<01:33, 64.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.07G/11.4G [01:29<01:35, 76.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  41% 4.14G/10.0G [01:30<01:14, 78.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.08G/11.4G [01:30<01:28, 82.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.15G/10.0G [01:30<01:13, 79.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.85G/9.83G [01:30<01:16, 78.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.09G/11.4G [01:30<01:31, 79.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.16G/10.0G [01:30<01:11, 82.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.10G/11.4G [01:30<01:24, 85.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.86G/9.83G [01:30<01:22, 72.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.17G/10.0G [01:30<01:06, 87.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.11G/11.4G [01:30<01:20, 89.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.12G/11.4G [01:30<01:20, 89.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.19G/10.0G [01:31<01:01, 94.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  39% 3.88G/9.83G [01:31<01:12, 82.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  36% 4.14G/11.4G [01:30<01:07, 107MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 3.89G/9.83G [01:31<01:14, 79.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.20G/10.0G [01:31<01:06, 87.4MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.22G/10.0G [01:31<01:09, 83.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 3.90G/9.83G [01:31<01:16, 77.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.16G/11.4G [01:30<01:09, 104MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.23G/10.0G [01:31<01:08, 84.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 3.91G/9.83G [01:31<01:18, 75.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.17G/11.4G [01:31<01:16, 94.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  42% 4.25G/10.0G [01:31<00:55, 103MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 3.92G/9.83G [01:31<01:15, 78.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.18G/11.4G [01:31<01:19, 90.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 3.93G/9.83G [01:31<01:10, 83.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.27G/10.0G [01:31<00:53, 107MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.20G/11.4G [01:31<01:16, 94.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 3.95G/9.83G [01:32<01:11, 82.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.22G/11.4G [01:31<01:18, 91.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.29G/10.0G [01:32<00:58, 97.4MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.30G/10.0G [01:32<01:01, 92.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.24G/11.4G [01:31<01:11, 100MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  40% 3.97G/9.83G [01:32<01:07, 86.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.31G/10.0G [01:32<01:01, 92.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.25G/11.4G [01:31<01:12, 98.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.00G/9.83G [01:32<01:00, 97.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  37% 4.26G/11.4G [01:31<01:11, 99.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.32G/10.0G [01:32<01:03, 90.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.01G/9.83G [01:32<01:00, 95.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.28G/11.4G [01:32<00:59, 118MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  43% 4.34G/10.0G [01:32<00:54, 103MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.02G/9.83G [01:32<01:03, 91.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.30G/11.4G [01:32<00:55, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.36G/10.0G [01:32<00:46, 120MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.03G/9.83G [01:32<01:04, 90.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.04G/9.83G [01:32<01:06, 87.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.32G/11.4G [01:32<00:59, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.38G/10.0G [01:33<01:09, 80.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.05G/9.83G [01:33<01:27, 66.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.34G/11.4G [01:32<01:10, 99.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.39G/10.0G [01:33<01:07, 83.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  41% 4.06G/9.83G [01:33<01:20, 71.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  38% 4.36G/11.4G [01:32<01:06, 105MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.41G/10.0G [01:33<01:04, 86.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.08G/9.83G [01:33<01:10, 81.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.42G/10.0G [01:33<01:07, 82.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.09G/9.83G [01:33<01:16, 74.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.38G/11.4G [01:33<01:21, 86.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.44G/10.0G [01:33<01:09, 80.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.10G/9.83G [01:33<01:14, 77.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.39G/11.4G [01:33<01:23, 83.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  44% 4.45G/10.0G [01:33<01:07, 81.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.11G/9.83G [01:33<01:11, 79.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.41G/11.4G [01:33<01:10, 98.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.12G/9.83G [01:34<01:07, 84.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.47G/10.0G [01:34<00:56, 98.1MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.48G/10.0G [01:34<00:59, 92.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.44G/11.4G [01:33<01:17, 89.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.13G/9.83G [01:34<01:56, 48.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.50G/10.0G [01:34<01:43, 53.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.46G/11.4G [01:37<08:16, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.14G/9.83G [01:38<11:53, 7.96MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.51G/10.0G [01:38<08:22, 10.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  39% 4.48G/11.4G [01:38<05:52, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.16G/9.83G [01:38<06:49, 13.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.53G/10.0G [01:38<05:25, 16.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  42% 4.17G/9.83G [01:38<05:22, 17.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.50G/11.4G [01:38<04:19, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  45% 4.54G/10.0G [01:38<04:27, 20.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.18G/9.83G [01:38<04:12, 22.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.52G/11.4G [01:38<03:13, 35.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.55G/10.0G [01:38<03:39, 24.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.19G/9.83G [01:39<03:22, 27.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.54G/11.4G [01:38<02:38, 42.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.20G/9.83G [01:39<02:59, 31.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.57G/10.0G [01:39<02:49, 32.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.22G/9.83G [01:39<02:29, 37.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.56G/11.4G [01:40<04:55, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.23G/9.83G [01:43<12:52, 7.25MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.24G/9.83G [01:44<11:32, 8.07MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.26G/9.83G [01:44<06:28, 14.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.57G/11.4G [01:44<11:17, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  43% 4.27G/9.83G [01:44<05:07, 18.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.59G/10.0G [01:44<10:27, 8.61MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  40% 4.59G/11.4G [01:44<07:42, 14.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.28G/9.83G [01:44<04:05, 22.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.61G/10.0G [01:45<07:09, 12.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.60G/11.4G [01:44<06:27, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.29G/9.83G [01:45<03:20, 27.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.62G/10.0G [01:45<06:01, 14.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.61G/11.4G [01:44<05:29, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.30G/9.83G [01:45<02:52, 32.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.63G/10.0G [01:45<04:54, 18.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.62G/11.4G [01:44<04:26, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  46% 4.65G/10.0G [01:45<03:59, 22.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.32G/9.83G [01:45<01:58, 46.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.63G/11.4G [01:45<03:45, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.67G/10.0G [01:45<02:38, 33.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.65G/11.4G [01:45<03:02, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.34G/9.83G [01:45<01:34, 58.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.67G/11.4G [01:45<02:02, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.68G/10.0G [01:45<02:21, 37.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.35G/9.83G [01:45<01:30, 60.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.69G/10.0G [01:45<02:01, 43.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  44% 4.36G/9.83G [01:46<01:28, 62.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.69G/11.4G [01:45<01:49, 60.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.70G/10.0G [01:46<01:50, 48.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.37G/9.83G [01:46<01:24, 64.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.71G/10.0G [01:46<01:41, 52.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.70G/11.4G [01:45<01:48, 61.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.38G/9.83G [01:46<01:16, 71.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.72G/10.0G [01:46<01:28, 59.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  41% 4.71G/11.4G [01:45<01:40, 66.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.39G/9.83G [01:46<01:17, 70.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  47% 4.73G/10.0G [01:46<01:21, 64.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.72G/11.4G [01:45<01:36, 69.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.40G/9.83G [01:46<01:14, 72.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.73G/11.4G [01:46<01:31, 72.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.75G/10.0G [01:46<01:04, 80.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.41G/9.83G [01:46<01:09, 77.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.74G/11.4G [01:46<01:27, 75.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.42G/9.83G [01:46<01:07, 80.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.77G/10.0G [01:46<00:55, 94.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.75G/11.4G [01:46<01:26, 76.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.78G/10.0G [01:46<00:57, 90.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.44G/9.83G [01:46<01:09, 77.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.76G/11.4G [01:46<01:23, 78.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.79G/10.0G [01:47<00:56, 92.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.45G/9.83G [01:47<01:07, 79.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.77G/11.4G [01:46<01:19, 83.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.80G/10.0G [01:47<00:59, 87.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.46G/9.83G [01:47<01:06, 80.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.78G/11.4G [01:46<01:19, 82.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.81G/10.0G [01:47<00:58, 88.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  45% 4.47G/9.83G [01:47<01:03, 84.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.79G/11.4G [01:46<01:19, 82.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.48G/9.83G [01:47<01:01, 87.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.82G/10.0G [01:47<01:01, 84.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.80G/11.4G [01:46<01:22, 79.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.49G/9.83G [01:47<00:59, 89.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  48% 4.83G/10.0G [01:47<00:59, 86.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.50G/9.83G [01:47<00:58, 91.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.81G/11.4G [01:47<01:28, 74.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.51G/9.83G [01:47<00:59, 89.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.85G/10.0G [01:47<00:57, 89.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  42% 4.82G/11.4G [01:47<01:27, 74.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.87G/10.0G [01:47<00:55, 92.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.52G/9.83G [01:47<01:04, 82.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.83G/11.4G [01:47<01:27, 74.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.89G/10.0G [01:48<00:48, 105MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.84G/11.4G [01:47<01:23, 77.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.90G/10.0G [01:48<00:54, 93.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.87G/11.4G [01:47<01:15, 85.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.54G/9.83G [01:48<01:18, 67.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.91G/10.0G [01:48<00:53, 95.2MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.92G/10.0G [01:48<00:53, 95.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  46% 4.55G/9.83G [01:48<01:14, 70.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.88G/11.4G [01:47<01:22, 78.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  49% 4.93G/10.0G [01:48<01:00, 84.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.90G/11.4G [01:48<01:11, 89.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.57G/9.83G [01:48<01:09, 76.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 4.95G/10.0G [01:48<00:59, 84.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.58G/9.83G [01:48<01:12, 71.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.92G/11.4G [01:48<01:10, 91.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 4.96G/10.0G [01:48<00:59, 85.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  43% 4.93G/11.4G [01:48<01:09, 92.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.59G/9.83G [01:49<01:13, 71.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 4.98G/10.0G [01:49<00:54, 92.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.61G/9.83G [01:49<01:03, 82.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 4.95G/11.4G [01:48<01:11, 89.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 4.99G/10.0G [01:49<00:56, 88.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.62G/9.83G [01:49<01:06, 78.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 4.96G/11.4G [01:48<01:16, 83.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 5.00G/10.0G [01:49<00:58, 85.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.65G/9.83G [01:49<00:56, 92.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 5.01G/10.0G [01:49<00:56, 87.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 4.98G/11.4G [01:48<01:05, 97.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.66G/9.83G [01:49<00:56, 90.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 4.99G/11.4G [01:49<01:09, 91.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 5.02G/10.0G [01:49<00:59, 84.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 5.00G/11.4G [01:49<01:10, 90.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  47% 4.67G/9.83G [01:49<01:01, 84.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  50% 5.03G/10.0G [01:49<01:02, 79.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.68G/9.83G [01:49<00:58, 88.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 5.02G/11.4G [01:49<01:05, 96.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.05G/10.0G [01:50<00:56, 87.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.69G/9.83G [01:50<01:00, 85.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  44% 5.04G/11.4G [01:49<00:58, 108MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.06G/10.0G [01:50<00:59, 83.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.70G/9.83G [01:50<01:03, 81.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.71G/9.83G [01:50<00:59, 85.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.08G/10.0G [01:50<00:57, 85.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.06G/11.4G [01:49<01:01, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.09G/10.0G [01:50<00:55, 88.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.72G/9.83G [01:50<01:02, 81.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.08G/11.4G [01:49<01:02, 101MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.10G/10.0G [01:50<00:54, 90.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.73G/9.83G [01:50<01:09, 73.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.09G/11.4G [01:50<01:07, 92.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.12G/10.0G [01:50<00:44, 109MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.11G/11.4G [01:50<01:00, 104MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.75G/9.83G [01:50<00:58, 86.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  51% 5.14G/10.0G [01:50<00:47, 103MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  48% 4.76G/9.83G [01:50<00:59, 85.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.12G/11.4G [01:50<01:06, 93.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  52% 5.16G/10.0G [01:51<00:45, 107MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.78G/9.83G [01:51<00:56, 89.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.14G/11.4G [01:50<01:12, 86.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  52% 5.18G/10.0G [01:51<00:43, 110MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.79G/9.83G [01:51<00:56, 88.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.80G/9.83G [01:51<00:57, 86.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.15G/11.4G [01:50<01:20, 77.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  52% 5.20G/10.0G [01:51<00:44, 107MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.81G/9.83G [01:51<00:56, 88.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.16G/11.4G [01:51<01:24, 73.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.82G/9.83G [01:51<00:58, 85.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  45% 5.17G/11.4G [01:51<01:26, 71.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.83G/9.83G [01:51<01:01, 80.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  52% 5.22G/10.0G [01:51<00:55, 85.3MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  52% 5.23G/10.0G [01:51<00:54, 87.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.84G/9.83G [01:51<01:02, 79.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.19G/11.4G [01:51<01:17, 80.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  49% 4.85G/9.83G [01:52<01:00, 81.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.25G/10.0G [01:52<00:49, 94.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.87G/9.83G [01:52<00:57, 86.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.21G/11.4G [01:51<01:11, 86.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.27G/10.0G [01:52<00:46, 102MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.22G/11.4G [01:51<01:12, 84.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.88G/9.83G [01:52<01:00, 82.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.89G/9.83G [01:52<01:01, 79.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.23G/11.4G [01:51<01:18, 78.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.30G/10.0G [01:52<00:56, 83.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.90G/9.83G [01:52<01:09, 70.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.24G/11.4G [01:52<01:27, 69.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.31G/10.0G [01:52<01:06, 70.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.25G/11.4G [01:52<01:39, 61.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.91G/9.83G [01:52<01:26, 57.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.26G/11.4G [01:52<01:29, 68.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.32G/10.0G [01:53<01:05, 71.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  46% 5.27G/11.4G [01:52<01:24, 71.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.93G/9.83G [01:53<01:11, 68.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.33G/10.0G [01:53<01:04, 72.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.28G/11.4G [01:52<01:26, 70.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  53% 5.34G/10.0G [01:53<01:03, 72.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.94G/9.83G [01:53<01:17, 63.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.35G/10.0G [01:53<01:00, 77.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.95G/9.83G [01:53<01:11, 68.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.31G/11.4G [01:52<01:13, 82.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.36G/10.0G [01:53<01:01, 75.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  50% 4.96G/9.83G [01:53<01:12, 66.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.32G/11.4G [01:53<01:16, 79.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.37G/10.0G [01:53<01:04, 72.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.33G/11.4G [01:53<01:18, 76.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 4.97G/9.83G [01:53<01:19, 61.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.38G/10.0G [01:53<01:08, 67.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.34G/11.4G [01:53<01:23, 72.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.39G/10.0G [01:54<01:03, 72.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.35G/11.4G [01:53<01:18, 76.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 4.99G/9.83G [01:54<01:13, 65.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.40G/10.0G [01:54<01:03, 72.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.36G/11.4G [01:53<01:13, 81.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.41G/10.0G [01:54<00:59, 76.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.37G/11.4G [01:53<01:10, 85.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 5.01G/9.83G [01:54<01:07, 71.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.42G/10.0G [01:54<01:03, 72.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.38G/11.4G [01:53<01:21, 73.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 5.02G/9.83G [01:54<01:07, 71.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.43G/10.0G [01:54<01:04, 71.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  47% 5.39G/11.4G [01:54<01:21, 73.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 5.03G/9.83G [01:54<01:06, 71.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  54% 5.44G/10.0G [01:54<01:00, 75.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.40G/11.4G [01:54<01:16, 77.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.45G/10.0G [01:54<00:58, 77.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.41G/11.4G [01:54<01:16, 77.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 5.04G/9.83G [01:54<01:25, 56.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.47G/10.0G [01:55<00:48, 93.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.43G/11.4G [01:54<01:06, 89.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  51% 5.05G/9.83G [01:55<01:22, 57.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.44G/11.4G [01:54<01:06, 88.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.49G/10.0G [01:55<00:45, 98.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.06G/9.83G [01:55<01:15, 63.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.45G/11.4G [01:54<01:18, 74.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.51G/10.0G [01:55<00:55, 80.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.08G/9.83G [01:55<01:20, 59.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.46G/11.4G [01:55<01:25, 68.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.52G/10.0G [01:55<00:59, 75.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.09G/9.83G [01:55<01:19, 59.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.53G/10.0G [01:55<01:00, 74.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.47G/11.4G [01:55<01:28, 66.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.10G/9.83G [01:55<01:18, 60.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.48G/11.4G [01:55<01:24, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.54G/10.0G [01:55<01:01, 73.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.11G/9.83G [01:55<01:16, 61.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.49G/11.4G [01:55<01:25, 68.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  55% 5.55G/10.0G [01:56<01:02, 71.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.12G/9.83G [01:56<01:10, 66.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  48% 5.51G/11.4G [01:55<01:19, 74.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.56G/10.0G [01:56<01:01, 72.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.13G/9.83G [01:56<01:07, 70.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.52G/11.4G [01:55<01:20, 73.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.57G/10.0G [01:56<00:59, 74.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.14G/9.83G [01:56<01:08, 68.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.53G/11.4G [01:55<01:16, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.58G/10.0G [01:56<01:00, 73.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  52% 5.15G/9.83G [01:56<01:06, 69.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.54G/11.4G [01:56<01:20, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.59G/10.0G [01:56<01:02, 70.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.55G/11.4G [01:56<01:22, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.16G/9.83G [01:56<01:14, 62.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.60G/10.0G [01:56<01:03, 69.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.56G/11.4G [01:56<01:19, 72.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.17G/9.83G [01:56<01:10, 66.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.61G/10.0G [01:56<01:04, 67.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.18G/9.83G [01:57<01:08, 67.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.57G/11.4G [01:56<01:24, 68.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.62G/10.0G [01:57<01:09, 63.2MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.63G/10.0G [01:57<01:01, 71.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.58G/11.4G [01:56<01:36, 59.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.19G/9.83G [01:57<01:22, 56.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  56% 5.64G/10.0G [01:57<00:59, 73.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.59G/11.4G [01:56<01:32, 62.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.20G/9.83G [01:57<01:18, 59.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.65G/10.0G [01:57<00:54, 79.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.21G/9.83G [01:57<01:09, 66.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.60G/11.4G [01:57<01:28, 64.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.66G/10.0G [01:57<00:55, 78.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  49% 5.61G/11.4G [01:57<02:39, 36.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.22G/9.83G [01:58<02:10, 35.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.67G/10.0G [01:58<01:52, 38.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.23G/9.83G [01:58<01:47, 42.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.63G/11.4G [01:57<01:45, 54.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.68G/10.0G [01:58<01:34, 45.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.64G/11.4G [01:57<01:39, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  53% 5.25G/9.83G [01:58<01:20, 56.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.65G/11.4G [01:58<01:29, 64.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.69G/10.0G [01:58<01:36, 44.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.26G/9.83G [01:58<01:15, 60.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.70G/10.0G [01:58<01:22, 51.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.67G/11.4G [01:58<01:12, 78.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.28G/9.83G [01:58<01:01, 74.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.68G/11.4G [01:58<01:15, 75.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.73G/10.0G [01:58<01:08, 61.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.30G/9.83G [01:58<00:59, 76.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.69G/11.4G [02:00<05:40, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  57% 5.74G/10.0G [02:01<04:20, 16.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.31G/9.83G [02:01<04:24, 17.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.71G/11.4G [02:00<03:32, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.33G/9.83G [02:01<02:45, 27.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  58% 5.76G/10.0G [02:01<02:44, 25.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.34G/9.83G [02:01<02:17, 32.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  50% 5.74G/11.4G [02:00<02:31, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  58% 5.78G/10.0G [02:01<02:00, 35.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  54% 5.35G/9.83G [02:01<02:01, 36.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.75G/11.4G [02:00<02:15, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.36G/9.83G [02:01<01:44, 42.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.76G/11.4G [02:01<02:03, 45.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  58% 5.79G/10.0G [02:01<01:53, 36.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.37G/9.83G [02:01<01:29, 49.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.77G/11.4G [02:01<01:49, 51.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  58% 5.80G/10.0G [02:01<01:38, 42.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.38G/9.83G [02:01<01:22, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.78G/11.4G [02:01<01:39, 56.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  58% 5.81G/10.0G [02:01<01:29, 46.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.40G/9.83G [02:02<01:01, 71.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.80G/11.4G [02:01<01:15, 73.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  58% 5.83G/10.0G [02:02<01:04, 64.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.41G/9.83G [02:02<01:02, 71.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.82G/11.4G [02:01<01:03, 87.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  59% 5.85G/10.0G [02:02<00:54, 76.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.42G/9.83G [02:02<00:59, 73.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  51% 5.84G/11.4G [02:01<00:55, 100MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.43G/9.83G [02:02<00:56, 77.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  59% 5.87G/10.0G [02:02<00:45, 89.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.86G/11.4G [02:01<00:48, 113MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.44G/9.83G [02:02<00:54, 80.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  59% 5.89G/10.0G [02:02<00:40, 101MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  55% 5.45G/9.83G [02:02<00:54, 80.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.88G/11.4G [02:02<00:47, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  59% 5.91G/10.0G [02:05<03:07, 21.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.46G/9.83G [02:05<05:36, 13.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.90G/11.4G [02:04<03:55, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  59% 5.93G/10.0G [02:05<02:15, 29.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.92G/11.4G [02:04<02:50, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.48G/9.83G [02:05<03:19, 21.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  60% 5.96G/10.0G [02:05<01:44, 38.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.51G/9.83G [02:05<02:20, 30.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.95G/11.4G [02:05<02:21, 38.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  60% 5.98G/10.0G [02:05<01:25, 46.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.52G/9.83G [02:05<02:01, 35.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  52% 5.96G/11.4G [02:05<02:09, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  60% 5.99G/10.0G [02:05<01:20, 49.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.53G/9.83G [02:05<01:47, 39.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 5.97G/11.4G [02:05<01:58, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  60% 6.01G/10.0G [02:06<01:03, 63.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  56% 5.54G/9.83G [02:06<01:37, 44.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 5.99G/11.4G [02:05<01:31, 58.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  60% 6.03G/10.0G [02:06<00:51, 77.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.56G/9.83G [02:06<01:13, 58.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 6.00G/11.4G [02:05<01:30, 59.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.57G/9.83G [02:06<01:06, 64.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 6.01G/11.4G [02:05<01:23, 63.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  61% 6.05G/10.0G [02:06<00:48, 81.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 6.02G/11.4G [02:05<01:18, 68.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.58G/9.83G [02:06<01:06, 63.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  61% 6.08G/10.0G [02:06<00:36, 108MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.59G/9.83G [02:06<00:59, 71.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 6.03G/11.4G [02:06<01:19, 67.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.60G/9.83G [02:06<00:56, 75.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  61% 6.10G/10.0G [02:06<00:36, 108MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 6.05G/11.4G [02:06<01:00, 87.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.61G/9.83G [02:06<00:56, 74.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 6.06G/11.4G [02:06<01:00, 87.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.62G/9.83G [02:06<00:54, 76.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  61% 6.12G/10.0G [02:07<00:39, 98.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  53% 6.07G/11.4G [02:06<01:01, 85.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.08G/11.4G [02:06<00:59, 88.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  61% 6.14G/10.0G [02:07<00:40, 94.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  57% 5.64G/9.83G [02:07<00:52, 80.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.10G/11.4G [02:06<00:47, 110MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.12G/11.4G [02:06<00:41, 125MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.17G/10.0G [02:07<00:38, 98.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.66G/9.83G [02:07<00:49, 83.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.14G/11.4G [02:06<00:38, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.67G/9.83G [02:07<00:59, 69.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.19G/10.0G [02:07<00:45, 83.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.68G/9.83G [02:07<00:55, 75.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.17G/11.4G [02:07<00:49, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.20G/10.0G [02:07<00:46, 82.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.70G/9.83G [02:07<00:46, 88.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.21G/10.0G [02:08<00:44, 85.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  54% 6.19G/11.4G [02:07<00:52, 99.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.71G/9.83G [02:08<00:55, 73.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.22G/10.0G [02:08<00:52, 72.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.73G/9.83G [02:08<00:55, 73.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.23G/10.0G [02:08<00:53, 70.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.21G/11.4G [02:07<01:03, 80.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  62% 6.24G/10.0G [02:08<00:50, 74.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.74G/9.83G [02:08<00:57, 70.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.22G/11.4G [02:07<01:04, 79.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.25G/10.0G [02:08<00:48, 77.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  58% 5.75G/9.83G [02:08<00:53, 76.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.23G/11.4G [02:08<01:03, 81.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.26G/10.0G [02:08<00:46, 80.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.76G/9.83G [02:08<00:53, 75.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.24G/11.4G [02:08<01:01, 82.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.27G/10.0G [02:08<00:47, 79.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.25G/11.4G [02:08<01:03, 80.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.77G/9.83G [02:08<00:58, 69.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.28G/10.0G [02:09<00:48, 76.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.26G/11.4G [02:08<01:04, 79.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.78G/9.83G [02:09<00:58, 69.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.29G/10.0G [02:09<00:52, 70.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.27G/11.4G [02:08<01:10, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.79G/9.83G [02:09<01:00, 66.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.28G/11.4G [02:08<01:11, 71.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.31G/10.0G [02:09<00:48, 76.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.80G/9.83G [02:09<01:02, 64.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.29G/11.4G [02:09<01:12, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.81G/9.83G [02:09<00:57, 70.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.32G/10.0G [02:09<00:49, 73.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  55% 6.30G/11.4G [02:09<01:08, 73.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.33G/10.0G [02:09<00:48, 75.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.82G/9.83G [02:09<00:59, 67.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.31G/11.4G [02:09<01:11, 70.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  63% 6.34G/10.0G [02:09<00:49, 74.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.83G/9.83G [02:09<01:00, 66.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.32G/11.4G [02:09<01:11, 70.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.35G/10.0G [02:10<00:50, 72.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  59% 5.84G/9.83G [02:10<00:54, 72.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.33G/11.4G [02:09<01:11, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.85G/9.83G [02:10<00:54, 73.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.36G/10.0G [02:10<00:52, 68.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.34G/11.4G [02:09<01:10, 71.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.86G/9.83G [02:10<00:57, 68.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.38G/10.0G [02:10<00:53, 67.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.35G/11.4G [02:09<01:10, 70.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.87G/9.83G [02:10<00:56, 70.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.39G/10.0G [02:10<00:51, 69.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.38G/11.4G [02:10<00:59, 84.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.40G/10.0G [02:10<00:53, 67.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.88G/9.83G [02:10<01:04, 61.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.39G/11.4G [02:10<00:59, 83.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.41G/10.0G [02:10<00:53, 66.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.89G/9.83G [02:10<01:08, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.40G/11.4G [02:10<01:06, 74.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.42G/10.0G [02:11<00:55, 64.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.90G/9.83G [02:11<01:07, 58.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.41G/11.4G [02:10<01:07, 73.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.43G/10.0G [02:11<00:54, 65.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.91G/9.83G [02:11<01:04, 60.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  56% 6.42G/11.4G [02:10<01:09, 71.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  64% 6.44G/10.0G [02:11<00:53, 67.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.92G/9.83G [02:11<00:58, 66.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.43G/11.4G [02:10<01:04, 77.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.45G/10.0G [02:11<00:50, 70.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  60% 5.93G/9.83G [02:11<00:56, 68.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.44G/11.4G [02:10<01:05, 75.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.46G/10.0G [02:11<00:48, 72.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 5.95G/9.83G [02:11<00:51, 75.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 5.96G/9.83G [02:11<00:52, 74.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.46G/11.4G [02:11<01:02, 79.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.47G/10.0G [02:11<00:53, 66.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.47G/11.4G [02:11<01:02, 77.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 5.97G/9.83G [02:11<00:54, 71.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.48G/10.0G [02:11<00:51, 67.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.48G/11.4G [02:11<01:06, 73.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 5.98G/9.83G [02:12<00:57, 66.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.49G/10.0G [02:12<00:55, 63.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.50G/11.4G [02:11<00:54, 88.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 6.00G/9.83G [02:12<00:47, 80.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.50G/10.0G [02:12<01:04, 54.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.51G/11.4G [02:11<00:57, 84.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 6.02G/9.83G [02:12<00:46, 81.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.51G/10.0G [02:12<01:03, 55.1MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.52G/10.0G [02:12<00:55, 62.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 6.03G/9.83G [02:12<00:46, 81.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  57% 6.52G/11.4G [02:12<01:22, 58.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  61% 6.04G/9.83G [02:12<00:44, 84.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.53G/10.0G [02:12<00:51, 67.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.05G/9.83G [02:12<00:44, 84.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.54G/11.4G [02:12<01:08, 70.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  65% 6.54G/10.0G [02:12<00:51, 67.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.06G/9.83G [02:13<00:46, 80.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.55G/11.4G [02:12<01:06, 72.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.55G/10.0G [02:13<00:47, 72.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.56G/11.4G [02:12<01:04, 74.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.07G/9.83G [02:13<00:48, 77.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.56G/10.0G [02:13<00:49, 68.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.57G/11.4G [02:12<01:00, 79.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.08G/9.83G [02:13<00:47, 78.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.57G/10.0G [02:13<00:46, 74.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.59G/11.4G [02:12<01:00, 79.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.09G/9.83G [02:13<00:50, 74.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.59G/10.0G [02:13<00:47, 72.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.60G/11.4G [02:13<00:58, 80.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.10G/9.83G [02:13<00:50, 74.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.60G/10.0G [02:13<00:45, 74.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.61G/11.4G [02:13<01:12, 65.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.61G/10.0G [02:13<00:51, 65.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.11G/9.83G [02:13<00:59, 62.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.62G/11.4G [02:13<01:08, 68.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.62G/10.0G [02:13<00:46, 72.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  62% 6.13G/9.83G [02:14<00:48, 76.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  58% 6.63G/11.4G [02:13<01:08, 69.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  66% 6.64G/10.0G [02:14<00:40, 83.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.65G/11.4G [02:13<00:56, 83.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  63% 6.16G/9.83G [02:14<00:43, 84.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.65G/10.0G [02:14<00:39, 85.1MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.66G/10.0G [02:14<00:41, 81.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  63% 6.17G/9.83G [02:14<00:46, 78.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.66G/11.4G [02:13<01:01, 76.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  63% 6.18G/9.83G [02:14<00:48, 75.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.67G/11.4G [02:14<01:05, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.67G/10.0G [02:14<00:46, 71.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  63% 6.20G/9.83G [02:14<00:39, 91.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.69G/10.0G [02:14<00:36, 91.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.69G/11.4G [02:14<00:54, 86.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  63% 6.21G/9.83G [02:14<00:38, 93.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.71G/10.0G [02:14<00:33, 99.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  63% 6.22G/9.83G [02:15<00:40, 88.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.71G/11.4G [02:14<00:53, 87.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  67% 6.73G/10.0G [02:15<00:31, 104MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  63% 6.23G/9.83G [02:15<00:43, 83.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.72G/11.4G [02:14<00:53, 87.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.73G/11.4G [02:18<08:05, 9.55MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.24G/9.83G [02:19<07:10, 8.33MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.75G/10.0G [02:19<04:08, 13.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  59% 6.75G/11.4G [02:19<05:02, 15.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.77G/10.0G [02:19<02:53, 18.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.26G/9.83G [02:19<04:17, 13.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.77G/11.4G [02:19<03:32, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.27G/9.83G [02:19<03:32, 16.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.79G/10.0G [02:19<02:09, 24.7MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.81G/10.0G [02:20<01:55, 27.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.28G/9.83G [02:20<02:54, 20.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.79G/11.4G [02:19<02:38, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  68% 6.83G/10.0G [02:20<01:23, 37.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.81G/11.4G [02:19<02:17, 33.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.30G/9.83G [02:20<01:58, 29.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.85G/10.0G [02:20<01:02, 50.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.82G/11.4G [02:19<01:59, 38.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.32G/9.83G [02:20<01:26, 40.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.83G/11.4G [02:19<01:47, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.87G/10.0G [02:20<00:52, 59.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  64% 6.33G/9.83G [02:20<01:18, 44.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.85G/11.4G [02:20<01:20, 55.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.89G/10.0G [02:20<00:44, 69.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.34G/9.83G [02:20<01:07, 51.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.86G/11.4G [02:20<01:13, 60.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.35G/9.83G [02:20<01:00, 56.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.91G/10.0G [02:20<00:37, 82.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  60% 6.87G/11.4G [02:20<01:09, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.36G/9.83G [02:21<00:54, 64.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  69% 6.93G/10.0G [02:21<00:35, 86.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.38G/9.83G [02:21<00:52, 66.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.89G/11.4G [02:20<01:05, 67.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.40G/9.83G [02:21<00:42, 80.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  70% 6.95G/10.0G [02:21<00:35, 86.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.90G/11.4G [02:20<01:04, 68.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.41G/9.83G [02:21<00:42, 81.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  70% 6.97G/10.0G [02:21<00:33, 90.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.92G/11.4G [02:21<00:54, 81.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  65% 6.43G/9.83G [02:21<00:39, 86.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.93G/11.4G [02:21<00:56, 79.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  70% 6.99G/10.0G [02:21<00:29, 100MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.44G/9.83G [02:21<00:40, 83.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.95G/11.4G [02:21<00:49, 88.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.45G/9.83G [02:21<00:42, 80.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  70% 7.01G/10.0G [02:22<00:31, 95.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.96G/11.4G [02:21<00:49, 89.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.46G/9.83G [02:22<00:44, 75.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  70% 7.04G/10.0G [02:22<00:28, 105MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  61% 6.98G/11.4G [02:21<00:48, 89.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.47G/9.83G [02:22<00:45, 73.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 6.99G/11.4G [02:21<00:48, 89.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  71% 7.06G/10.0G [02:22<00:33, 87.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.49G/9.83G [02:22<00:39, 84.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.00G/11.4G [02:21<00:48, 89.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.01G/11.4G [02:22<00:47, 90.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.50G/9.83G [02:22<00:41, 80.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  71% 7.08G/10.0G [02:22<00:32, 90.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.03G/11.4G [02:22<00:47, 91.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.51G/9.83G [02:22<00:39, 83.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.04G/11.4G [02:22<00:48, 89.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.52G/9.83G [02:22<00:39, 84.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  71% 7.10G/10.0G [02:22<00:31, 93.1MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  71% 7.11G/10.0G [02:23<00:32, 89.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.06G/11.4G [02:22<00:44, 96.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  66% 6.53G/9.83G [02:23<00:48, 67.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  71% 7.12G/10.0G [02:23<00:33, 86.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.08G/11.4G [02:22<00:39, 110MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.54G/9.83G [02:23<00:48, 67.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  71% 7.14G/10.0G [02:23<00:32, 86.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.55G/9.83G [02:23<00:49, 66.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  62% 7.10G/11.4G [02:22<00:41, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.56G/9.83G [02:25<03:19, 16.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.16G/10.0G [02:25<02:02, 23.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.12G/11.4G [02:25<02:55, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.57G/9.83G [02:25<02:56, 18.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.18G/10.0G [02:25<01:30, 31.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.14G/11.4G [02:25<02:09, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.60G/9.83G [02:25<01:48, 29.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.19G/10.0G [02:25<01:18, 35.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.15G/11.4G [02:25<01:54, 36.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.61G/9.83G [02:25<01:32, 34.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.20G/10.0G [02:26<01:08, 41.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.16G/11.4G [02:25<01:41, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.62G/9.83G [02:26<01:19, 40.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.21G/10.0G [02:26<01:01, 45.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.17G/11.4G [02:25<01:33, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  67% 6.63G/9.83G [02:26<01:09, 46.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.18G/11.4G [02:25<01:21, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.64G/9.83G [02:26<00:59, 53.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.24G/10.0G [02:26<00:47, 58.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.19G/11.4G [02:25<01:10, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.65G/9.83G [02:26<00:51, 61.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  72% 7.25G/10.0G [02:26<00:43, 63.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.20G/11.4G [02:26<01:02, 66.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.66G/9.83G [02:26<00:48, 65.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.26G/10.0G [02:26<00:41, 66.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  63% 7.21G/11.4G [02:26<00:57, 71.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.27G/10.0G [02:26<00:38, 71.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.22G/11.4G [02:26<00:56, 73.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.67G/9.83G [02:26<00:50, 62.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.28G/10.0G [02:26<00:37, 73.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.24G/11.4G [02:26<00:56, 73.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.68G/9.83G [02:26<00:48, 64.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.29G/10.0G [02:29<03:47, 11.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.25G/11.4G [02:29<05:56, 11.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.69G/9.83G [02:29<04:37, 11.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.31G/10.0G [02:29<02:13, 20.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.27G/11.4G [02:29<03:27, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.71G/9.83G [02:29<02:42, 19.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.28G/11.4G [02:29<02:47, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.33G/10.0G [02:30<01:30, 29.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  68% 6.72G/9.83G [02:30<02:13, 23.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  73% 7.34G/10.0G [02:30<01:16, 34.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.29G/11.4G [02:29<02:19, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.73G/9.83G [02:30<01:48, 28.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.35G/10.0G [02:30<01:07, 39.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.74G/9.83G [02:30<01:29, 34.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.31G/11.4G [02:29<01:39, 40.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.36G/10.0G [02:30<00:59, 44.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.75G/9.83G [02:30<01:13, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  64% 7.32G/11.4G [02:29<01:28, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.38G/10.0G [02:30<00:44, 59.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.33G/11.4G [02:30<01:18, 51.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.77G/9.83G [02:30<00:55, 54.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.39G/10.0G [02:30<00:39, 65.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.34G/11.4G [02:30<01:10, 56.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.78G/9.83G [02:30<00:52, 58.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.40G/10.0G [02:30<00:36, 71.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.79G/9.83G [02:30<00:47, 63.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.36G/11.4G [02:30<00:57, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.42G/10.0G [02:31<00:34, 75.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.37G/11.4G [02:30<00:55, 71.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.81G/9.83G [02:31<00:50, 60.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.39G/11.4G [02:30<00:41, 95.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  74% 7.43G/10.0G [02:31<00:41, 61.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  69% 6.83G/9.83G [02:31<00:43, 68.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.41G/11.4G [02:30<00:39, 98.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.84G/9.83G [02:31<00:42, 70.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  75% 7.46G/10.0G [02:31<00:35, 72.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.85G/9.83G [02:31<00:41, 71.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  75% 7.48G/10.0G [02:31<00:26, 93.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.86G/9.83G [02:31<00:43, 68.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  75% 7.50G/10.0G [02:31<00:24, 103MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  65% 7.43G/11.4G [02:31<00:53, 73.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.87G/9.83G [02:31<00:41, 70.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  75% 7.52G/10.0G [02:32<00:21, 114MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.46G/11.4G [02:31<00:44, 87.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.88G/9.83G [02:32<00:42, 69.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  75% 7.54G/10.0G [02:32<00:25, 96.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.48G/11.4G [02:31<00:46, 82.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.89G/9.83G [02:32<00:43, 66.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.49G/11.4G [02:31<00:45, 86.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  76% 7.56G/10.0G [02:32<00:23, 105MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.91G/9.83G [02:32<00:34, 83.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.51G/11.4G [02:32<00:39, 97.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  76% 7.58G/10.0G [02:32<00:21, 115MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  70% 6.92G/9.83G [02:32<00:35, 82.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.53G/11.4G [02:32<00:40, 95.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  76% 7.60G/10.0G [02:32<00:23, 102MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 6.94G/9.83G [02:32<00:34, 84.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.54G/11.4G [02:32<00:43, 87.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 6.95G/9.83G [02:33<00:36, 78.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  66% 7.55G/11.4G [02:32<00:56, 67.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  76% 7.62G/10.0G [02:33<00:30, 78.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 6.96G/9.83G [02:33<00:50, 56.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  76% 7.63G/10.0G [02:33<00:29, 80.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.56G/11.4G [02:32<00:55, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 6.97G/9.83G [02:33<00:44, 63.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  76% 7.64G/10.0G [02:33<00:28, 83.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.57G/11.4G [02:32<00:54, 69.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 6.98G/9.83G [02:33<00:45, 62.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  77% 7.65G/10.0G [02:33<00:30, 75.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.59G/11.4G [02:33<00:42, 87.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  77% 7.67G/10.0G [02:33<00:29, 79.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.60G/11.4G [02:33<00:42, 89.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 6.99G/9.83G [02:33<00:43, 65.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  71% 7.00G/9.83G [02:33<00:38, 72.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  77% 7.69G/10.0G [02:33<00:24, 95.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.62G/11.4G [02:33<00:35, 105MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  77% 7.70G/10.0G [02:34<00:26, 86.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.03G/9.83G [02:34<00:38, 73.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.64G/11.4G [02:33<00:40, 92.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  77% 7.72G/10.0G [02:34<00:23, 95.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.04G/9.83G [02:34<00:37, 73.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.65G/11.4G [02:33<00:45, 82.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.05G/9.83G [02:34<00:39, 71.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  77% 7.73G/10.0G [02:34<00:29, 75.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  67% 7.67G/11.4G [02:33<00:46, 79.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.06G/9.83G [02:34<00:36, 75.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  77% 7.74G/10.0G [02:34<00:28, 79.2MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.75G/10.0G [02:34<00:26, 83.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.69G/11.4G [02:34<00:43, 84.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.07G/9.83G [02:34<00:40, 68.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.77G/10.0G [02:34<00:20, 106MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.08G/9.83G [02:34<00:37, 73.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.71G/11.4G [02:34<00:37, 98.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.72G/11.4G [02:34<00:38, 93.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.79G/10.0G [02:35<00:22, 95.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.73G/11.4G [02:34<00:39, 91.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.80G/10.0G [02:35<00:23, 95.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.10G/9.83G [02:35<00:40, 67.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.74G/11.4G [02:34<00:38, 93.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.81G/10.0G [02:35<00:22, 96.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.75G/11.4G [02:34<00:38, 93.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.82G/10.0G [02:35<00:22, 97.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.76G/11.4G [02:34<00:41, 87.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.83G/10.0G [02:35<00:23, 91.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  72% 7.12G/9.83G [02:35<00:41, 65.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  78% 7.84G/10.0G [02:35<00:23, 91.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  68% 7.78G/11.4G [02:35<00:37, 95.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.14G/9.83G [02:35<00:36, 74.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.85G/10.0G [02:35<00:25, 83.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.79G/11.4G [02:35<00:40, 88.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.86G/10.0G [02:35<00:24, 85.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.15G/9.83G [02:35<00:37, 71.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.80G/11.4G [02:35<00:43, 82.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.87G/10.0G [02:36<00:25, 81.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.81G/11.4G [02:35<00:42, 82.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.89G/10.0G [02:36<00:24, 85.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.17G/9.83G [02:36<00:35, 75.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.82G/11.4G [02:35<00:43, 81.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.18G/9.83G [02:36<00:33, 79.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.91G/10.0G [02:36<00:20, 104MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.19G/9.83G [02:36<00:31, 83.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.84G/11.4G [02:35<00:41, 85.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.92G/10.0G [02:36<00:24, 85.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.20G/9.83G [02:36<00:32, 81.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.93G/10.0G [02:36<00:23, 86.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.85G/11.4G [02:36<00:43, 80.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  73% 7.21G/9.83G [02:36<00:31, 83.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  79% 7.94G/10.0G [02:36<00:23, 88.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.86G/11.4G [02:36<00:41, 83.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.24G/9.83G [02:36<00:29, 87.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 7.95G/10.0G [02:36<00:25, 80.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  69% 7.89G/11.4G [02:36<00:37, 91.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.25G/9.83G [02:37<00:30, 85.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 7.97G/10.0G [02:37<00:20, 99.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.26G/9.83G [02:37<00:31, 80.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 7.98G/10.0G [02:37<00:20, 96.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.91G/11.4G [02:36<00:39, 88.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.27G/9.83G [02:37<00:32, 78.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 7.99G/10.0G [02:37<00:22, 87.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.92G/11.4G [02:36<00:41, 82.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.28G/9.83G [02:37<00:32, 77.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 8.00G/10.0G [02:37<00:23, 85.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.93G/11.4G [02:36<00:41, 82.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 8.01G/10.0G [02:37<00:24, 80.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.94G/11.4G [02:37<00:46, 73.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.30G/9.83G [02:37<00:31, 80.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 8.02G/10.0G [02:37<00:27, 73.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.95G/11.4G [02:37<00:49, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.31G/9.83G [02:37<00:36, 69.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  80% 8.03G/10.0G [02:37<00:28, 69.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.96G/11.4G [02:37<00:49, 69.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  74% 7.32G/9.83G [02:38<00:33, 74.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.05G/10.0G [02:38<00:23, 81.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.97G/11.4G [02:37<00:50, 67.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.33G/9.83G [02:38<00:33, 74.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.06G/10.0G [02:38<00:22, 86.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.35G/9.83G [02:38<00:30, 82.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.98G/11.4G [02:37<01:06, 51.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.07G/10.0G [02:38<00:28, 67.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.36G/9.83G [02:38<00:32, 74.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.08G/10.0G [02:38<00:25, 73.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 7.99G/11.4G [02:38<00:59, 56.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.37G/9.83G [02:38<00:30, 79.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.10G/10.0G [02:38<00:24, 78.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  70% 8.00G/11.4G [02:38<00:52, 64.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.38G/9.83G [02:38<00:30, 80.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.11G/10.0G [02:38<00:25, 74.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.01G/11.4G [02:38<00:54, 61.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.39G/9.83G [02:39<00:33, 71.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.13G/10.0G [02:39<00:23, 79.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  75% 7.40G/9.83G [02:39<00:35, 68.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.03G/11.4G [02:38<00:47, 70.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  81% 8.14G/10.0G [02:39<00:22, 80.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.04G/11.4G [02:38<00:45, 73.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.15G/10.0G [02:39<00:23, 78.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.42G/9.83G [02:39<00:31, 75.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.05G/11.4G [02:38<00:41, 78.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.16G/10.0G [02:39<00:24, 73.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.43G/9.83G [02:39<00:33, 71.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.06G/11.4G [02:39<00:47, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.17G/10.0G [02:39<00:26, 68.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.44G/9.83G [02:39<00:38, 61.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.07G/11.4G [02:39<00:54, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.18G/10.0G [02:39<00:26, 68.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.08G/11.4G [02:39<00:48, 67.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.19G/10.0G [02:40<00:24, 74.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.46G/9.83G [02:40<00:49, 47.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  71% 8.11G/11.4G [02:39<00:44, 73.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.21G/10.0G [02:40<00:22, 79.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.47G/9.83G [02:40<00:46, 50.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.22G/10.0G [02:40<00:23, 76.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.13G/11.4G [02:39<00:39, 81.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.48G/9.83G [02:40<00:43, 54.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.23G/10.0G [02:40<00:22, 77.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.14G/11.4G [02:40<00:41, 77.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.49G/9.83G [02:40<00:39, 58.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  82% 8.24G/10.0G [02:40<00:22, 77.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.15G/11.4G [02:40<00:40, 79.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.50G/9.83G [02:40<00:35, 65.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.25G/10.0G [02:40<00:21, 80.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.16G/11.4G [02:40<00:39, 82.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.26G/10.0G [02:40<00:21, 82.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  76% 7.51G/9.83G [02:40<00:35, 64.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.17G/11.4G [02:40<00:42, 75.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.27G/10.0G [02:41<00:20, 84.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.52G/9.83G [02:41<00:35, 65.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.18G/11.4G [02:40<00:42, 75.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.28G/10.0G [02:41<00:22, 74.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.53G/9.83G [02:41<00:34, 67.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.29G/10.0G [02:41<00:22, 76.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.19G/11.4G [02:40<00:47, 66.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.54G/9.83G [02:41<00:31, 73.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.20G/11.4G [02:40<00:44, 71.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.30G/10.0G [02:41<00:21, 78.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.55G/9.83G [02:41<00:31, 71.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.21G/11.4G [02:41<00:42, 75.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.32G/10.0G [02:41<00:21, 79.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.56G/9.83G [02:41<00:30, 74.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.22G/11.4G [02:41<00:39, 80.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.33G/10.0G [02:41<00:20, 82.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.57G/9.83G [02:43<02:43, 13.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  83% 8.34G/10.0G [02:44<02:03, 13.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  72% 8.23G/11.4G [02:43<03:55, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.58G/9.83G [02:44<02:07, 17.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  84% 8.35G/10.0G [02:44<01:31, 17.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.59G/9.83G [02:44<01:36, 23.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  73% 8.25G/11.4G [02:43<02:16, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  77% 7.61G/9.83G [02:44<00:59, 37.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  84% 8.37G/10.0G [02:44<00:55, 29.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  73% 8.27G/11.4G [02:43<01:30, 34.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  84% 8.38G/10.0G [02:44<00:48, 33.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  73% 8.28G/11.4G [02:43<01:22, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  78% 7.62G/9.83G [02:44<00:54, 40.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  78% 7.63G/9.83G [02:44<00:46, 47.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  84% 8.39G/10.0G [02:44<00:41, 39.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  73% 8.30G/11.4G [02:44<01:00, 50.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  84% 8.40G/10.0G [02:44<00:36, 43.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  78% 7.65G/9.83G [02:44<00:35, 61.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  73% 8.33G/11.4G [02:44<00:47, 63.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  84% 8.42G/10.0G [02:45<00:26, 59.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  78% 7.68G/9.83G [02:45<00:30, 71.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  73% 8.35G/11.4G [02:44<00:44, 67.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  84% 8.43G/10.0G [02:45<00:26, 58.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  78% 7.69G/9.83G [02:45<00:30, 69.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.37G/11.4G [02:44<00:38, 78.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  78% 7.70G/9.83G [02:45<00:29, 72.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.45G/10.0G [02:45<00:22, 68.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  78% 7.71G/9.83G [02:45<00:31, 68.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.39G/11.4G [02:45<00:37, 79.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.47G/10.0G [02:45<00:20, 75.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  79% 7.72G/9.83G [02:45<00:30, 68.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.40G/11.4G [02:45<00:35, 82.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  79% 7.73G/9.83G [02:45<00:31, 67.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.49G/10.0G [02:45<00:18, 83.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.42G/11.4G [02:45<00:33, 88.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  79% 7.74G/9.83G [02:45<00:27, 75.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.50G/10.0G [02:46<00:17, 85.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.43G/11.4G [02:45<00:32, 89.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  79% 7.75G/9.83G [02:46<00:27, 76.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.51G/10.0G [02:46<00:17, 85.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.44G/11.4G [02:45<00:33, 87.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.52G/10.0G [02:46<00:17, 83.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.45G/11.4G [02:45<00:32, 90.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  79% 7.77G/9.83G [02:46<00:23, 86.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.54G/10.0G [02:46<00:17, 83.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  74% 8.46G/11.4G [02:45<00:34, 84.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  85% 8.55G/10.0G [02:46<00:16, 87.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  79% 7.79G/9.83G [02:46<00:21, 94.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.48G/11.4G [02:46<00:28, 99.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  79% 7.80G/9.83G [02:46<00:22, 89.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  86% 8.57G/10.0G [02:46<00:14, 98.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.49G/11.4G [02:46<00:29, 97.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  86% 8.58G/10.0G [02:46<00:14, 98.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.51G/11.4G [02:46<00:26, 106MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.82G/9.83G [02:46<00:23, 85.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  86% 8.60G/10.0G [02:46<00:12, 108MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.83G/9.83G [02:47<00:24, 80.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.54G/11.4G [02:46<00:29, 96.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.84G/9.83G [02:47<00:24, 80.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.56G/11.4G [02:46<00:26, 104MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  86% 8.62G/10.0G [02:47<00:16, 81.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.85G/9.83G [02:47<00:24, 81.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.86G/9.83G [02:47<00:24, 78.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  86% 8.64G/10.0G [02:47<00:15, 89.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.87G/9.83G [02:47<00:25, 75.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  87% 8.66G/10.0G [02:47<00:12, 103MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  75% 8.58G/11.4G [02:47<00:39, 70.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  87% 8.68G/10.0G [02:47<00:12, 103MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.90G/9.83G [02:47<00:23, 81.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  76% 8.60G/11.4G [02:47<00:34, 81.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  80% 7.91G/9.83G [02:47<00:23, 81.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  87% 8.70G/10.0G [02:48<00:12, 106MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 7.92G/9.83G [02:48<00:24, 76.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  76% 8.62G/11.4G [02:47<00:31, 86.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 7.93G/9.83G [02:48<00:23, 81.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  87% 8.72G/10.0G [02:48<00:14, 88.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  76% 8.64G/11.4G [02:47<00:31, 87.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 7.94G/9.83G [02:48<00:25, 74.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  87% 8.73G/10.0G [02:48<00:14, 88.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  76% 8.65G/11.4G [02:47<00:30, 88.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 7.95G/9.83G [02:48<00:24, 77.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 7.96G/9.83G [02:48<00:22, 81.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.76G/10.0G [02:48<00:13, 91.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  76% 8.67G/11.4G [02:48<00:27, 96.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 7.97G/9.83G [02:48<00:21, 84.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.77G/10.0G [02:48<00:13, 91.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.69G/11.4G [02:48<00:24, 108MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 7.98G/9.83G [02:48<00:22, 80.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.78G/10.0G [02:48<00:14, 81.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.71G/11.4G [02:48<00:22, 116MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 7.99G/9.83G [02:49<00:23, 77.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.79G/10.0G [02:49<00:15, 76.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  81% 8.00G/9.83G [02:49<00:22, 81.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.73G/11.4G [02:48<00:28, 93.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.01G/9.83G [02:49<00:23, 76.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.81G/10.0G [02:49<00:14, 82.3MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.82G/10.0G [02:49<00:14, 79.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.76G/11.4G [02:48<00:28, 92.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.03G/9.83G [02:49<00:21, 82.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.83G/10.0G [02:49<00:13, 84.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.77G/11.4G [02:49<00:28, 92.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.04G/9.83G [02:49<00:21, 84.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  88% 8.84G/10.0G [02:49<00:13, 84.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.78G/11.4G [02:49<00:29, 89.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.05G/9.83G [02:49<00:21, 81.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.85G/10.0G [02:49<00:14, 81.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.79G/11.4G [02:49<00:31, 82.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.06G/9.83G [02:49<00:22, 77.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.86G/10.0G [02:50<00:14, 77.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  77% 8.80G/11.4G [02:53<04:29, 9.50MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.07G/9.83G [02:54<03:29, 8.36MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.87G/10.0G [02:54<02:21, 7.95MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.08G/9.83G [02:54<02:40, 10.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.81G/11.4G [02:53<03:38, 11.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.10G/9.83G [02:54<01:59, 14.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.82G/11.4G [02:53<02:46, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.89G/10.0G [02:54<01:21, 13.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  82% 8.11G/9.83G [02:54<01:29, 19.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.90G/10.0G [02:54<01:04, 17.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.12G/9.83G [02:54<01:10, 24.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.84G/11.4G [02:54<01:46, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.91G/10.0G [02:54<00:51, 20.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.85G/11.4G [02:54<01:28, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.13G/9.83G [02:54<00:57, 29.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.92G/10.0G [02:55<00:42, 25.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.86G/11.4G [02:54<01:16, 32.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.14G/9.83G [02:55<00:47, 35.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.93G/10.0G [02:55<00:34, 30.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.15G/9.83G [02:55<00:39, 42.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.87G/11.4G [02:54<01:06, 37.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  89% 8.94G/10.0G [02:55<00:27, 37.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.88G/11.4G [02:54<00:55, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.16G/9.83G [02:55<00:33, 49.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.17G/9.83G [02:55<00:28, 58.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 8.95G/10.0G [02:55<00:24, 42.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.89G/11.4G [02:54<00:50, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.19G/9.83G [02:55<00:20, 80.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.90G/11.4G [02:55<00:43, 56.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 8.97G/10.0G [02:55<00:22, 46.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  83% 8.20G/9.83G [02:55<00:19, 83.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 8.98G/10.0G [02:55<00:18, 54.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  78% 8.91G/11.4G [02:55<00:39, 61.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.21G/9.83G [02:55<00:18, 85.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 9.00G/10.0G [02:55<00:12, 77.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  79% 8.93G/11.4G [02:55<00:29, 81.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.22G/9.83G [02:55<00:19, 82.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 9.01G/10.0G [02:56<00:13, 76.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  79% 8.95G/11.4G [02:55<00:24, 99.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.23G/9.83G [02:56<00:19, 79.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 9.02G/10.0G [02:56<00:12, 78.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.24G/9.83G [02:56<00:19, 80.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 9.03G/10.0G [02:56<00:12, 74.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  79% 8.98G/11.4G [02:55<00:26, 88.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.25G/9.83G [02:56<00:19, 82.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  90% 9.04G/10.0G [02:56<00:11, 80.4MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.26G/9.83G [02:56<00:19, 79.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  79% 9.00G/11.4G [02:55<00:24, 95.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.05G/10.0G [02:56<00:13, 70.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  79% 9.01G/11.4G [02:56<00:25, 92.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.27G/9.83G [02:56<00:22, 67.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.06G/10.0G [02:56<00:12, 74.5MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.28G/9.83G [02:56<00:20, 75.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  79% 9.03G/11.4G [02:56<00:23, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.07G/10.0G [02:56<00:12, 75.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  84% 8.29G/9.83G [02:56<00:20, 76.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.04G/11.4G [02:56<00:24, 95.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.08G/10.0G [02:56<00:11, 80.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.32G/9.83G [02:57<00:17, 85.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.10G/10.0G [02:57<00:10, 88.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.06G/11.4G [02:56<00:25, 90.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.11G/10.0G [02:57<00:10, 86.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.07G/11.4G [02:56<00:25, 89.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.34G/9.83G [02:57<00:17, 87.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.08G/11.4G [02:56<00:25, 90.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.35G/9.83G [02:57<00:16, 87.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.13G/10.0G [02:57<00:09, 90.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.09G/11.4G [02:57<00:26, 85.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.36G/9.83G [02:57<00:18, 77.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  91% 9.14G/10.0G [02:57<00:10, 79.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.10G/11.4G [02:57<00:29, 77.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.38G/9.83G [02:57<00:16, 87.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  92% 9.16G/10.0G [02:57<00:09, 89.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.39G/9.83G [02:57<00:16, 88.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.11G/11.4G [02:57<00:36, 61.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  92% 9.19G/10.0G [02:58<00:07, 101MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  85% 8.40G/9.83G [02:58<00:16, 84.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  80% 9.13G/11.4G [02:57<00:28, 77.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  92% 9.21G/10.0G [02:58<00:07, 108MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.15G/11.4G [02:57<00:25, 87.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  92% 9.23G/10.0G [02:58<00:07, 107MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.16G/11.4G [02:57<00:24, 90.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.41G/9.83G [02:58<00:25, 56.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.25G/10.0G [02:58<00:06, 111MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.18G/11.4G [02:58<00:25, 85.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.42G/9.83G [02:58<00:23, 59.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.27G/10.0G [02:58<00:06, 114MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.43G/9.83G [02:58<00:21, 64.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.20G/11.4G [02:58<00:22, 94.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.22G/11.4G [02:58<00:20, 102MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.45G/9.83G [02:58<00:19, 72.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.29G/10.0G [02:59<00:07, 101MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.23G/11.4G [02:58<00:20, 102MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.47G/9.83G [02:59<00:16, 79.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  81% 9.25G/11.4G [02:58<00:18, 115MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.30G/10.0G [02:59<00:09, 74.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.48G/9.83G [02:59<00:16, 80.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  82% 9.27G/11.4G [02:58<00:16, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.31G/10.0G [02:59<00:08, 77.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  86% 8.49G/9.83G [02:59<00:16, 80.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  82% 9.29G/11.4G [02:58<00:15, 132MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.33G/10.0G [02:59<00:08, 82.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.50G/9.83G [02:59<00:18, 71.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  82% 9.31G/11.4G [02:59<00:18, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.51G/9.83G [02:59<00:16, 77.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  93% 9.34G/10.0G [02:59<00:08, 79.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  82% 9.33G/11.4G [02:59<00:16, 120MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.54G/9.83G [02:59<00:14, 88.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.36G/10.0G [03:00<00:07, 85.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.55G/9.83G [03:00<00:14, 85.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  82% 9.35G/11.4G [02:59<00:19, 105MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.38G/10.0G [03:00<00:07, 86.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.56G/9.83G [03:00<00:16, 77.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.57G/9.83G [03:00<00:15, 82.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.41G/10.0G [03:00<00:06, 96.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.58G/9.83G [03:00<00:14, 83.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.37G/11.4G [02:59<00:23, 85.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  94% 9.43G/10.0G [03:00<00:05, 106MB/s] \u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  87% 8.59G/9.83G [03:00<00:15, 79.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.40G/11.4G [03:00<00:21, 89.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.60G/9.83G [03:00<00:14, 82.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.41G/11.4G [03:00<00:22, 85.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.61G/9.83G [03:00<00:14, 85.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.45G/10.0G [03:00<00:06, 90.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.42G/11.4G [03:00<00:22, 85.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.46G/10.0G [03:01<00:06, 87.9MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.62G/9.83G [03:01<00:16, 71.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.63G/9.83G [03:01<00:15, 77.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.44G/11.4G [03:00<00:22, 86.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.48G/10.0G [03:01<00:06, 84.1MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.64G/9.83G [03:01<00:19, 61.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.45G/11.4G [03:00<00:28, 67.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.49G/10.0G [03:01<00:07, 65.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.46G/11.4G [03:01<00:28, 66.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.65G/9.83G [03:01<00:21, 54.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.51G/10.0G [03:01<00:05, 82.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.47G/11.4G [03:01<00:26, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.66G/9.83G [03:01<00:18, 63.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.52G/10.0G [03:01<00:05, 80.8MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.67G/9.83G [03:01<00:17, 66.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  83% 9.48G/11.4G [03:01<00:26, 70.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  88% 8.68G/9.83G [03:02<00:17, 64.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  84% 9.49G/11.4G [03:01<00:27, 68.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  95% 9.54G/10.0G [03:02<00:05, 78.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.70G/9.83G [03:02<00:13, 83.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  84% 9.50G/11.4G [03:01<00:27, 66.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  96% 9.55G/10.0G [03:02<00:05, 79.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.71G/9.83G [03:02<00:13, 84.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  84% 9.52G/11.4G [03:01<00:22, 80.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.72G/9.83G [03:02<00:12, 87.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  96% 9.57G/10.0G [03:02<00:04, 85.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  84% 9.54G/11.4G [03:02<00:17, 101MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.73G/9.83G [03:02<00:12, 87.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  96% 9.59G/10.0G [03:02<00:03, 102MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  84% 9.56G/11.4G [03:02<00:15, 119MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.75G/9.83G [03:02<00:12, 87.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  96% 9.62G/10.0G [03:02<00:03, 101MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.76G/9.83G [03:02<00:12, 85.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  84% 9.58G/11.4G [03:02<00:16, 111MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.77G/9.83G [03:03<00:13, 80.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  96% 9.64G/10.0G [03:03<00:03, 101MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.78G/9.83G [03:03<00:12, 84.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.60G/11.4G [03:02<00:16, 106MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  89% 8.79G/9.83G [03:03<00:13, 79.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.63G/11.4G [03:02<00:19, 87.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  97% 9.66G/10.0G [03:03<00:04, 75.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 8.80G/9.83G [03:03<00:15, 67.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.64G/11.4G [03:03<00:19, 89.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  97% 9.67G/10.0G [03:03<00:04, 78.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 8.81G/9.83G [03:03<00:14, 72.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.66G/11.4G [03:03<00:17, 98.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 8.82G/9.83G [03:03<00:14, 69.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  97% 9.69G/10.0G [03:03<00:03, 87.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.68G/11.4G [03:03<00:15, 112MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 8.83G/9.83G [03:03<00:13, 72.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  97% 9.70G/10.0G [03:03<00:03, 85.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  85% 9.70G/11.4G [03:03<00:14, 112MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  97% 9.72G/10.0G [03:04<00:02, 95.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 8.85G/9.83G [03:04<00:11, 82.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.72G/11.4G [03:03<00:16, 97.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 8.86G/9.83G [03:05<00:48, 20.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  97% 9.74G/10.0G [03:06<00:11, 21.3MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  90% 8.87G/9.83G [03:06<00:52, 18.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.74G/11.4G [03:06<01:07, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  98% 9.76G/10.0G [03:06<00:08, 28.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 8.89G/9.83G [03:06<00:33, 27.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  98% 9.77G/10.0G [03:06<00:06, 33.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.76G/11.4G [03:06<00:51, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 8.90G/9.83G [03:06<00:28, 32.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  98% 9.78G/10.0G [03:07<00:05, 37.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.77G/11.4G [03:06<00:45, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 8.91G/9.83G [03:07<00:24, 37.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  98% 9.79G/10.0G [03:07<00:04, 42.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.78G/11.4G [03:06<00:40, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 8.92G/9.83G [03:07<00:22, 39.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  98% 9.80G/10.0G [03:07<00:04, 46.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.79G/11.4G [03:06<00:36, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 8.93G/9.83G [03:08<00:43, 20.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.80G/11.4G [03:07<01:08, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  98% 9.81G/10.0G [03:08<00:08, 22.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 8.94G/9.83G [03:08<00:33, 26.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  86% 9.81G/11.4G [03:08<00:54, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 8.95G/9.83G [03:08<00:25, 33.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  98% 9.84G/10.0G [03:08<00:04, 33.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.84G/11.4G [03:08<00:38, 40.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.85G/10.0G [03:08<00:03, 37.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 8.98G/9.83G [03:08<00:17, 48.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  91% 8.99G/9.83G [03:08<00:15, 55.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.86G/11.4G [03:08<00:29, 50.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.87G/10.0G [03:09<00:02, 48.6MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.00G/9.83G [03:09<00:14, 58.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.87G/11.4G [03:08<00:29, 51.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.01G/9.83G [03:09<00:12, 63.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.89G/10.0G [03:09<00:01, 62.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.88G/11.4G [03:08<00:26, 55.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.02G/9.83G [03:09<00:12, 65.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.90G/10.0G [03:09<00:01, 64.7MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.03G/9.83G [03:09<00:11, 71.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.91G/10.0G [03:09<00:01, 68.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.90G/11.4G [03:09<00:21, 69.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.92G/10.0G [03:09<00:01, 72.2MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.04G/9.83G [03:09<00:11, 69.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.91G/11.4G [03:09<00:19, 73.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.92G/11.4G [03:09<00:20, 70.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.05G/9.83G [03:09<00:11, 64.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  99% 9.94G/10.0G [03:09<00:00, 77.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.93G/11.4G [03:09<00:19, 73.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.07G/9.83G [03:10<00:08, 85.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  87% 9.94G/11.4G [03:09<00:20, 69.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  92% 9.08G/9.83G [03:10<00:09, 81.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors: 100% 9.96G/10.0G [03:10<00:00, 76.8MB/s]\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors: 100% 9.97G/10.0G [03:10<00:00, 79.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  88% 9.96G/11.4G [03:09<00:18, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.10G/9.83G [03:10<00:09, 78.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors: 100% 9.98G/10.0G [03:10<00:00, 74.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  88% 9.97G/11.4G [03:09<00:17, 78.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00002-of-00003.safetensors: 100% 9.99G/10.0G [03:10<00:00, 80.0MB/s]\u001b[A\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors: 100% 10.0G/10.0G [03:10<00:00, 52.4MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/diffusion_pytorch_model-00002-of-00003.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  88% 9.99G/11.4G [03:10<00:17, 78.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.13G/9.83G [03:10<00:08, 84.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  88% 10.0G/11.4G [03:10<00:15, 89.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.15G/9.83G [03:10<00:07, 95.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  88% 10.0G/11.4G [03:10<00:12, 110MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.16G/9.83G [03:11<00:07, 92.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  89% 10.1G/11.4G [03:10<00:09, 139MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.18G/9.83G [03:11<00:07, 91.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  93% 9.19G/9.83G [03:11<00:07, 90.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  89% 10.1G/11.4G [03:10<00:10, 121MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.20G/9.83G [03:11<00:07, 89.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  89% 10.1G/11.4G [03:11<00:09, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.21G/9.83G [03:11<00:07, 85.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  89% 10.1G/11.4G [03:11<00:09, 135MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.22G/9.83G [03:11<00:07, 82.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  89% 10.2G/11.4G [03:11<00:08, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.23G/9.83G [03:11<00:07, 80.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  90% 10.2G/11.4G [03:11<00:07, 150MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.24G/9.83G [03:11<00:06, 85.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.25G/9.83G [03:12<00:06, 87.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  90% 10.2G/11.4G [03:11<00:07, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.26G/9.83G [03:12<00:06, 87.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  90% 10.2G/11.4G [03:11<00:06, 166MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  90% 10.2G/11.4G [03:11<00:06, 173MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.27G/9.83G [03:12<00:06, 82.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  90% 10.3G/11.4G [03:11<00:05, 193MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  91% 10.3G/11.4G [03:12<00:05, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  94% 9.28G/9.83G [03:12<00:09, 55.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  91% 10.3G/11.4G [03:12<00:04, 212MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.29G/9.83G [03:12<00:08, 62.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  91% 10.4G/11.4G [03:12<00:05, 190MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.31G/9.83G [03:12<00:06, 81.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  91% 10.4G/11.4G [03:12<00:05, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.32G/9.83G [03:13<00:06, 82.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.33G/9.83G [03:13<00:05, 84.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  92% 10.4G/11.4G [03:12<00:05, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.34G/9.83G [03:13<00:06, 80.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  92% 10.4G/11.4G [03:12<00:05, 183MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.35G/9.83G [03:13<00:05, 84.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  92% 10.5G/11.4G [03:12<00:04, 188MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.36G/9.83G [03:13<00:05, 85.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  95% 9.37G/9.83G [03:13<00:05, 86.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  92% 10.5G/11.4G [03:13<00:06, 141MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.38G/9.83G [03:13<00:05, 83.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  92% 10.5G/11.4G [03:13<00:05, 147MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.40G/9.83G [03:13<00:05, 84.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  93% 10.5G/11.4G [03:13<00:04, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.41G/9.83G [03:14<00:04, 84.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  93% 10.6G/11.4G [03:13<00:04, 179MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.42G/9.83G [03:14<00:04, 85.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  93% 10.6G/11.4G [03:13<00:04, 171MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.43G/9.83G [03:14<00:04, 85.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.44G/9.83G [03:14<00:04, 87.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  93% 10.6G/11.4G [03:14<00:06, 114MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.45G/9.83G [03:14<00:04, 82.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.46G/9.83G [03:14<00:04, 82.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  94% 10.6G/11.4G [03:14<00:05, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.47G/9.83G [03:14<00:04, 84.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  94% 10.7G/11.4G [03:14<00:04, 164MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  96% 9.48G/9.83G [03:14<00:04, 79.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  94% 10.7G/11.4G [03:14<00:03, 172MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.49G/9.83G [03:15<00:04, 79.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  94% 10.7G/11.4G [03:18<00:31, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.50G/9.83G [03:18<00:37, 8.62MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.7G/11.4G [03:18<00:23, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.52G/9.83G [03:19<00:20, 15.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.8G/11.4G [03:18<00:18, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.54G/9.83G [03:19<00:12, 23.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.8G/11.4G [03:18<00:13, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.55G/9.83G [03:19<00:10, 26.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.8G/11.4G [03:18<00:10, 52.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.56G/9.83G [03:19<00:08, 31.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  97% 9.57G/9.83G [03:19<00:06, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.8G/11.4G [03:19<00:08, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.58G/9.83G [03:19<00:05, 44.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  95% 10.8G/11.4G [03:19<00:07, 73.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.60G/9.83G [03:19<00:03, 58.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  96% 10.9G/11.4G [03:19<00:06, 80.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.62G/9.83G [03:20<00:03, 62.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  96% 10.9G/11.4G [03:19<00:05, 89.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.63G/9.83G [03:20<00:03, 64.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  96% 10.9G/11.4G [03:19<00:03, 114MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.64G/9.83G [03:20<00:02, 67.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  96% 10.9G/11.4G [03:19<00:03, 122MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.65G/9.83G [03:20<00:02, 71.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  96% 11.0G/11.4G [03:20<00:02, 138MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.66G/9.83G [03:20<00:02, 74.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  97% 11.0G/11.4G [03:20<00:02, 134MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  98% 9.67G/9.83G [03:20<00:02, 74.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  97% 11.0G/11.4G [03:20<00:02, 127MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.68G/9.83G [03:20<00:02, 70.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  97% 11.0G/11.4G [03:20<00:02, 124MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.70G/9.83G [03:21<00:01, 75.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  97% 11.0G/11.4G [03:20<00:02, 128MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.71G/9.83G [03:21<00:01, 74.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.72G/9.83G [03:24<00:10, 10.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.74G/9.83G [03:25<00:04, 16.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  97% 11.1G/11.4G [03:24<00:18, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.75G/9.83G [03:25<00:03, 20.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  98% 11.1G/11.4G [03:24<00:10, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.76G/9.83G [03:25<00:02, 25.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  98% 11.1G/11.4G [03:24<00:06, 37.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  99% 9.77G/9.83G [03:25<00:01, 29.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  98% 11.1G/11.4G [03:25<00:04, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors: 100% 9.78G/9.83G [03:25<00:01, 36.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  98% 11.2G/11.4G [03:25<00:03, 57.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors: 100% 9.79G/9.83G [03:25<00:00, 42.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  98% 11.2G/11.4G [03:25<00:02, 69.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors: 100% 9.80G/9.83G [03:25<00:00, 50.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  99% 11.2G/11.4G [03:25<00:01, 83.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  99% 11.2G/11.4G [03:25<00:01, 100MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors: 100% 9.81G/9.83G [03:26<00:00, 54.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  99% 11.3G/11.4G [03:25<00:00, 129MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors: 100% 9.83G/9.83G [03:26<00:00, 47.6MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/diffusion_pytorch_model-00001-of-00003.safetensors\n",
            "Fetching 23 files:  61% 14/23 [03:26<02:15, 15.10s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  99% 11.3G/11.4G [03:25<00:00, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth: 100% 11.3G/11.4G [03:25<00:00, 159MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth: 100% 11.4G/11.4G [03:26<00:00, 55.1MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/models_t5_umt5-xxl-enc-bf16.pth\n",
            "Fetching 23 files: 100% 23/23 [03:27<00:00,  9.00s/it]\n",
            "/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/Wan2.2-TI2V-5B\n",
            "🎬 Starting WahDrobe trailer generation...\n",
            "\n",
            "🎥 Generating Scene 1: Close-up of a frustrated young person staring at a messy clo...\n",
            "❌ Error generating Scene 1:\n",
            "Error: Traceback (most recent call last):\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/generate.py\", line 17, in <module>\n",
            "    import wan\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/__init__.py\", line 2, in <module>\n",
            "    from . import configs, distributed, modules\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/__init__.py\", line 2, in <module>\n",
            "    from .attention import flash_attention\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/attention.py\", line 11, in <module>\n",
            "    import flash_attn\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/__init__.py\", line 3, in <module>\n",
            "    from flash_attn.flash_attn_interface import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 15, in <module>\n",
            "    import flash_attn_2_cuda as flash_attn_gpu\n",
            "ImportError: /usr/local/lib/python3.11/dist-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
            "\n",
            "\n",
            "🎥 Generating Scene 2: Smooth animation of a modern smartphone mockup with WahDrobe...\n",
            "❌ Error generating Scene 2:\n",
            "Error: Traceback (most recent call last):\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/generate.py\", line 17, in <module>\n",
            "    import wan\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/__init__.py\", line 2, in <module>\n",
            "    from . import configs, distributed, modules\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/__init__.py\", line 2, in <module>\n",
            "    from .attention import flash_attention\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/attention.py\", line 11, in <module>\n",
            "    import flash_attn\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/__init__.py\", line 3, in <module>\n",
            "    from flash_attn.flash_attn_interface import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 15, in <module>\n",
            "    import flash_attn_2_cuda as flash_attn_gpu\n",
            "ImportError: /usr/local/lib/python3.11/dist-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
            "\n",
            "\n",
            "🎥 Generating Scene 3: Weather widget showing 34 degrees Celsius Delhi, fashion app...\n",
            "❌ Error generating Scene 3:\n",
            "Error: Traceback (most recent call last):\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/generate.py\", line 17, in <module>\n",
            "    import wan\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/__init__.py\", line 2, in <module>\n",
            "    from . import configs, distributed, modules\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/__init__.py\", line 2, in <module>\n",
            "    from .attention import flash_attention\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/attention.py\", line 11, in <module>\n",
            "    import flash_attn\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/__init__.py\", line 3, in <module>\n",
            "    from flash_attn.flash_attn_interface import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 15, in <module>\n",
            "    import flash_attn_2_cuda as flash_attn_gpu\n",
            "ImportError: /usr/local/lib/python3.11/dist-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
            "\n",
            "\n",
            "🎥 Generating Scene 4: Split screen showing confident person walking in stylish rec...\n",
            "❌ Error generating Scene 4:\n",
            "Error: Traceback (most recent call last):\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/generate.py\", line 17, in <module>\n",
            "    import wan\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/__init__.py\", line 2, in <module>\n",
            "    from . import configs, distributed, modules\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/__init__.py\", line 2, in <module>\n",
            "    from .attention import flash_attention\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/attention.py\", line 11, in <module>\n",
            "    import flash_attn\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/__init__.py\", line 3, in <module>\n",
            "    from flash_attn.flash_attn_interface import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 15, in <module>\n",
            "    import flash_attn_2_cuda as flash_attn_gpu\n",
            "ImportError: /usr/local/lib/python3.11/dist-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
            "\n",
            "\n",
            "🎥 Generating Scene 5: Elegant cinematic outro with floating fashion icons dress sh...\n",
            "❌ Error generating Scene 5:\n",
            "Error: Traceback (most recent call last):\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/generate.py\", line 17, in <module>\n",
            "    import wan\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/__init__.py\", line 2, in <module>\n",
            "    from . import configs, distributed, modules\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/__init__.py\", line 2, in <module>\n",
            "    from .attention import flash_attention\n",
            "  File \"/content/Kolors/Kolors/Kolors/Kolors/Kolors/Wan2.2/wan/modules/attention.py\", line 11, in <module>\n",
            "    import flash_attn\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/__init__.py\", line 3, in <module>\n",
            "    from flash_attn.flash_attn_interface import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flash_attn/flash_attn_interface.py\", line 15, in <module>\n",
            "    import flash_attn_2_cuda as flash_attn_gpu\n",
            "ImportError: /usr/local/lib/python3.11/dist-packages/flash_attn_2_cuda.cpython-311-x86_64-linux-gnu.so: undefined symbol: _ZN3c105ErrorC2ENS_14SourceLocationENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE\n",
            "\n",
            "❌ No scenes were successfully generated\n",
            "\n",
            "🎉 Generation complete! Check the wahdrobe_scenes folder for individual scenes\n",
            "📁 Final trailer: final_wahdrobe_trailer.mp4\n",
            "\n",
            "💡 To generate a single scene manually, use:\n",
            "python generate.py --task ti2v-5B --size 1280*704 --ckpt_dir ./Wan2.2-TI2V-5B --offload_model True --convert_model_dtype --t5_cpu --prompt 'Your prompt here'\n",
            "\n",
            "📋 System Requirements for Wan2.2-TI2V-5B:\n",
            "• GPU: RTX 4090 (24GB VRAM) or better\n",
            "• With optimizations (--offload_model, --convert_model_dtype, --t5_cpu)\n",
            "• Generates 720P videos at 24fps\n",
            "• ~9 minutes for 5-second video on single consumer GPU\n",
            "\n",
            "🚀 For faster generation:\n",
            "• Use 80GB VRAM GPU and remove optimization flags\n",
            "• Use multi-GPU setup with: torchrun --nproc_per_node=8 generate.py ...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# WahDrobe Video Trailer Generator - Google Colab Optimized\n",
        "# Using Wan2.2-TI2V-5B Model\n",
        "# ===============================\n",
        "\n",
        "# ===============================\n",
        "# 1. Check GPU and setup environment\n",
        "# ===============================\n",
        "!nvidia-smi\n",
        "import torch\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU'}\")\n",
        "\n",
        "# ===============================\n",
        "# 2. Clone repository and install dependencies\n",
        "# ===============================\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "# Clone the Wan2.2 repository\n",
        "!git clone https://github.com/Wan-Video/Wan2.2.git\n",
        "os.chdir('/content/Wan2.2')\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -r requirements.txt\n",
        "!pip install imageio[ffmpeg] ffmpeg-python\n",
        "\n",
        "# ===============================\n",
        "# 3. Download the Wan2.2-TI2V-5B model\n",
        "# ===============================\n",
        "print(\"📥 Downloading Wan2.2-TI2V-5B model (this may take several minutes)...\")\n",
        "\n",
        "# Install huggingface_hub if not available\n",
        "!pip install -q \"huggingface_hub[cli]\"\n",
        "\n",
        "# Download the model\n",
        "!huggingface-cli download Wan-AI/Wan2.2-TI2V-5B --local-dir ./Wan2.2-TI2V-5B\n",
        "\n",
        "print(\"✅ Model download completed!\")\n",
        "\n",
        "# ===============================\n",
        "# 4. Define WahDrobe trailer scenes\n",
        "# ===============================\n",
        "scenes = [\n",
        "    {\n",
        "        \"prompt\": \"Close-up cinematic shot of a frustrated young person staring at messy closet full of scattered clothes, dramatic lighting, fashion photography style, high quality 4K\",\n",
        "        \"scene_name\": \"closet_problem\",\n",
        "        \"description\": \"Opening - The Problem\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Elegant 3D animation of modern smartphone with WahDrobe app logo glowing in pink purple gradient, premium tech aesthetic, soft pastel background, high quality\",\n",
        "        \"scene_name\": \"app_logo\",\n",
        "        \"description\": \"App Introduction\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Clean UI animation showing weather app displaying 34°C Delhi temperature, fashion app recommending white t-shirt blue jeans sneakers outfit, rating showing 71 percent match\",\n",
        "        \"scene_name\": \"weather_recommendation\",\n",
        "        \"description\": \"Weather-Based Recommendation\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Split screen cinematic shot: confident person walking outdoors in recommended stylish outfit, smartphone screen showing positive fashion feedback with heart emojis and text\",\n",
        "        \"scene_name\": \"confident_result\",\n",
        "        \"description\": \"Happy Customer\"\n",
        "    },\n",
        "    {\n",
        "        \"prompt\": \"Premium outro animation with floating fashion icons including dress shirt shoes handbag, soft gradient background, Coming Soon text with App Store Google Play badges\",\n",
        "        \"scene_name\": \"app_store_outro\",\n",
        "        \"description\": \"Call to Action\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# ===============================\n",
        "# 5. Helper functions for Colab\n",
        "# ===============================\n",
        "import subprocess\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "def run_generation(prompt, output_name, scene_desc):\n",
        "    \"\"\"Run video generation with proper error handling for Colab\"\"\"\n",
        "    print(f\"\\n🎬 Generating: {scene_desc}\")\n",
        "    print(f\"📝 Prompt: {prompt[:80]}...\")\n",
        "\n",
        "    # Create command for Wan2.2 generation\n",
        "    cmd = [\n",
        "        \"python\", \"generate.py\",\n",
        "        \"--task\", \"ti2v-5B\",\n",
        "        \"--size\", \"1280*704\",           # 720P resolution\n",
        "        \"--ckpt_dir\", \"./Wan2.2-TI2V-5B\",\n",
        "        \"--offload_model\", \"True\",      # Essential for Colab GPU memory\n",
        "        \"--convert_model_dtype\",        # Optimize memory usage\n",
        "        \"--t5_cpu\",                     # Move T5 to CPU\n",
        "        \"--prompt\", prompt\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        start_time = time.time()\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=1200,  # 20 minute timeout for Colab\n",
        "            cwd=\"/content/Wan2.2\"\n",
        "        )\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            print(f\"✅ Success! Generated in {generation_time:.1f} seconds\")\n",
        "            print(f\"📁 Output saved in the generation directory\")\n",
        "            return True\n",
        "        else:\n",
        "            print(f\"❌ Generation failed!\")\n",
        "            print(f\"Error output: {result.stderr}\")\n",
        "            return False\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(f\"⏰ Generation timed out after 20 minutes\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Unexpected error: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "# ===============================\n",
        "# 6. Create output directory\n",
        "# ===============================\n",
        "output_dir = Path(\"/content/wahdrobe_trailer\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "successful_generations = []\n",
        "\n",
        "# ===============================\n",
        "# 7. Generate each scene\n",
        "# ===============================\n",
        "print(\"🚀 Starting WahDrobe trailer generation...\")\n",
        "print(f\"📊 Total scenes to generate: {len(scenes)}\")\n",
        "\n",
        "for idx, scene in enumerate(scenes, 1):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"🎥 SCENE {idx}/{len(scenes)}: {scene['description']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    success = run_generation(\n",
        "        scene[\"prompt\"],\n",
        "        scene[\"scene_name\"],\n",
        "        scene[\"description\"]\n",
        "    )\n",
        "\n",
        "    if success:\n",
        "        successful_generations.append(f\"scene_{idx}_{scene['scene_name']}\")\n",
        "\n",
        "    # Add a small delay between generations to avoid memory issues\n",
        "    if idx < len(scenes):\n",
        "        print(\"⏳ Waiting 30 seconds before next generation...\")\n",
        "        time.sleep(30)\n",
        "\n",
        "# ===============================\n",
        "# 8. Results summary\n",
        "# ===============================\n",
        "print(f\"\\n🎉 GENERATION COMPLETE!\")\n",
        "print(f\"✅ Successfully generated: {len(successful_generations)}/{len(scenes)} scenes\")\n",
        "\n",
        "if successful_generations:\n",
        "    print(f\"\\n📁 Generated scenes:\")\n",
        "    for scene in successful_generations:\n",
        "        print(f\"   • {scene}\")\n",
        "\n",
        "    print(f\"\\n📂 Check the output directory for generated videos\")\n",
        "    print(f\"💡 Videos are typically saved in the Wan2.2 directory with .mp4 extension\")\n",
        "else:\n",
        "    print(f\"❌ No scenes were successfully generated\")\n",
        "\n",
        "# ===============================\n",
        "# 9. List generated files\n",
        "# ===============================\n",
        "print(f\"\\n📋 Searching for generated video files...\")\n",
        "\n",
        "# Look for generated videos in common locations\n",
        "search_paths = [\n",
        "    \"/content/Wan2.2\",\n",
        "    \"/content/Wan2.2/outputs\",\n",
        "    \"/content/Wan2.2/results\",\n",
        "    \"/content\"\n",
        "]\n",
        "\n",
        "video_files = []\n",
        "for path in search_paths:\n",
        "    if os.path.exists(path):\n",
        "        for file in Path(path).rglob(\"*.mp4\"):\n",
        "            video_files.append(str(file))\n",
        "\n",
        "if video_files:\n",
        "    print(f\"🎬 Found {len(video_files)} video files:\")\n",
        "    for video in video_files:\n",
        "        print(f\"   📹 {video}\")\n",
        "else:\n",
        "    print(f\"🔍 No .mp4 files found. Check the Wan2.2 directory manually.\")\n",
        "\n",
        "# ===============================\n",
        "# 10. Video merging (if multiple videos found)\n",
        "# ===============================\n",
        "if len(video_files) > 1:\n",
        "    print(f\"\\n🔗 Attempting to merge videos into final trailer...\")\n",
        "\n",
        "    # Create file list for ffmpeg\n",
        "    filelist_path = \"/content/wahdrobe_trailer/filelist.txt\"\n",
        "    with open(filelist_path, \"w\") as f:\n",
        "        for video in sorted(video_files):\n",
        "            f.write(f\"file '{video}'\\n\")\n",
        "\n",
        "    # Merge command\n",
        "    merge_cmd = [\n",
        "        \"ffmpeg\", \"-y\",\n",
        "        \"-f\", \"concat\",\n",
        "        \"-safe\", \"0\",\n",
        "        \"-i\", filelist_path,\n",
        "        \"-c\", \"copy\",\n",
        "        \"/content/wahdrobe_trailer/final_wahdrobe_trailer.mp4\"\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        subprocess.run(merge_cmd, check=True)\n",
        "        print(f\"✅ Final trailer created: /content/wahdrobe_trailer/final_wahdrobe_trailer.mp4\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        print(f\"❌ Error merging videos: {e}\")\n",
        "\n",
        "# ===============================\n",
        "# 11. Download instructions for Colab\n",
        "# ===============================\n",
        "print(f\"\"\"\n",
        "📥 TO DOWNLOAD YOUR VIDEOS:\n",
        "\n",
        "1. Use the Colab file browser (📁 icon on the left)\n",
        "2. Navigate to /content/wahdrobe_trailer/ or /content/Wan2.2/\n",
        "3. Right-click on .mp4 files and select \"Download\"\n",
        "\n",
        "OR use code:\n",
        "\"\"\")\n",
        "\n",
        "print(\"\"\"\n",
        "from google.colab import files\n",
        "\n",
        "# Download individual scenes\n",
        "for video in video_files:\n",
        "    try:\n",
        "        files.download(video)\n",
        "    except:\n",
        "        print(f\"Could not download {video}\")\n",
        "\n",
        "# Download final trailer if it exists\n",
        "if os.path.exists(\"/content/wahdrobe_trailer/final_wahdrobe_trailer.mp4\"):\n",
        "    files.download(\"/content/wahdrobe_trailer/final_wahdrobe_trailer.mp4\")\n",
        "\"\"\")\n",
        "\n",
        "# ===============================\n",
        "# 12. Troubleshooting info\n",
        "# ===============================\n",
        "print(f\"\"\"\n",
        "🔧 TROUBLESHOOTING TIPS:\n",
        "\n",
        "• If generation fails due to memory: Restart runtime and try one scene at a time\n",
        "• For T4 GPU: Use all optimization flags (already included)\n",
        "• For better GPU (A100/V100): Remove --offload_model --convert_model_dtype --t5_cpu\n",
        "• Each scene takes ~5-15 minutes depending on GPU\n",
        "• Total trailer generation: 25-75 minutes\n",
        "\n",
        "🎯 SCENE PROMPTS USED:\n",
        "\"\"\")\n",
        "\n",
        "for i, scene in enumerate(scenes, 1):\n",
        "    print(f\"{i}. {scene['description']}: {scene['prompt'][:100]}...\")\n",
        "\n",
        "print(f\"\\n🎬 Happy video generation! 🎬\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06VhDWNVQxcM",
        "outputId": "2177750e-2feb-42d7-f59f-452bbcced7ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "CUDA available: False\n",
            "GPU: No GPU\n",
            "Cloning into 'Wan2.2'...\n",
            "remote: Enumerating objects: 109, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 109 (delta 38), reused 31 (delta 31), pack-reused 54 (from 1)\u001b[K\n",
            "Receiving objects: 100% (109/109), 1.48 MiB | 18.90 MiB/s, done.\n",
            "Resolving deltas: 100% (41/41), done.\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0)\n",
            "Requirement already satisfied: torchvision>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Requirement already satisfied: opencv-python>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (4.11.0.86)\n",
            "Requirement already satisfied: diffusers>=0.31.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (0.34.0)\n",
            "Requirement already satisfied: transformers>=4.49.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (4.55.2)\n",
            "Requirement already satisfied: tokenizers>=0.20.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.21.4)\n",
            "Requirement already satisfied: accelerate>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (1.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (4.67.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.13)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (6.3.1)\n",
            "Requirement already satisfied: dashscope in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (1.24.1)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (0.6.0)\n",
            "Requirement already satisfied: flash_attn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (2.8.3)\n",
            "Requirement already satisfied: numpy<2,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (1.26.4)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (2.37.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.19.0->-r requirements.txt (line 2)) (11.3.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (8.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (0.34.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers>=0.31.0->-r requirements.txt (line 4)) (0.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.49.0->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=1.1.1->-r requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->-r requirements.txt (line 11)) (0.2.13)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from dashscope->-r requirements.txt (line 12)) (3.12.15)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from dashscope->-r requirements.txt (line 12)) (1.8.0)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from dashscope->-r requirements.txt (line 12)) (43.0.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash_attn->-r requirements.txt (line 14)) (0.8.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers>=0.31.0->-r requirements.txt (line 4)) (1.1.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->dashscope->-r requirements.txt (line 12)) (1.20.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->dashscope->-r requirements.txt (line 12)) (1.17.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers>=0.31.0->-r requirements.txt (line 4)) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.31.0->-r requirements.txt (line 4)) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.31.0->-r requirements.txt (line 4)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.31.0->-r requirements.txt (line 4)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers>=0.31.0->-r requirements.txt (line 4)) (2025.8.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->dashscope->-r requirements.txt (line 12)) (2.22)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: imageio[ffmpeg] in /usr/local/lib/python3.11/dist-packages (2.37.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (11.3.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (0.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from imageio[ffmpeg]) (5.9.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "📥 Downloading Wan2.2-TI2V-5B model (this may take several minutes)...\n",
            "\u001b[33m⚠️  Warning: 'huggingface-cli download' is deprecated. Use 'hf download' instead.\u001b[0m\n",
            "Fetching 23 files:   0% 0/23 [00:00<?, ?it/s]Downloading '.msc' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/yGuuhN3jcMp8wjph_sAk9JRj2EM=.b9cd87580ba33d16a89a8cd9db0cbc67efe4fc79.incomplete'\n",
            "Downloading '.gitattributes' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.4b227fbecf653a7faf8b46492810c4a2174c7431.incomplete'\n",
            "Downloading 'Wan2.2_VAE.pth' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/CHzdR2H1q5_tJrjQMk3clUgGTXg=.20eb789667fa5e60e7516bf509512f6cb61f01b0aa0695eadaea930c13892b36.incomplete'\n",
            "Downloading 'assets/comp_effic.png' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/assets/X4-4NQEdffK1bUQbDx0NJ4IbcNo=.75ee012dcfb08365bec67a3ec7afc126fc2817f79b9f80e38711792d4770e32b.incomplete'\n",
            "\n",
            ".gitattributes: 1.87kB [00:00, 5.82MB/s]\n",
            "\n",
            ".msc: 100% 507/507 [00:00<00:00, 1.99MB/s]\n",
            "Downloading 'README.md' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.40523d8b626810c1ff5293746d181fb99aca6a7a.incomplete'\n",
            "Downloading 'assets/moe_2.png' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/assets/nRet4S88FozLSSwTJNookKkPe2U=.4ea471ccb64349bd08bc9a78f336ae000e9ca3b40da9a652b8028b214a8c6093.incomplete'\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/.gitattributes\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/.msc\n",
            "Fetching 23 files:   4% 1/23 [00:00<00:02,  7.34it/s]Downloading 'assets/logo.png' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/assets/gvouIpVGo_vjLxWDOGAmKk_SZvY=.0c55854cbd9692975f217714ffd83fd4b37f5dca.incomplete'\n",
            "\n",
            "README.md: 15.9kB [00:00, 22.2MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/README.md\n",
            "\n",
            "comp_effic.png:   0% 0.00/202k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "logo.png: 100% 56.3k/56.3k [00:00<00:00, 91.5MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/assets/logo.png\n",
            "\n",
            "\n",
            "comp_effic.png: 100% 202k/202k [00:00<00:00, 8.98MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/assets/comp_effic.png\n",
            "\n",
            "moe_2.png:   0% 0.00/528k [00:00<?, ?B/s]\u001b[ADownloading '.mv' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/TMvir_q0dnrJoBi-VP-reJNJVIY=.acac14f612675621cd9d2529ad4a590bfd9d0546.incomplete'\n",
            "Downloading 'assets/performance.png' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/assets/82SfNOaJIZo5zsyAX2vafak-9FA=.97ef99c13c8ae717a8a11c8d8ec927b69077c647cc6689755d08fc38e7fbb830.incomplete'\n",
            "moe_2.png: 100% 528k/528k [00:00<00:00, 8.66MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/assets/moe_2.png\n",
            "Downloading 'assets/vae.png' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/assets/wxqqE9bvovHNN6I2pgKdH8nIAKo=.4aaea5e187f1c5908e15ade5bef24c9fb59882986bc3d2ad75f7fe820f3d772f.incomplete'\n",
            "Downloading 'assets/moe_arch.png' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/assets/PxF_a-FLJ44WN1MONdliwvhjiOg=.7822af1e65215ee2a9449c9b7616afd713f67a01.incomplete'\n",
            "\n",
            ".mv: 100% 36.0/36.0 [00:00<00:00, 117kB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/.mv\n",
            "Fetching 23 files:  13% 3/23 [00:00<00:01, 11.25it/s]Downloading 'config.json' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.abb356dedbca416450700e180a6622626d789601.incomplete'\n",
            "\n",
            "moe_arch.png: 100% 74.9k/74.9k [00:00<00:00, 62.0MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/assets/moe_arch.png\n",
            "\n",
            "performance.png:   0% 0.00/307k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "config.json: 100% 251/251 [00:00<00:00, 1.15MB/s]\n",
            "\n",
            "\n",
            "\n",
            "vae.png:   0% 0.00/165k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[ADownloading 'configuration.json' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/pOL2LEBeNWU9Y3bTUNO_khibHs8=.d64db5cb6ceecfb2c7f0929427dc5f48bc4b7f37.incomplete'\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/config.json\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "configuration.json: 100% 43.0/43.0 [00:00<00:00, 224kB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/configuration.json\n",
            "vae.png: 100% 165k/165k [00:00<00:00, 10.6MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/assets/vae.png\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:   0% 10.5M/2.82G [00:00<00:50, 55.1MB/s]Downloading 'diffusion_pytorch_model-00001-of-00003.safetensors' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/5n3ByLHcDVGl-4O5UeVdJRvodxk=.720b06c4ade5e87c1246bba8ac95b664c638749cd9b102cf84d823bb44c026a1.incomplete'\n",
            "performance.png: 100% 307k/307k [00:00<00:00, 6.08MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/assets/performance.png\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:801: UserWarning: Not enough free disk space to download the file. The expected file size is: 9825.01 MB. The target location Wan2.2-TI2V-5B/.cache/huggingface/download only has 8442.55 MB free disk space.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:801: UserWarning: Not enough free disk space to download the file. The expected file size is: 9825.01 MB. The target location Wan2.2-TI2V-5B only has 8442.23 MB free disk space.\n",
            "  warnings.warn(\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   0% 0.00/9.83G [00:00<?, ?B/s]\u001b[ADownloading 'diffusion_pytorch_model-00002-of-00003.safetensors' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/xIb00LLWe-iHth2j35r6TGIYKx8=.09ec5ef720d8396f6cfa51fbdcbdb2327e37722afd6e89fd38f1e7e5e782c283.incomplete'\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:801: UserWarning: Not enough free disk space to download the file. The expected file size is: 9995.66 MB. The target location Wan2.2-TI2V-5B/.cache/huggingface/download only has 8432.06 MB free disk space.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:801: UserWarning: Not enough free disk space to download the file. The expected file size is: 9995.66 MB. The target location Wan2.2-TI2V-5B only has 8432.06 MB free disk space.\n",
            "  warnings.warn(\n",
            "Downloading 'diffusion_pytorch_model-00003-of-00003.safetensors' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/GwHdKznehhuKvEEAo-cIQ3kH9qA=.6306f7894c345de9093ad588771c2abfaeb668a81f7a6d9a918bd26ba3568e49.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   0% 0.00/10.0G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[ADownloading 'diffusion_pytorch_model.safetensors.index.json' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/VpHHFEQcyqWBKjkjOBMoMr6uTZU=.2a1d8b9ee7cd1456f79f944ae15c87724d49110e.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   0% 0.00/179M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[ADownloading 'google/umt5-xxl/spiece.model' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/google/umt5-xxl/vj8E1loknrCNPSP8nWJC234Bff4=.e3909a67b780650b35cf529ac782ad2b6b26e6d1f849d3fbb6a872905f452458.incomplete'\n",
            "Downloading 'google/umt5-xxl/special_tokens_map.json' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/google/umt5-xxl/ahkChHUJFxEmOdq5GDFEmerRzCY=.14855e7052ffbb595057dfd791d293c1c940db2c.incomplete'\n",
            "Downloading 'examples/i2v_input.JPG' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/examples/GqO1vCXUoNdTZc6wjxo1L7sjRdI=.077e3d965090c9028c69c00931675f42e1acc815c6eb450ab291b3b72d211a8e.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(…)ion_pytorch_model.safetensors.index.json: 72.9kB [00:00, 35.8MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/diffusion_pytorch_model.safetensors.index.json\n",
            "\n",
            "\n",
            "Wan2.2_VAE.pth:   1% 21.0M/2.82G [00:00<00:45, 60.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spiece.model:   0% 0.00/4.55M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "i2v_input.JPG: 100% 251k/251k [00:00<00:00, 193MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/examples/i2v_input.JPG\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "special_tokens_map.json: 6.62kB [00:00, 13.1MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/google/umt5-xxl/special_tokens_map.json\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   0% 10.5M/10.0G [00:00<04:02, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   0% 10.5M/9.83G [00:00<04:47, 34.1MB/s]\u001b[ADownloading 'google/umt5-xxl/tokenizer.json' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/google/umt5-xxl/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.6e197b4d3dbd71da14b4eb255f4fa91c9c1f2068b20a2de2472967ca3d22602b.incomplete'\n",
            "Downloading 'models_t5_umt5-xxl-enc-bf16.pth' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/7xjTyx9p9-CteGiI3VEINu_Ohx0=.7cace0da2b446bbbbc57d031ab6cf163a3d59b366da94e5afe36745b746fd81d.incomplete'\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:801: UserWarning: Not enough free disk space to download the file. The expected file size is: 11361.92 MB. The target location Wan2.2-TI2V-5B/.cache/huggingface/download only has 8403.12 MB free disk space.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:801: UserWarning: Not enough free disk space to download the file. The expected file size is: 11361.92 MB. The target location Wan2.2-TI2V-5B only has 8403.00 MB free disk space.\n",
            "  warnings.warn(\n",
            "Downloading 'google/umt5-xxl/tokenizer_config.json' to 'Wan2.2-TI2V-5B/.cache/huggingface/download/google/umt5-xxl/vzaExXFZNBay89bvlQv-ZcI6BTg=.4e1cc1cd85599ce0b47fd0a746af188fe4043ff2.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 0.00/11.4G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "spiece.model: 100% 4.55M/4.55M [00:00<00:00, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 61.7kB [00:00, 78.8MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/google/umt5-xxl/tokenizer_config.json\n",
            "spiece.model: 100% 4.55M/4.55M [00:00<00:00, 15.1MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/google/umt5-xxl/spiece.model\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:   0% 0.00/16.8M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   1% 31.5M/2.82G [00:00<01:08, 40.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:   6% 10.5M/179M [00:00<00:06, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   0% 21.0M/10.0G [00:00<04:11, 39.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   0% 21.0M/9.83G [00:00<04:26, 36.8MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   1% 41.9M/2.82G [00:00<00:58, 47.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  12% 21.0M/179M [00:00<00:04, 34.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:  62% 10.5M/16.8M [00:00<00:00, 36.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 10.5M/11.4G [00:00<06:23, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   0% 31.5M/9.83G [00:00<04:02, 40.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   0% 31.5M/10.0G [00:00<04:05, 40.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   2% 52.4M/2.82G [00:01<01:00, 45.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 100% 16.8M/16.8M [00:00<00:00, 24.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  18% 31.5M/179M [00:01<00:04, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[ADownload complete. Moving file to Wan2.2-TI2V-5B/google/umt5-xxl/tokenizer.json\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   0% 41.9M/10.0G [00:01<04:51, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 21.0M/11.4G [00:00<07:31, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   0% 41.9M/9.83G [00:01<05:00, 32.5MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   2% 62.9M/2.82G [00:01<01:10, 39.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  23% 41.9M/179M [00:01<00:03, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 31.5M/11.4G [00:01<05:29, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 52.4M/10.0G [00:01<04:34, 36.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 52.4M/9.83G [00:01<04:34, 35.6MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   3% 73.4M/2.82G [00:01<01:09, 39.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 41.9M/11.4G [00:01<04:19, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 62.9M/10.0G [00:01<04:02, 40.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  29% 52.4M/179M [00:01<00:03, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 62.9M/9.83G [00:01<04:25, 36.8MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   3% 83.9M/2.82G [00:01<01:06, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   0% 52.4M/11.4G [00:01<04:39, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 73.4M/10.0G [00:01<03:44, 44.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  35% 62.9M/179M [00:01<00:02, 39.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   3% 94.4M/2.82G [00:02<01:02, 43.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 73.4M/9.83G [00:01<04:06, 39.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 62.9M/11.4G [00:01<04:21, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  41% 73.4M/179M [00:01<00:02, 43.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 83.9M/10.0G [00:02<03:36, 45.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   4% 105M/2.82G [00:02<01:03, 42.8MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 73.4M/11.4G [00:01<03:59, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 83.9M/9.83G [00:02<04:16, 38.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 94.4M/10.0G [00:02<03:54, 42.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  47% 83.9M/179M [00:02<00:02, 36.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 83.9M/11.4G [00:02<04:05, 46.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   4% 115M/2.82G [00:02<01:10, 38.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 105M/10.0G [00:02<03:36, 45.7MB/s] \u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 94.4M/9.83G [00:02<04:21, 37.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  53% 94.4M/179M [00:02<00:02, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 94.4M/11.4G [00:02<03:54, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 105M/9.83G [00:02<03:48, 42.6MB/s] \u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   4% 126M/2.82G [00:02<01:02, 42.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 115M/10.0G [00:02<04:16, 38.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   5% 136M/2.82G [00:06<05:14, 8.53MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  59% 105M/179M [00:06<00:09, 8.17MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 105M/11.4G [00:05<22:30, 8.33MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 115M/9.83G [00:06<19:11, 8.43MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 126M/10.0G [00:06<18:48, 8.74MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 115M/11.4G [00:06<16:34, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  65% 115M/179M [00:06<00:05, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   5% 147M/2.82G [00:06<03:54, 11.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 126M/9.83G [00:06<14:18, 11.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 136M/10.0G [00:06<14:12, 11.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 126M/11.4G [00:06<13:16, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   6% 157M/2.82G [00:07<03:07, 14.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   1% 147M/10.0G [00:06<11:13, 14.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 136M/9.83G [00:06<11:36, 13.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  70% 126M/179M [00:06<00:03, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 157M/10.0G [00:07<09:07, 18.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   1% 147M/9.83G [00:07<09:16, 17.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 136M/11.4G [00:06<10:57, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   6% 168M/2.82G [00:07<02:35, 17.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  76% 136M/179M [00:07<00:02, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 168M/10.0G [00:07<07:42, 21.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   6% 178M/2.82G [00:07<02:08, 20.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 157M/9.83G [00:07<07:55, 20.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 147M/11.4G [00:07<09:14, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  82% 147M/179M [00:07<00:01, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 178M/10.0G [00:07<06:46, 24.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   7% 189M/2.82G [00:07<01:53, 23.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 168M/9.83G [00:07<06:57, 23.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 157M/11.4G [00:07<08:14, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  88% 157M/179M [00:07<00:00, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 189M/10.0G [00:07<05:45, 28.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   7% 199M/2.82G [00:08<01:39, 26.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 178M/9.83G [00:07<06:03, 26.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   1% 168M/11.4G [00:07<07:05, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors:  94% 168M/179M [00:07<00:00, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 199M/10.0G [00:08<05:31, 29.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 189M/9.83G [00:08<05:32, 29.0MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   7% 210M/2.82G [00:08<01:34, 27.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 178M/11.4G [00:07<06:53, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors: 100% 178M/179M [00:08<00:00, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 199M/9.83G [00:08<04:50, 33.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00003-of-00003.safetensors: 100% 179M/179M [00:08<00:00, 21.3MB/s]\n",
            "Download complete. Moving file to Wan2.2-TI2V-5B/diffusion_pytorch_model-00003-of-00003.safetensors\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 189M/11.4G [00:08<06:17, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   8% 220M/2.82G [00:08<01:29, 29.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 210M/9.83G [00:08<04:25, 36.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 220M/10.0G [00:08<04:35, 35.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   8% 231M/2.82G [00:12<05:25, 7.95MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 220M/9.83G [00:12<19:41, 8.13MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   9% 241M/2.82G [00:12<03:58, 10.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   2% 241M/9.83G [00:12<10:56, 14.6MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:   9% 262M/2.82G [00:12<02:13, 19.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 231M/10.0G [00:12<21:15, 7.66MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 199M/11.4G [00:12<25:28, 7.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  10% 283M/2.82G [00:12<01:26, 29.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 273M/9.83G [00:12<06:06, 26.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 210M/11.4G [00:12<18:33, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   2% 241M/10.0G [00:12<15:34, 10.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 283M/9.83G [00:12<05:22, 29.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 220M/11.4G [00:12<13:45, 13.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  11% 304M/2.82G [00:13<01:07, 37.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 252M/10.0G [00:12<11:47, 13.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 231M/11.4G [00:12<10:20, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 294M/9.83G [00:12<04:49, 32.9MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  11% 315M/2.82G [00:13<01:00, 41.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 262M/10.0G [00:12<08:48, 18.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 241M/11.4G [00:12<07:45, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 304M/9.83G [00:13<04:10, 38.0MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  12% 325M/2.82G [00:13<00:53, 46.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 273M/10.0G [00:13<06:51, 23.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 252M/11.4G [00:12<06:19, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 315M/9.83G [00:13<03:51, 41.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 283M/10.0G [00:13<05:38, 28.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  12% 346M/2.82G [00:13<00:45, 54.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 262M/11.4G [00:13<05:26, 34.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 325M/9.83G [00:13<03:28, 45.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 294M/10.0G [00:13<04:32, 35.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 273M/11.4G [00:13<04:38, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  13% 357M/2.82G [00:13<00:46, 53.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   3% 336M/9.83G [00:13<03:11, 49.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   2% 283M/11.4G [00:13<03:47, 48.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 304M/10.0G [00:13<04:11, 38.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  13% 367M/2.82G [00:13<00:43, 56.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 346M/9.83G [00:13<02:55, 53.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 294M/11.4G [00:13<03:20, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 315M/10.0G [00:13<03:34, 45.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 357M/9.83G [00:13<02:35, 60.7MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  13% 377M/2.82G [00:14<00:41, 59.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 304M/11.4G [00:13<02:54, 63.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 325M/10.0G [00:13<03:04, 52.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  14% 388M/2.82G [00:14<00:39, 62.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 367M/9.83G [00:14<02:36, 60.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 315M/11.4G [00:13<02:48, 65.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 336M/10.0G [00:14<03:01, 53.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  14% 398M/2.82G [00:14<00:34, 69.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 377M/9.83G [00:14<02:34, 61.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 325M/11.4G [00:13<02:56, 62.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   3% 346M/10.0G [00:14<02:43, 58.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 357M/10.0G [00:14<02:32, 63.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  15% 419M/2.82G [00:14<00:33, 72.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 336M/11.4G [00:14<03:01, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 398M/9.83G [00:14<02:14, 70.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 367M/10.0G [00:14<02:17, 70.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 346M/11.4G [00:14<02:54, 63.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 409M/9.83G [00:14<02:07, 73.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 377M/10.0G [00:14<02:15, 71.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  16% 440M/2.82G [00:14<00:31, 76.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 357M/11.4G [00:14<02:51, 64.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 419M/9.83G [00:14<02:10, 72.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 388M/10.0G [00:14<02:20, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  16% 451M/2.82G [00:15<00:32, 72.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 430M/9.83G [00:14<02:10, 72.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 377M/11.4G [00:14<02:23, 76.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 398M/10.0G [00:14<02:21, 67.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  16% 461M/2.82G [00:15<00:32, 71.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   4% 440M/9.83G [00:15<02:33, 61.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   3% 388M/11.4G [00:14<02:36, 70.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 409M/10.0G [00:15<02:28, 64.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  17% 472M/2.82G [00:15<00:34, 68.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 398M/11.4G [00:14<02:35, 70.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 419M/10.0G [00:15<02:30, 63.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 461M/9.83G [00:15<02:17, 68.0MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  17% 482M/2.82G [00:15<00:40, 58.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 409M/11.4G [00:15<02:42, 67.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   4% 430M/10.0G [00:15<02:35, 61.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 472M/9.83G [00:15<02:21, 66.3MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  17% 493M/2.82G [00:15<00:37, 61.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 419M/11.4G [00:15<02:34, 70.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 482M/9.83G [00:15<02:39, 58.7MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  18% 503M/2.82G [00:16<00:42, 54.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 451M/10.0G [00:15<02:31, 63.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 430M/11.4G [00:15<03:10, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 493M/9.83G [00:15<02:24, 64.4MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  18% 514M/2.82G [00:16<00:36, 62.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 440M/11.4G [00:15<02:52, 63.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 503M/9.83G [00:16<02:21, 65.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 451M/11.4G [00:15<02:47, 65.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  19% 524M/2.82G [00:16<00:39, 57.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 472M/10.0G [00:16<02:27, 64.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 514M/9.83G [00:16<02:09, 71.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 461M/11.4G [00:15<02:57, 61.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  19% 535M/2.82G [00:16<00:40, 56.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 482M/10.0G [00:16<02:40, 59.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 524M/9.83G [00:16<02:22, 65.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 493M/10.0G [00:16<02:37, 60.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   5% 535M/9.83G [00:16<02:41, 57.5MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  20% 556M/2.82G [00:16<00:36, 62.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 482M/11.4G [00:16<02:48, 64.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 503M/10.0G [00:16<02:21, 66.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 545M/9.83G [00:16<02:32, 60.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 514M/10.0G [00:16<02:20, 67.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 493M/11.4G [00:16<03:02, 59.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  20% 577M/2.82G [00:17<00:31, 71.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 556M/9.83G [00:16<02:29, 62.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 524M/10.0G [00:16<02:15, 70.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   4% 503M/11.4G [00:16<02:43, 66.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  21% 587M/2.82G [00:17<00:34, 65.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 566M/9.83G [00:17<02:35, 59.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 535M/10.0G [00:17<02:38, 59.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 514M/11.4G [00:16<03:08, 57.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  21% 598M/2.82G [00:17<00:41, 53.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 577M/9.83G [00:17<03:00, 51.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   5% 545M/10.0G [00:17<02:57, 53.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 524M/11.4G [00:17<03:31, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  22% 608M/2.82G [00:17<00:37, 59.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 587M/9.83G [00:17<02:49, 54.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 556M/10.0G [00:17<02:52, 54.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  22% 619M/2.82G [00:17<00:33, 65.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 535M/11.4G [00:17<03:15, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 598M/9.83G [00:17<02:35, 59.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 566M/10.0G [00:17<02:48, 55.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 545M/11.4G [00:17<03:18, 54.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  22% 629M/2.82G [00:18<00:37, 58.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 608M/9.83G [00:17<02:46, 55.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 577M/10.0G [00:17<03:08, 50.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  23% 640M/2.82G [00:18<00:44, 48.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 556M/11.4G [00:17<04:13, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 619M/9.83G [00:18<03:27, 44.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 587M/10.0G [00:18<03:09, 49.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 566M/11.4G [00:17<03:55, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  23% 650M/2.82G [00:18<00:45, 47.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   6% 629M/9.83G [00:18<03:10, 48.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 598M/10.0G [00:18<02:55, 53.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 577M/11.4G [00:18<03:45, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  23% 661M/2.82G [00:18<00:45, 47.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 608M/10.0G [00:18<02:56, 53.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 640M/9.83G [00:18<03:07, 48.9MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  24% 671M/2.82G [00:18<00:38, 56.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 619M/10.0G [00:18<02:30, 62.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 650M/9.83G [00:18<02:57, 51.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 598M/11.4G [00:18<03:10, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 629M/10.0G [00:18<02:34, 60.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 661M/9.83G [00:18<02:38, 57.9MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  25% 692M/2.82G [00:19<00:32, 65.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 608M/11.4G [00:18<02:55, 61.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   6% 640M/10.0G [00:19<02:26, 63.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   5% 619M/11.4G [00:18<02:42, 66.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  25% 703M/2.82G [00:19<00:31, 66.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 671M/9.83G [00:19<02:41, 56.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 650M/10.0G [00:19<02:28, 62.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  25% 713M/2.82G [00:19<00:32, 65.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 682M/9.83G [00:19<02:34, 59.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 640M/11.4G [00:18<02:20, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  26% 724M/2.82G [00:19<00:29, 70.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 661M/10.0G [00:19<02:39, 58.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 692M/9.83G [00:19<02:25, 62.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 650M/11.4G [00:19<02:16, 78.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  26% 734M/2.82G [00:19<00:27, 74.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Fetching 23 files:  13% 3/23 [00:20<00:01, 11.25it/s]\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 682M/10.0G [00:19<02:09, 71.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 703M/9.83G [00:19<02:38, 57.6MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  26% 744M/2.82G [00:19<00:29, 71.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 671M/11.4G [00:19<02:20, 75.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 713M/9.83G [00:19<02:29, 60.8MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  27% 755M/2.82G [00:20<00:31, 64.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 682M/11.4G [00:19<02:29, 71.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 703M/10.0G [00:19<02:08, 72.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  27% 765M/2.82G [00:20<00:32, 63.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 724M/9.83G [00:20<02:50, 53.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 692M/11.4G [00:19<02:31, 70.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 713M/10.0G [00:20<02:20, 65.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   7% 734M/9.83G [00:20<02:39, 57.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 703M/11.4G [00:19<02:46, 64.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 724M/10.0G [00:20<02:15, 68.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  28% 776M/2.82G [00:20<00:35, 58.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 744M/9.83G [00:20<02:39, 57.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 734M/10.0G [00:20<02:18, 66.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 713M/11.4G [00:20<02:54, 61.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  28% 786M/2.82G [00:20<00:36, 55.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 755M/9.83G [00:20<02:32, 59.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   7% 744M/10.0G [00:20<02:24, 63.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 724M/11.4G [00:20<02:58, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  28% 797M/2.82G [00:20<00:37, 53.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 765M/9.83G [00:20<02:33, 59.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   6% 734M/11.4G [00:20<02:39, 66.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 776M/9.83G [00:20<02:15, 66.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 755M/10.0G [00:20<02:48, 54.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  29% 807M/2.82G [00:21<00:39, 51.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 744M/11.4G [00:20<02:56, 60.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 786M/9.83G [00:21<02:26, 61.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 765M/10.0G [00:21<02:52, 53.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  29% 818M/2.82G [00:21<00:39, 50.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 755M/11.4G [00:20<03:07, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 797M/9.83G [00:21<02:38, 56.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 776M/10.0G [00:21<02:52, 53.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  29% 828M/2.82G [00:21<00:39, 50.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 765M/11.4G [00:20<03:04, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 807M/9.83G [00:21<02:42, 55.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 786M/10.0G [00:21<02:48, 54.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  30% 839M/2.82G [00:21<00:38, 52.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 776M/11.4G [00:21<03:13, 54.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 818M/9.83G [00:21<02:36, 57.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 797M/10.0G [00:21<02:41, 57.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  30% 849M/2.82G [00:21<00:36, 54.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   8% 828M/9.83G [00:21<02:21, 63.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 786M/11.4G [00:21<03:18, 53.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 807M/10.0G [00:21<02:38, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  31% 860M/2.82G [00:22<00:33, 57.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 839M/9.83G [00:21<02:20, 63.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 797M/11.4G [00:21<03:05, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 818M/10.0G [00:21<02:50, 53.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  31% 870M/2.82G [00:22<00:36, 54.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 849M/9.83G [00:22<02:29, 60.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 807M/11.4G [00:21<03:05, 56.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 828M/10.0G [00:22<02:40, 57.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  31% 881M/2.82G [00:22<00:34, 56.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 860M/9.83G [00:22<02:25, 61.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 818M/11.4G [00:21<03:01, 58.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 839M/10.0G [00:22<02:36, 58.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  32% 891M/2.82G [00:22<00:32, 59.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 870M/9.83G [00:22<02:23, 62.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 828M/11.4G [00:22<02:55, 60.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   8% 849M/10.0G [00:22<02:42, 56.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  32% 902M/2.82G [00:22<00:35, 53.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 839M/11.4G [00:22<03:06, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 881M/9.83G [00:22<02:44, 54.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 860M/10.0G [00:22<02:49, 54.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   7% 849M/11.4G [00:22<03:04, 56.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  32% 912M/2.82G [00:23<00:36, 52.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 891M/9.83G [00:22<02:38, 56.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 870M/10.0G [00:22<02:45, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  33% 923M/2.82G [00:23<00:31, 60.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 860M/11.4G [00:22<02:47, 62.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 902M/9.83G [00:23<02:25, 61.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 881M/10.0G [00:23<02:48, 54.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  33% 933M/2.82G [00:23<00:33, 56.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 870M/11.4G [00:22<03:06, 56.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 912M/9.83G [00:23<02:44, 54.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 891M/10.0G [00:23<02:52, 52.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  33% 944M/2.82G [00:23<00:37, 50.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 881M/11.4G [00:23<03:24, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 902M/10.0G [00:23<02:45, 54.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  34% 954M/2.82G [00:23<00:34, 54.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 891M/11.4G [00:23<03:07, 55.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 923M/9.83G [00:23<03:37, 40.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 912M/10.0G [00:23<02:36, 58.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  34% 965M/2.82G [00:23<00:33, 56.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 902M/11.4G [00:23<03:09, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:   9% 933M/9.83G [00:23<03:22, 44.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 923M/10.0G [00:23<02:34, 58.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  35% 975M/2.82G [00:24<00:31, 58.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 912M/11.4G [00:23<02:54, 59.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 944M/9.83G [00:23<02:46, 53.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 933M/10.0G [00:24<02:32, 59.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 923M/11.4G [00:23<03:05, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 954M/9.83G [00:24<02:57, 49.9MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  35% 986M/2.82G [00:24<00:35, 52.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:   9% 944M/10.0G [00:24<02:23, 63.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 933M/11.4G [00:23<02:45, 63.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 965M/9.83G [00:24<02:49, 52.3MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  35% 996M/2.82G [00:24<00:34, 53.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 954M/10.0G [00:24<02:38, 57.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 944M/11.4G [00:24<03:03, 56.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  36% 1.01G/2.82G [00:24<00:30, 58.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 975M/9.83G [00:24<02:41, 54.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 965M/10.0G [00:24<02:23, 63.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  36% 1.02G/2.82G [00:24<00:29, 61.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 954M/11.4G [00:24<02:59, 58.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 975M/10.0G [00:24<02:20, 64.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 986M/9.83G [00:24<02:39, 55.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   8% 965M/11.4G [00:24<02:59, 57.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 996M/9.83G [00:24<02:33, 57.6MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  36% 1.03G/2.82G [00:25<00:31, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 986M/10.0G [00:24<02:40, 56.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 975M/11.4G [00:24<02:54, 59.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 1.01G/9.83G [00:25<02:24, 61.1MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  37% 1.04G/2.82G [00:25<00:29, 61.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 996M/10.0G [00:25<02:28, 60.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  37% 1.05G/2.82G [00:25<00:29, 59.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 1.01G/10.0G [00:25<02:21, 63.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 1.02G/9.83G [00:25<02:32, 57.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 986M/11.4G [00:24<03:46, 45.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  38% 1.06G/2.82G [00:25<00:28, 61.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 1.02G/10.0G [00:25<02:18, 64.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  10% 1.03G/9.83G [00:25<02:24, 60.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 996M/11.4G [00:25<03:30, 49.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  38% 1.07G/2.82G [00:25<00:31, 55.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 1.03G/10.0G [00:25<02:34, 58.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.04G/9.83G [00:25<02:40, 54.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 1.01G/11.4G [00:25<03:10, 54.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.05G/9.83G [00:25<02:18, 63.5MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  38% 1.08G/2.82G [00:26<00:33, 52.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 1.04G/10.0G [00:25<02:49, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.06G/9.83G [00:25<02:19, 62.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 1.02G/11.4G [00:25<03:18, 52.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  39% 1.09G/2.82G [00:26<00:30, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  10% 1.05G/10.0G [00:25<02:43, 54.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 1.03G/11.4G [00:25<03:07, 55.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.07G/9.83G [00:26<02:24, 60.5MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  39% 1.10G/2.82G [00:26<00:28, 60.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.06G/10.0G [00:26<02:23, 62.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.08G/9.83G [00:26<02:17, 63.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.07G/10.0G [00:26<02:10, 68.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  39% 1.11G/2.82G [00:26<00:26, 64.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 1.05G/11.4G [00:25<02:25, 71.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.09G/9.83G [00:26<02:04, 70.3MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  40% 1.12G/2.82G [00:26<00:24, 70.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 1.06G/11.4G [00:25<02:17, 74.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.09G/10.0G [00:26<01:52, 79.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:   9% 1.07G/11.4G [00:26<02:08, 80.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  40% 1.13G/2.82G [00:26<00:22, 74.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.11G/9.83G [00:26<01:42, 85.3MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  41% 1.14G/2.82G [00:26<00:21, 79.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.11G/10.0G [00:26<01:53, 78.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  11% 1.12G/9.83G [00:26<02:01, 71.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.09G/11.4G [00:26<02:07, 80.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  41% 1.15G/2.82G [00:26<00:22, 74.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.13G/9.83G [00:26<01:55, 75.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.12G/10.0G [00:26<02:02, 72.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.10G/11.4G [00:26<02:19, 73.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  41% 1.16G/2.82G [00:27<00:23, 70.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.14G/9.83G [00:27<02:08, 67.5MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  42% 1.17G/2.82G [00:27<00:23, 68.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.13G/10.0G [00:27<02:11, 67.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.11G/11.4G [00:26<02:29, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.15G/9.83G [00:27<02:18, 62.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  11% 1.14G/10.0G [00:27<02:20, 63.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.12G/11.4G [00:26<02:41, 63.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  42% 1.18G/2.82G [00:27<00:27, 60.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.16G/9.83G [00:27<02:29, 57.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.15G/10.0G [00:27<03:03, 48.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  42% 1.20G/2.82G [00:27<00:37, 43.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.13G/11.4G [00:27<03:57, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.16G/10.0G [00:28<04:25, 33.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.14G/11.4G [00:27<05:07, 33.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.17G/9.83G [00:28<05:01, 28.7MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  43% 1.21G/2.82G [00:28<00:53, 30.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.18G/9.83G [00:28<04:04, 35.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.15G/11.4G [00:28<04:33, 37.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  43% 1.22G/2.82G [00:28<00:46, 34.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.20G/9.83G [00:28<03:40, 39.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.16G/11.4G [00:28<04:10, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  44% 1.23G/2.82G [00:28<00:40, 38.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.18G/10.0G [00:28<04:06, 35.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.21G/9.83G [00:28<03:24, 42.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.17G/11.4G [00:28<03:46, 45.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  44% 1.24G/2.82G [00:29<00:36, 43.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.21G/10.0G [00:28<02:53, 50.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  10% 1.18G/11.4G [00:28<03:21, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.22G/10.0G [00:28<02:36, 56.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  44% 1.25G/2.82G [00:30<01:36, 16.2MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  12% 1.23G/9.83G [00:30<07:04, 20.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.20G/11.4G [00:30<09:40, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.23G/10.0G [00:30<06:53, 21.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  45% 1.26G/2.82G [00:30<01:11, 21.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.24G/9.83G [00:30<05:51, 24.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.21G/11.4G [00:30<07:33, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.24G/10.0G [00:30<05:43, 25.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  45% 1.27G/2.82G [00:30<00:54, 28.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  12% 1.25G/10.0G [00:32<11:51, 12.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.22G/11.4G [00:32<15:25, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.25G/9.83G [00:32<11:53, 12.0MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  45% 1.28G/2.82G [00:33<02:10, 11.8MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.26G/9.83G [00:32<09:03, 15.8MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  46% 1.29G/2.82G [00:33<01:35, 16.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.24G/11.4G [00:32<08:53, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.27G/10.0G [00:32<07:24, 19.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.27G/9.83G [00:33<07:05, 20.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.25G/11.4G [00:32<07:18, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  46% 1.30G/2.82G [00:33<01:14, 20.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.28G/10.0G [00:33<06:16, 23.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.28G/9.83G [00:33<05:34, 25.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.26G/11.4G [00:32<05:58, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  46% 1.31G/2.82G [00:33<01:00, 25.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.29G/9.83G [00:33<04:24, 32.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.29G/10.0G [00:33<05:12, 27.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.27G/11.4G [00:32<04:53, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  47% 1.32G/2.82G [00:33<00:46, 31.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.30G/9.83G [00:33<03:40, 38.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.28G/11.4G [00:33<04:07, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.30G/10.0G [00:33<04:27, 32.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  47% 1.33G/2.82G [00:33<00:39, 38.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.31G/9.83G [00:33<03:11, 44.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.31G/10.0G [00:33<03:43, 38.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.29G/11.4G [00:33<03:37, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  48% 1.34G/2.82G [00:33<00:33, 44.7MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  13% 1.32G/9.83G [00:33<02:47, 50.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  11% 1.30G/11.4G [00:33<03:05, 54.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.32G/10.0G [00:33<03:15, 44.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.31G/11.4G [00:33<02:41, 62.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.34G/9.83G [00:33<02:01, 69.6MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  48% 1.35G/2.82G [00:34<00:35, 40.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.32G/11.4G [00:33<02:43, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.35G/9.83G [00:34<02:02, 69.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  13% 1.34G/10.0G [00:34<02:39, 54.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  48% 1.36G/2.82G [00:34<00:32, 44.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.33G/11.4G [00:33<02:42, 61.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.36G/9.83G [00:34<02:05, 67.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.35G/10.0G [00:34<02:33, 56.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  49% 1.37G/2.82G [00:34<00:27, 53.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.37G/9.83G [00:34<01:58, 71.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.34G/11.4G [00:33<02:32, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.36G/10.0G [00:34<02:24, 59.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  49% 1.38G/2.82G [00:34<00:26, 54.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.35G/11.4G [00:34<02:29, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.38G/9.83G [00:34<02:03, 68.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.38G/10.0G [00:34<01:57, 73.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.36G/11.4G [00:34<02:26, 68.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.39G/9.83G [00:34<01:58, 71.1MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  50% 1.41G/2.82G [00:34<00:19, 71.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.39G/10.0G [00:34<01:50, 77.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.37G/11.4G [00:34<02:31, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.41G/9.83G [00:34<02:09, 64.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.41G/10.0G [00:34<01:57, 73.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  50% 1.42G/2.82G [00:35<00:21, 65.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.38G/11.4G [00:34<02:26, 68.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  14% 1.42G/9.83G [00:34<02:00, 69.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.42G/10.0G [00:34<01:52, 76.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  51% 1.43G/2.82G [00:35<00:21, 66.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.39G/11.4G [00:34<02:13, 74.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.43G/9.83G [00:35<02:05, 67.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.43G/10.0G [00:35<02:08, 66.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.41G/11.4G [00:34<02:18, 71.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  51% 1.44G/2.82G [00:35<00:23, 58.3MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.44G/9.83G [00:35<02:07, 65.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.44G/10.0G [00:35<02:05, 68.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  12% 1.42G/11.4G [00:34<02:23, 69.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  51% 1.45G/2.82G [00:35<00:23, 57.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  14% 1.45G/10.0G [00:35<02:05, 68.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.45G/9.83G [00:35<02:19, 60.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.43G/11.4G [00:35<02:30, 66.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  52% 1.46G/2.82G [00:35<00:25, 54.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.46G/10.0G [00:35<02:18, 61.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.46G/9.83G [00:35<02:32, 54.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.44G/11.4G [00:35<02:56, 56.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  52% 1.47G/2.82G [00:36<00:25, 52.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.47G/10.0G [00:35<02:34, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.47G/9.83G [00:35<02:42, 51.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.45G/11.4G [00:35<03:00, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  52% 1.48G/2.82G [00:36<00:24, 55.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.48G/10.0G [00:36<02:21, 60.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.48G/9.83G [00:36<02:29, 55.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.46G/11.4G [00:35<03:35, 46.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  53% 1.49G/2.82G [00:36<00:29, 44.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.49G/10.0G [00:36<03:09, 44.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.49G/9.83G [00:36<03:14, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.47G/11.4G [00:36<03:23, 48.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  53% 1.50G/2.82G [00:36<00:25, 50.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.50G/10.0G [00:36<02:58, 47.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  54% 1.51G/2.82G [00:36<00:26, 49.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.50G/9.83G [00:36<03:17, 42.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.48G/11.4G [00:36<03:33, 46.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.51G/10.0G [00:36<02:55, 48.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.51G/9.83G [00:36<03:02, 45.6MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  54% 1.52G/2.82G [00:37<00:25, 50.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.49G/11.4G [00:36<03:25, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.52G/10.0G [00:36<02:46, 50.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  15% 1.52G/9.83G [00:37<02:49, 49.1MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  54% 1.53G/2.82G [00:37<00:25, 51.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.53G/10.0G [00:37<02:37, 53.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.50G/11.4G [00:36<03:31, 46.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.53G/9.83G [00:37<02:36, 53.1MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  55% 1.54G/2.82G [00:37<00:23, 55.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  15% 1.54G/10.0G [00:37<02:24, 58.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.51G/11.4G [00:37<03:27, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.54G/9.83G [00:37<02:36, 53.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.55G/10.0G [00:37<02:28, 56.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  55% 1.55G/2.82G [00:37<00:24, 52.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.52G/11.4G [00:37<03:26, 47.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.55G/9.83G [00:37<02:37, 52.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.56G/10.0G [00:37<02:25, 58.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  55% 1.56G/2.82G [00:37<00:23, 54.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  13% 1.53G/11.4G [00:37<03:09, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.56G/9.83G [00:37<02:28, 55.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.57G/10.0G [00:37<02:20, 60.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  56% 1.57G/2.82G [00:38<00:21, 57.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.54G/11.4G [00:37<02:52, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.58G/10.0G [00:38<02:25, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.57G/9.83G [00:38<02:37, 52.5MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  56% 1.58G/2.82G [00:38<00:23, 51.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.55G/11.4G [00:37<03:09, 51.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.59G/10.0G [00:38<02:40, 52.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.58G/9.83G [00:38<02:46, 49.6MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  57% 1.59G/2.82G [00:38<00:25, 49.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.56G/11.4G [00:37<03:08, 52.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.60G/10.0G [00:38<02:35, 53.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  57% 1.60G/2.82G [00:38<00:22, 54.1MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.59G/9.83G [00:38<02:39, 51.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.57G/11.4G [00:38<03:03, 53.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.61G/10.0G [00:38<02:35, 53.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  57% 1.61G/2.82G [00:38<00:22, 54.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.60G/9.83G [00:38<02:48, 48.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.58G/11.4G [00:38<02:58, 54.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  58% 1.63G/2.82G [00:39<00:19, 60.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.59G/11.4G [00:38<02:56, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  16% 1.61G/9.83G [00:38<02:44, 49.8MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  58% 1.64G/2.82G [00:39<00:19, 62.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.63G/10.0G [00:39<03:20, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.63G/9.83G [00:39<02:27, 55.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.60G/11.4G [00:38<02:49, 57.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  58% 1.65G/2.82G [00:39<00:20, 57.0MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.64G/9.83G [00:39<02:18, 58.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.64G/10.0G [00:39<03:13, 43.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.61G/11.4G [00:38<02:50, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  59% 1.66G/2.82G [00:39<00:17, 65.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.65G/9.83G [00:39<02:13, 61.3MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  59% 1.67G/2.82G [00:39<00:16, 69.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.63G/11.4G [00:39<02:48, 57.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  16% 1.65G/10.0G [00:39<02:59, 46.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.64G/11.4G [00:39<02:30, 64.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.66G/9.83G [00:39<02:35, 52.4MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  60% 1.68G/2.82G [00:39<00:20, 55.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.66G/10.0G [00:39<03:11, 43.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  14% 1.65G/11.4G [00:39<02:43, 59.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.67G/9.83G [00:39<02:40, 51.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.66G/11.4G [00:39<02:23, 67.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  60% 1.69G/2.82G [00:40<00:20, 55.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.67G/10.0G [00:39<03:05, 44.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.67G/11.4G [00:39<02:17, 70.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.68G/9.83G [00:40<02:29, 54.6MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  60% 1.70G/2.82G [00:40<00:33, 33.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.68G/11.4G [00:40<04:02, 39.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.68G/10.0G [00:40<04:36, 30.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.69G/9.83G [00:40<04:03, 33.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.69G/10.0G [00:40<03:41, 37.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  61% 1.71G/2.82G [00:40<00:29, 37.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.69G/11.4G [00:40<03:47, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.70G/9.83G [00:40<03:25, 39.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.70G/10.0G [00:40<03:00, 45.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  61% 1.72G/2.82G [00:41<00:25, 43.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.70G/11.4G [00:40<03:15, 49.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.71G/10.0G [00:40<02:35, 53.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  17% 1.71G/9.83G [00:40<02:58, 45.5MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  61% 1.73G/2.82G [00:41<00:23, 46.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.71G/11.4G [00:42<12:08, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  62% 1.74G/2.82G [00:43<01:17, 13.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.72G/9.83G [00:43<10:17, 13.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.72G/10.0G [00:43<10:13, 13.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  62% 1.75G/2.82G [00:43<00:57, 18.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.73G/10.0G [00:43<07:34, 18.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.73G/11.4G [00:42<07:09, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.74G/9.83G [00:43<06:06, 22.1MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  62% 1.76G/2.82G [00:43<00:43, 24.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  17% 1.74G/10.0G [00:43<05:59, 23.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.74G/11.4G [00:42<05:58, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.75G/9.83G [00:43<05:02, 26.7MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  63% 1.77G/2.82G [00:43<00:35, 29.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.75G/10.0G [00:43<04:57, 27.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.76G/9.83G [00:43<04:14, 31.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  15% 1.75G/11.4G [00:43<05:08, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  63% 1.78G/2.82G [00:43<00:29, 35.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.76G/10.0G [00:43<04:01, 34.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.77G/9.83G [00:43<03:36, 37.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.76G/11.4G [00:43<04:23, 36.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  64% 1.79G/2.82G [00:43<00:23, 42.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.77G/10.0G [00:43<03:19, 41.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.78G/9.83G [00:43<03:00, 44.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.77G/11.4G [00:43<03:40, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  64% 1.80G/2.82G [00:44<00:21, 46.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.78G/11.4G [00:43<03:08, 50.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.78G/10.0G [00:43<03:05, 44.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.79G/9.83G [00:44<02:54, 46.1MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  64% 1.81G/2.82G [00:44<00:19, 52.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.79G/11.4G [00:43<03:06, 51.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.79G/10.0G [00:44<02:50, 48.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  65% 1.82G/2.82G [00:44<00:16, 59.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.80G/9.83G [00:44<02:39, 50.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.80G/11.4G [00:43<02:47, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  18% 1.81G/9.83G [00:44<02:24, 55.3MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  65% 1.84G/2.82G [00:44<00:15, 61.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.80G/10.0G [00:44<02:39, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.81G/11.4G [00:43<02:28, 64.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.82G/9.83G [00:44<02:10, 61.2MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  65% 1.85G/2.82G [00:44<00:15, 63.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.82G/11.4G [00:44<02:16, 70.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.81G/10.0G [00:44<02:38, 51.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.84G/9.83G [00:44<02:02, 65.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.84G/11.4G [00:44<02:12, 72.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  66% 1.87G/2.82G [00:44<00:11, 80.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.82G/10.0G [00:44<02:25, 56.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.85G/9.83G [00:44<01:57, 67.9MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  67% 1.88G/2.82G [00:45<00:11, 78.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.85G/11.4G [00:44<02:23, 66.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.84G/10.0G [00:44<02:28, 55.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.86G/9.83G [00:44<02:01, 65.5MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  67% 1.89G/2.82G [00:45<00:12, 76.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  16% 1.87G/11.4G [00:44<01:55, 82.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  18% 1.85G/10.0G [00:45<02:24, 56.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.87G/9.83G [00:45<02:07, 62.4MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  67% 1.90G/2.82G [00:45<00:12, 76.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.88G/9.83G [00:45<02:05, 63.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.89G/11.4G [00:44<01:50, 85.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  68% 1.91G/2.82G [00:45<00:12, 71.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.86G/10.0G [00:45<02:24, 56.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.90G/11.4G [00:44<01:47, 87.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.87G/10.0G [00:45<02:14, 60.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  68% 1.92G/2.82G [00:45<00:12, 72.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.92G/11.4G [00:45<01:35, 99.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.88G/10.0G [00:45<02:07, 63.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.89G/9.83G [00:45<02:36, 50.7MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  68% 1.93G/2.82G [00:45<00:12, 71.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.93G/11.4G [00:45<01:36, 98.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  69% 1.94G/2.82G [00:45<00:12, 72.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.90G/9.83G [00:45<02:26, 53.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.89G/10.0G [00:45<02:10, 62.0MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.94G/11.4G [00:45<01:36, 97.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  19% 1.91G/9.83G [00:45<02:19, 56.7MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  70% 1.96G/2.82G [00:46<00:10, 78.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.95G/11.4G [00:45<01:56, 80.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.90G/10.0G [00:45<02:26, 55.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 1.92G/9.83G [00:45<02:00, 65.5MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  70% 1.97G/2.82G [00:46<00:11, 75.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.91G/10.0G [00:46<02:19, 57.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.96G/11.4G [00:45<02:22, 65.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 1.93G/9.83G [00:46<02:29, 52.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.92G/10.0G [00:46<02:13, 60.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  70% 1.98G/2.82G [00:46<00:12, 67.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.97G/11.4G [00:45<02:22, 65.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  71% 1.99G/2.82G [00:46<00:11, 69.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  19% 1.93G/10.0G [00:46<02:15, 59.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 1.95G/9.83G [00:46<02:02, 64.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  17% 1.98G/11.4G [00:46<02:26, 64.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  71% 2.00G/2.82G [00:46<00:10, 75.5MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 1.96G/9.83G [00:46<01:53, 69.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 1.99G/11.4G [00:46<02:29, 62.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  71% 2.01G/2.82G [00:46<00:11, 69.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 1.95G/10.0G [00:46<02:01, 66.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 1.97G/9.83G [00:46<01:51, 70.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.00G/11.4G [00:46<02:36, 60.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 1.96G/10.0G [00:46<02:07, 62.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  72% 2.02G/2.82G [00:47<00:12, 61.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 1.98G/9.83G [00:46<01:58, 66.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.01G/11.4G [00:46<02:22, 65.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  72% 2.03G/2.82G [00:47<00:18, 41.6MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 1.99G/9.83G [00:49<09:01, 14.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.02G/11.4G [00:48<11:04, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 1.97G/10.0G [00:49<09:03, 14.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  73% 2.04G/2.82G [00:49<00:52, 14.9MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  20% 2.01G/9.83G [00:49<05:26, 23.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.04G/11.4G [00:48<06:37, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 1.99G/10.0G [00:49<05:38, 23.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  21% 2.02G/9.83G [00:49<04:40, 27.8MB/s]\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  73% 2.07G/2.82G [00:49<00:32, 23.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 2.00G/10.0G [00:49<04:54, 27.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.06G/11.4G [00:49<05:45, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  74% 2.08G/2.82G [00:49<00:27, 27.4MB/s]\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  21% 2.03G/9.83G [00:49<04:06, 31.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 2.01G/10.0G [00:49<04:14, 31.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.07G/11.4G [00:49<05:01, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  74% 2.09G/2.82G [00:49<00:21, 33.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 2.02G/10.0G [00:50<04:32, 29.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "Wan2.2_VAE.pth:  74% 2.10G/2.82G [00:50<00:29, 24.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.08G/11.4G [00:50<06:45, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  21% 2.06G/9.83G [00:50<04:38, 27.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "(…)pytorch_model-00001-of-00003.safetensors:  21% 2.06G/9.83G [00:50<03:11, 40.6MB/s]\n",
            "models_t5_umt5-xxl-enc-bf16.pth:  18% 2.08G/11.4G [00:50<03:44, 41.4MB/s]\n",
            "(…)pytorch_model-00002-of-00003.safetensors:  20% 2.03G/10.0G [00:50<03:17, 40.2MB/s]\n",
            "Wan2.2_VAE.pth:  74% 2.10G/2.82G [00:50<00:17, 41.3MB/s]\n",
            "Fetching 23 files:  17% 4/23 [00:50<04:02, 12.75s/it]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/huggingface-cli\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/commands/huggingface_cli.py\", line 61, in main\n",
            "    service.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/commands/download.py\", line 157, in run\n",
            "    print(self._download())  # Print path to downloaded files\n",
            "          ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/commands/download.py\", line 191, in _download\n",
            "    return snapshot_download(\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/_snapshot_download.py\", line 332, in snapshot_download\n",
            "    thread_map(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tqdm/contrib/concurrent.py\", line 69, in thread_map\n",
            "    return _executor_map(ThreadPoolExecutor, fn, *iterables, **tqdm_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tqdm/contrib/concurrent.py\", line 51, in _executor_map\n",
            "    return list(tqdm_class(ex.map(fn, *iterables, chunksize=chunksize), **kwargs))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/tqdm/std.py\", line 1181, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 619, in result_iterator\n",
            "    yield _result_or_cancel(fs.pop())\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 317, in _result_or_cancel\n",
            "    return fut.result(timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 456, in result\n",
            "    return self.__get_result()\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/concurrent/futures/_base.py\", line 401, in __get_result\n",
            "    raise self._exception\n",
            "  File \"/usr/lib/python3.11/concurrent/futures/thread.py\", line 58, in run\n",
            "    result = self.fn(*self.args, **self.kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/_snapshot_download.py\", line 306, in _inner_hf_hub_download\n",
            "    return hf_hub_download(\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 990, in hf_hub_download\n",
            "    return _hf_hub_download_to_local_dir(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1300, in _hf_hub_download_to_local_dir\n",
            "    _download_to_tmp_and_move(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 1738, in _download_to_tmp_and_move\n",
            "    http_get(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\", line 499, in http_get\n",
            "    temp_file.write(chunk)\n",
            "OSError: [Errno 28] No space left on device\n",
            "✅ Model download completed!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 28] No space left on device: '/content/wahdrobe_trailer'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-904376345.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# ===============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/wahdrobe_trailer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0moutput_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0msuccessful_generations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \"\"\"\n\u001b[1;32m   1115\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device: '/content/wahdrobe_trailer'"
          ]
        }
      ]
    }
  ]
}